{
  "question" : {
    "question_id" : 79707005,
    "title" : "Not able to run a spark code due to some issue on my local",
    "body" : "<p>I am facing the below error while running the given piece of spark code on my local Pycharm Community Edition and the spark session is not getting created.\nI have set up all my local environment variable correctly for jdk and spark both.\nFYI I am using java &quot;openjdk 11.0.22 2024-01-16&quot;, &quot;javac 11.0.22&quot;, Python 3.13.5 and pyspark 3.5.6 versions. Could someone please help me to solve this issue.\nThanks in Advance!!!</p>\n<pre><code>from pyspark.sql import functions as f\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import session_window\nfrom pyspark.sql import Window\nimport os\nimport findspark\n\nfindspark.init(&quot;C:\\\\spark&quot;)\nos.environ[&quot;JAVA_HOME&quot;] = &quot;C:\\\\Program Files\\\\Eclipse Adoptium\\\\jdk-11.0.22.7-hotspot&quot;\nos.environ[&quot;SPARK_HOME&quot;] = &quot;C:\\\\spark&quot;\nprint(&quot;Pyspark Imported&quot;)\nspark = SparkSession.builder.appName(&quot;CSVEXAMPLE&quot;).getOrCreate()\n\nprint(&quot;spark sessions started&quot;)\nprint(&quot;Spark Version:&quot;, spark.version)\n</code></pre>\n<p>The <strong>&quot;Pyspark Imported&quot;</strong> line is only getting printed then the below error is coming.</p>\n<p><strong>Error:</strong></p>\n<pre class=\"lang-none prettyprint-override\"><code>File &quot;C:\\Users\\pythonProject\\TEST_SCRIPT.py&quot;, line 11, in &lt;module&gt;\n \nspark = SparkSession.builder.appName(&quot;CSVEXAMPLE&quot;).getOrCreate()\n \nFile &quot;C:\\Users\\pythonProject\\.venv\\Lib\\site-packages\\pyspark\\sql\\session.py&quot;,\nline 559, in getOrCreate\n \nsession = SparkSession(sc, options=self._options)\n \nFile &quot;C:\\Users\\pythonProject\\.venv\\Lib\\site-packages\\pyspark\\sql\\session.py&quot;,\nline 635, in __init__\n \njSparkSessionClass.getDefaultSession().isDefined()\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n \nTypeError: 'JavaPackage' object is not callable\n\nProcess finished with exit code 1\n</code></pre>\n",
    "tags" : [ "python", "java", "apache-spark", "pyspark", "pyspark-pandas" ],
    "owner" : {
      "account_id" : 16967464,
      "reputation" : 27,
      "user_id" : 12272959,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/a5bd508c68ff2ba03a52b51c838f0a7f?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Node98",
      "link" : "https://stackoverflow.com/users/12272959/node98"
    },
    "is_answered" : false,
    "view_count" : 234,
    "answer_count" : 1,
    "score" : 0,
    "last_activity_date" : 1753081142,
    "creation_date" : 1752906934,
    "link" : "https://stackoverflow.com/questions/79707005/not-able-to-run-a-spark-code-due-to-some-issue-on-my-local",
    "content_license" : "CC BY-SA 4.0"
  },
  "answers" : [ {
    "answer_id" : 79708682,
    "question_id" : 79707005,
    "body" : "<p>The Pyspark version being used was 4.0.0, then It got resolved when I installed lower version of Pyspark that is Pyspark 3.5.6 hence its compatible with JDK11.</p>\n<p>Thanks</p>\n",
    "score" : 0,
    "is_accepted" : false,
    "owner" : {
      "account_id" : 16967464,
      "reputation" : 27,
      "user_id" : 12272959,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/a5bd508c68ff2ba03a52b51c838f0a7f?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Node98",
      "link" : "https://stackoverflow.com/users/12272959/node98"
    },
    "creation_date" : 1753081142,
    "last_activity_date" : 1753081142,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "question_comments" : [ {
    "comment_id" : 140603518,
    "post_id" : 79707005,
    "body" : "This is very suspicious.  I took a look at the source code for &quot;pyspark\\sql\\session.py&quot; in pyspark 3.5.6, and the code for <code>__init__</code> is different to what the stacktrace in your question implies.   And the line numbers don&#39;t match. (See <a href=\"https://github.com/apache/spark/blob/v3.5.6/python/pyspark/sql/session.py\" rel=\"nofollow noreferrer\">github.com/apache/spark/blob/v3.5.6/python/pyspark/sql/&hellip;</a>)  Are you absolutely sure that you are using that version of pyspark?",
    "score" : 0,
    "owner" : {
      "account_id" : 47283,
      "reputation" : 723428,
      "user_id" : 139985,
      "user_type" : "registered",
      "accept_rate" : 69,
      "profile_image" : "https://www.gravatar.com/avatar/147c5a9cc1feec049c50da791ac7d144?s=256&d=identicon&r=PG",
      "display_name" : "Stephen C",
      "link" : "https://stackoverflow.com/users/139985/stephen-c"
    },
    "creation_date" : 1753001612,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140603194,
    "post_id" : 79707005,
    "body" : "error may suggests that <code>getDefaultSession</code> or <code>isDefinded</code> is not function but module and it can&#39;t use <code>()</code>. It is not problem in your code but in module and it may need to send this problem to author(s) of this module.",
    "score" : 0,
    "owner" : {
      "account_id" : 99309,
      "reputation" : 148794,
      "user_id" : 1832058,
      "user_type" : "registered",
      "profile_image" : "https://i.sstatic.net/relWs.jpg?s=256",
      "display_name" : "furas",
      "link" : "https://stackoverflow.com/users/1832058/furas"
    },
    "creation_date" : 1752981463,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "answer_comments" : { }
}