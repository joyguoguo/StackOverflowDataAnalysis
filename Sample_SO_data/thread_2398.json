{
  "question" : {
    "question_id" : 79622876,
    "title" : "Spark Driver NoClassDefFoundError after upgrading Ivy to 2.5.3—how to fix without downgrading?",
    "body" : "<p>I recently upgraded the Apache Ivy package in my Spark container from version 2.5.1 to 2.5.2 and redeployed it inside an OpenShift cluster. The Spark master and workers start and run without issues. However, when I submit a job, the driver encounters a NoClassDefFoundError, which appears in the stderr file as shown below:</p>\n<pre><code>25/05/14 16:19:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n25/05/14 16:19:24 INFO SecurityManager: Changing view acls to: 1000700000\n25/05/14 16:19:24 INFO SecurityManager: Changing modify acls to: 1000700000\n25/05/14 16:19:24 INFO SecurityManager: Changing view acls groups to: \n25/05/14 16:19:24 INFO SecurityManager: Changing modify acls groups to: \n25/05/14 16:19:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: 1000700000; groups with view permissions: EMPTY; users with modify permissions: 1000700000; groups with modify permissions: EMPTY\n25/05/14 16:19:24 INFO Utils: Successfully started service 'Driver' on port 39873.\n25/05/14 16:19:24 INFO DriverWrapper: Driver address: 10.254.20.59:39873\n25/05/14 16:19:24 INFO WorkerWatcher: Connecting to worker spark://Worker@10.254.20.59:38753\nException in thread &quot;main&quot; java.lang.NoClassDefFoundError: org.apache.ivy.plugins.resolver.DependencyResolver\n    at org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:182)\n    at org.apache.spark.deploy.worker.DriverWrapper$.setupDependencies(DriverWrapper.scala:83)\n    at org.apache.spark.deploy.worker.DriverWrapper$.main(DriverWrapper.scala:58)\n    at org.apache.spark.deploy.worker.DriverWrapper.main(DriverWrapper.scala)\nCaused by: java.lang.ClassNotFoundException: org.apache.ivy.plugins.resolver.DependencyResolver\n    at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(Unknown Source)\n    at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(Unknown Source)\n    at java.base/java.lang.ClassLoader.loadClass(Unknown Source)\n    ... 4 more\n</code></pre>\n<p>I checked the /opt/spark/jars folder inside the Spark container and confirmed that ivy-2.5.2.jar is present, so it’s not missing. I also found this Jira ticket (<a href=\"https://issues.apache.org/jira/browse/SPARK-44968\" rel=\"nofollow noreferrer\">https://issues.apache.org/jira/browse/SPARK-44968</a>), which describes a Spark issue that arose when Ivy was upgraded to 2.5.2. That particular problem was resolved by downgrading to 2.5.1. While my issue is not identical, downgrading also resolves it in my case.</p>\n<p>I'm wondering if there's a way to fix this issue without downgrading, or if there’s an incompatibility between Ivy 2.5.2 and Spark.</p>\n<p>I’m fairly new to Spark and java, so I may be missing something obvious. Any guidance would be greatly appreciated!</p>\n<p>Thanks</p>\n",
    "tags" : [ "java", "apache-spark", "ivy" ],
    "owner" : {
      "account_id" : 20543025,
      "reputation" : 15,
      "user_id" : 15077538,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/0fe7a3572046cb3b56264f3f4d10d6b6?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Tarek Eid",
      "link" : "https://stackoverflow.com/users/15077538/tarek-eid"
    },
    "is_answered" : true,
    "view_count" : 52,
    "answer_count" : 1,
    "score" : 0,
    "last_activity_date" : 1747303997,
    "creation_date" : 1747296342,
    "link" : "https://stackoverflow.com/questions/79622876/spark-driver-noclassdeffounderror-after-upgrading-ivy-to-2-5-3-how-to-fix-withou",
    "content_license" : "CC BY-SA 4.0"
  },
  "answers" : [ {
    "answer_id" : 79623091,
    "question_id" : 79622876,
    "body" : "<p>You should check the Ivy Dependencies. IF that don't fix it try to Explicitly Add Dependency by manually adding an older JAR that contains it might work as a temporary solution.</p>\n",
    "score" : 0,
    "is_accepted" : true,
    "owner" : {
      "account_id" : 26661173,
      "reputation" : 141,
      "user_id" : 25504374,
      "user_type" : "registered",
      "profile_image" : "https://i.sstatic.net/gG2noSIz.jpg?s=256",
      "display_name" : "Tuhin Shaikh",
      "link" : "https://stackoverflow.com/users/25504374/tuhin-shaikh"
    },
    "creation_date" : 1747303997,
    "last_activity_date" : 1747303997,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "question_comments" : [ ],
  "answer_comments" : {
    "79623091" : [ {
      "comment_id" : 140441786,
      "post_id" : 79623091,
      "body" : "Thanks for your help, when i manually added the jar into spark, it fixed the problem.   I was using a a curl command to download the jar and then place it inside the jars folder with a script but the curl command was not working properly and wasnt downloading the correct file and then that file was being saved as ivy-2.5.2.jar so i never noticed that it was broken until i tried to open it.",
      "score" : 0,
      "owner" : {
        "account_id" : 20543025,
        "reputation" : 15,
        "user_id" : 15077538,
        "user_type" : "registered",
        "profile_image" : "https://www.gravatar.com/avatar/0fe7a3572046cb3b56264f3f4d10d6b6?s=256&d=identicon&r=PG&f=y&so-version=2",
        "display_name" : "Tarek Eid",
        "link" : "https://stackoverflow.com/users/15077538/tarek-eid"
      },
      "creation_date" : 1747727987,
      "content_license" : "CC BY-SA 4.0"
    } ]
  }
}