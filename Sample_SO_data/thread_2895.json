{
  "question" : {
    "question_id" : 79587269,
    "title" : "How to optimize subarray transformation for large inputs?",
    "body" : "<p>I have a problem where I need to select a contiguous subarray from a list of integers and add any integer z (positive or negative) to all elements in the subarray, such that the frequency of a target integer k is maximized in the list. The operation can only be done once.</p>\n<p><strong>Example 1:</strong></p>\n<pre><code>list = [2, 3, 2, 4, 3, 2]\nk = 2\nAnswer: 4\n</code></pre>\n<p><strong>Explanation:</strong></p>\n<p>We change the subarray [4, 3] and set <code>z = -2</code>, so the list becomes:</p>\n<pre><code>[2, 3, 2, (4-2), (3-2), 2] = [2, 3, 2, 2, 1, 2]\n</code></pre>\n<p>The frequency of <code>k = 2</code> in the final list is 4.</p>\n<p><strong>Example 2:</strong></p>\n<pre><code>list = [6, 4, 4, 5, 4, 4]\nk = 6\nAnswer: 5\n</code></pre>\n<p><strong>Example 3:</strong></p>\n<pre><code>list = [2, 5, 2, 5, 2]\nk = 2\nAnswer: 4\n</code></pre>\n<p><strong>Constraints:</strong></p>\n<pre><code>1 &lt;= n &lt;= 2 * 10^5\n\n1 &lt;= list[i] &lt;= 2 * 10^5\n\n1 &lt;= k &lt;= 10^5\n</code></pre>\n<p>Here is the code I have so far:</p>\n<pre><code>import java.util.*;\n\nclass Main {\n    public static int solve(List&lt;Integer&gt; list, int k) {\n        int n = list.size();\n        int baseCount = 0;\n\n        // Count frequency of `k` in the original list\n        for (int num : list) {\n            if (num == k) baseCount++;\n        }\n        \n        // Map to track the maximum gain from modifying the list\n        Map&lt;Integer, Integer&gt; maxGain = new HashMap&lt;&gt;();\n        Map&lt;Integer, Integer&gt; currentGain = new HashMap&lt;&gt;();\n\n        // Traverse the list to compute possible gains\n        for (int num : list) {\n            if (num == k) {\n                // If the number is `k`, we may reduce its frequency (no gain)\n                for (int x : currentGain.keySet()) {\n                    int gain = currentGain.get(x) - 1;\n                    currentGain.put(x, Math.max(gain, 0));\n                    maxGain.put(x, Math.max(maxGain.getOrDefault(x, 0), currentGain.get(x)));\n                }\n            } else {\n                // If the number is not `k`, calculate possible gain\n                int x = k - num;\n                int gain = currentGain.getOrDefault(x, 0) + 1;\n                currentGain.put(x, gain);\n                maxGain.put(x, Math.max(maxGain.getOrDefault(x, 0), gain));\n            }\n        }\n        \n        // Get the best possible gain\n        int best = 0;\n        for (int g : maxGain.values()) {\n            best = Math.max(best, g);\n        }\n\n        // Return the sum of original frequency and the best gain\n        return baseCount + best;\n    }\n\n    public static void main(String[] args) {\n        System.out.println(solve(Arrays.asList(2, 3, 2, 4, 3, 2), 2)); // Expected: 4\n        System.out.println(solve(Arrays.asList(6, 4, 4, 6, 4, 4), 6)); // Expected: 5\n        System.out.println(solve(Arrays.asList(2, 5, 2, 5, 2), 2));    // Expected: 4\n    }\n}\n</code></pre>\n<p><strong>Problem:</strong></p>\n<p>This was asked during an interview on Hackerrank ( I don't have a link for it to share), The solution works for smaller inputs, but when the input list size reaches n = 200,000, it starts to fail with timeout errors.</p>\n<p>I am looking for ways to reduce the time complexity of this solution so it can handle large inputs efficiently.</p>\n",
    "tags" : [ "java", "algorithm" ],
    "owner" : {
      "account_id" : 31187804,
      "reputation" : 794,
      "user_id" : 23993901,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/7417aaad0c8ece3fac44f06d05a8ba8b?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "CodeCrusader",
      "link" : "https://stackoverflow.com/users/23993901/codecrusader"
    },
    "is_answered" : true,
    "view_count" : 135,
    "answer_count" : 1,
    "score" : 4,
    "last_activity_date" : 1745503141,
    "creation_date" : 1745348499,
    "link" : "https://stackoverflow.com/questions/79587269/how-to-optimize-subarray-transformation-for-large-inputs",
    "content_license" : "CC BY-SA 4.0"
  },
  "answers" : [ {
    "answer_id" : 79587571,
    "question_id" : 79587269,
    "body" : "<p>The main slow point in the solution presented is the reduction of all the <code>currentGain</code> values by 1 each time a <code>k</code> is observed in the input.  That costs you O(<em>n</em><sup>2</sup>), whereas everything else is linear, so that is where you need to focus any algorithmic improvement effort.</p>\n<p>So ask yourself a couple questions:</p>\n<ul>\n<li><p>What if you have a run of consecutive <code>k</code>s?  Did you really need to update all the current gains for every one of those?</p>\n</li>\n<li><p>What if it turns out that there are no more appearances of a given <code>num</code> in the list at the point where you observe a <code>k</code>.  Do you really need to update the current gains for such <code>num</code>s?</p>\n</li>\n</ul>\n<p>In fact, the answer to both of those questions is &quot;no&quot;.  Consider this enhancement to your current code:</p>\n<ul>\n<li>As you process the list, keep a running count of the number of <code>k</code>s seen.  Updating  this count is the only thing you need to do when you process a <code>k</code>.  Use that count to support ...</li>\n<li>For each number <code>num</code> seen, keep track of the total number of <code>k</code>s that had been seen before last appearance of <code>num</code>.  These only need to be updated when you see <code>num</code>, so just one update of one such record per input item.</li>\n<li>For each <code>num</code> (other than <code>k</code>) seen, the previous two items allow you to compute the number of <code>k</code>s between the previous appearance of <code>num</code> and the current one.  This number offsets the gain (of 1) associated with the current appearance of <code>num</code>.</li>\n</ul>\n<p>That replaces the problematic quadratic update with a single <code>int</code> increment, at the cost of a little more bookkeeping (linear in space and time).  Asymptotic complexity drops to O(<em>n</em>).</p>\n<p>Here's the main working part of the result:</p>\n<pre><code>        Map&lt;Integer, Integer&gt; maxGain = new HashMap&lt;&gt;();\n        Map&lt;Integer, Integer&gt; currentGain = new HashMap&lt;&gt;();\n        Map&lt;Integer, Integer&gt; ksSeen = new HashMap&lt;&gt;();\n        int ks = 0;\n\n        // Traverse the list to compute possible gains\n        for (int num : list) {\n            if (num == k) {\n                ks += 1;\n            } else {\n                // == ks at the first appearance of each num:\n                int ksAtPreviousNum = ksSeen.getOrDefault(num, ks);\n\n                // 0 at the first appearance of each num\n                int ksSinceNum = ks - ksAtPreviousNum;\n\n                ksSeen.put(num, ks);\n\n                // gain for 'num' cannot be less than 1 when we're looking at a 'num'\n                int gain = Math.max(1, currentGain.getOrDefault(num, 0) + 1 - ksSinceNum);\n\n                currentGain.put(num, gain);\n                maxGain.put(num, Math.max(maxGain.getOrDefault(num, 0), gain));\n            }\n        }\n</code></pre>\n",
    "score" : 7,
    "is_accepted" : true,
    "owner" : {
      "account_id" : 2792262,
      "reputation" : 190832,
      "user_id" : 2402272,
      "user_type" : "registered",
      "accept_rate" : 85,
      "profile_image" : "https://www.gravatar.com/avatar/1182b1d5518a596d4e8cfe0567a65c4d?s=256&d=identicon&r=PG",
      "display_name" : "John Bollinger",
      "link" : "https://stackoverflow.com/users/2402272/john-bollinger"
    },
    "creation_date" : 1745362114,
    "last_activity_date" : 1745503141,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "question_comments" : [ {
    "comment_id" : 140359587,
    "post_id" : 79587269,
    "body" : "If your code works, but the only problem is that it times out for large inputs, the question might be a candidate for <a href=\"https://codereview.stackexchange.com/tour\">Code Review</a>. Before moving it, be sure and look at the requirements and standards there.",
    "score" : 0,
    "owner" : {
      "account_id" : 6606677,
      "reputation" : 1251,
      "user_id" : 5103317,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/c81d92487b054d7290b4f36562c0ee02?s=256&d=identicon&r=PG",
      "display_name" : "Old Dog Programmer",
      "link" : "https://stackoverflow.com/users/5103317/old-dog-programmer"
    },
    "creation_date" : 1745363911,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140359246,
    "post_id" : 79587269,
    "body" : "@JohnBollinger only because he&#39;s not removing the entries, if he would I would bet on map being faster if there are some ks.",
    "score" : 0,
    "owner" : {
      "account_id" : 6136413,
      "reputation" : 9587,
      "user_id" : 4785110,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/71b70abe72497023835a6dd8961b7c89?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "maraca",
      "link" : "https://stackoverflow.com/users/4785110/maraca"
    },
    "creation_date" : 1745353721,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140359242,
    "post_id" : 79587269,
    "body" : "@maraca, among the possibilities for large inputs is that all or nearly all of the possible keys are represented, so having to loop over substantially all the keys is not prevented by using a map.  BUT, that would probably reduce or overcome the speedup for small inputs, so my claim about all input sizes is probably wrong.",
    "score" : 0,
    "owner" : {
      "account_id" : 2792262,
      "reputation" : 190832,
      "user_id" : 2402272,
      "user_type" : "registered",
      "accept_rate" : 85,
      "profile_image" : "https://www.gravatar.com/avatar/1182b1d5518a596d4e8cfe0567a65c4d?s=256&d=identicon&r=PG",
      "display_name" : "John Bollinger",
      "link" : "https://stackoverflow.com/users/2402272/john-bollinger"
    },
    "creation_date" : 1745353535,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140359234,
    "post_id" : 79587269,
    "body" : "@JohnBollinger it&#39;s not that simple for his algorithm, it needs to be able to iterate over the defined keys if you use an array you need to loop over everything.",
    "score" : 0,
    "owner" : {
      "account_id" : 6136413,
      "reputation" : 9587,
      "user_id" : 4785110,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/71b70abe72497023835a6dd8961b7c89?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "maraca",
      "link" : "https://stackoverflow.com/users/4785110/maraca"
    },
    "creation_date" : 1745353284,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140359229,
    "post_id" : 79587269,
    "body" : "Have you considered using <code>int</code> arrays instead of <code>Map</code>s and <code>Integer</code>s?  Sure accessing a <code>HashMap</code> scales as <code>O(1)</code>, but it&#39;s still much slower than accessing an array.  I anticipate that switching to arrays would give a several-fold speedup for all input sizes.  And it might actually <i>save</i> memory for large inputs, because each <code>Integer</code> is much larger than an <code>int</code>.",
    "score" : 0,
    "owner" : {
      "account_id" : 2792262,
      "reputation" : 190832,
      "user_id" : 2402272,
      "user_type" : "registered",
      "accept_rate" : 85,
      "profile_image" : "https://www.gravatar.com/avatar/1182b1d5518a596d4e8cfe0567a65c4d?s=256&d=identicon&r=PG",
      "display_name" : "John Bollinger",
      "link" : "https://stackoverflow.com/users/2402272/john-bollinger"
    },
    "creation_date" : 1745353111,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "answer_comments" : {
    "79587571" : [ {
      "comment_id" : 140361752,
      "post_id" : 79587571,
      "body" : "Additional additional enhancement: replacing the three maps with arrays reduced the running time by an additional 60% (!) on my test workload, which features some maximum-size cases that take quadratic time in the original code. There was a strong improvement for each such replacement.  Even for <code>maxGain</code>, despite the fact that the final iteration over the <code>maxGain</code> array necessarily has many more iterations than the one over the original <code>maxGain</code> map could ever have.",
      "score" : 0,
      "owner" : {
        "account_id" : 2792262,
        "reputation" : 190832,
        "user_id" : 2402272,
        "user_type" : "registered",
        "accept_rate" : 85,
        "profile_image" : "https://www.gravatar.com/avatar/1182b1d5518a596d4e8cfe0567a65c4d?s=256&d=identicon&r=PG",
        "display_name" : "John Bollinger",
        "link" : "https://stackoverflow.com/users/2402272/john-bollinger"
      },
      "creation_date" : 1745417343,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140361651,
      "post_id" : 79587571,
      "body" : "As a minor additional enhancement, this also allows you to drop the initial computation of <code>baseCount</code>, as that result is the same as the final value of the running count of <code>k</code>s that is now computed separately.",
      "score" : 0,
      "owner" : {
        "account_id" : 2792262,
        "reputation" : 190832,
        "user_id" : 2402272,
        "user_type" : "registered",
        "accept_rate" : 85,
        "profile_image" : "https://www.gravatar.com/avatar/1182b1d5518a596d4e8cfe0567a65c4d?s=256&d=identicon&r=PG",
        "display_name" : "John Bollinger",
        "link" : "https://stackoverflow.com/users/2402272/john-bollinger"
      },
      "creation_date" : 1745416012,
      "content_license" : "CC BY-SA 4.0"
    } ]
  }
}