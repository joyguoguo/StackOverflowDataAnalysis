{
  "question" : {
    "question_id" : 79738462,
    "title" : "flink ConfluentRegistryAvroSerializationSchema not respecting registryConfigs",
    "body" : "<p>When I use in Apache Flink the KafkaRecordSerializationSchema with settings for the schema registry serialization , the registryConfigs settings are not taken in account</p>\n<p>settings like</p>\n<p>auto.register.schemas or avro.remove.java.properties</p>\n<pre class=\"lang-java prettyprint-override\"><code>package flink;\n\nimport example.avro.Car;\nimport org.apache.flink.api.common.eventtime.WatermarkStrategy;\nimport org.apache.flink.api.common.serialization.SimpleStringSchema;\nimport org.apache.flink.connector.base.DeliveryGuarantee;\nimport org.apache.flink.connector.kafka.sink.KafkaRecordSerializationSchema;\nimport org.apache.flink.connector.kafka.source.KafkaSource;\nimport org.apache.flink.connector.kafka.sink.KafkaSink;\nimport org.apache.flink.connector.kafka.source.enumerator.initializer.OffsetsInitializer;\nimport org.apache.flink.core.execution.CheckpointingMode;\nimport org.apache.flink.formats.avro.registry.confluent.ConfluentRegistryAvroSerializationSchema;\nimport org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n\nimport java.util.Map;\n\nimport static io.confluent.kafka.serializers.AbstractKafkaSchemaSerDeConfig.AUTO_REGISTER_SCHEMAS;\nimport static io.confluent.kafka.serializers.KafkaAvroSerializerConfig.AVRO_REMOVE_JAVA_PROPS_CONFIG;\n\npublic class Jobflink {\n\n  public static void main(String[] args) throws Exception {\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.enableCheckpointing(1000);\n    env.getCheckpointConfig().setCheckpointingConsistencyMode(CheckpointingMode.AT_LEAST_ONCE);\n\n    Map&lt;String, String&gt; schema_settings = Map.of(\n      AVRO_REMOVE_JAVA_PROPS_CONFIG, &quot;true&quot;,\n      AUTO_REGISTER_SCHEMAS, &quot;false&quot;\n    );\n\n    KafkaSink&lt;Car&gt; sink = KafkaSink.&lt;Car&gt;builder()\n      .setBootstrapServers(&quot;kafka-local:29092&quot;)\n      .setRecordSerializer(\n        KafkaRecordSerializationSchema.builder()\n          .setValueSerializationSchema(\n            ConfluentRegistryAvroSerializationSchema.forSpecific(\n              Car.class,\n              &quot;toto-value&quot;,\n              &quot;http://confluent-schema-registry-local:8081&quot;,\n              schema_settings))\n          .setTopic(&quot;toto&quot;)\n          .build())\n      .setDeliveryGuarantee(DeliveryGuarantee.AT_LEAST_ONCE)\n      .build();\n\n    env.execute();\n  }\n}\n</code></pre>\n<p>I also tried to set the confluent schema registry settings with setKafkaProducerConfig but it also do not work</p>\n<pre class=\"lang-java prettyprint-override\"><code>Properties properties = new Properties();\nproperties.setProperty(AVRO_REMOVE_JAVA_PROPS_CONFIG, &quot;true&quot;);\nproperties.setProperty(AUTO_REGISTER_SCHEMAS, &quot;false&quot;);\n\nKafkaSink&lt;Car&gt; sink = KafkaSink.&lt;Car&gt;builder()\n  .setBootstrapServers(&quot;kafka-local:29092&quot;)\n  .setKafkaProducerConfig(properties)\n  ...\n</code></pre>\n",
    "tags" : [ "java", "apache-flink", "avro", "confluent-schema-registry" ],
    "owner" : {
      "account_id" : 8283698,
      "reputation" : 1039,
      "user_id" : 6227500,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/e9be78c5f20b91a891a12dab02b23ca7?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "raphaelauv",
      "link" : "https://stackoverflow.com/users/6227500/raphaelauv"
    },
    "is_answered" : true,
    "view_count" : 125,
    "answer_count" : 1,
    "score" : 0,
    "last_activity_date" : 1755687282,
    "creation_date" : 1755507522,
    "link" : "https://stackoverflow.com/questions/79738462/flink-confluentregistryavroserializationschema-not-respecting-registryconfigs",
    "content_license" : "CC BY-SA 4.0"
  },
  "answers" : [ {
    "answer_id" : 79738988,
    "question_id" : 79738462,
    "body" : "<p>feature is not yet available , only SSL settings are working for the moment in registryConfigs</p>\n<p><a href=\"https://issues.apache.org/jira/browse/FLINK-33045\" rel=\"nofollow noreferrer\">https://issues.apache.org/jira/browse/FLINK-33045</a></p>\n<p>this is a working patch  -&gt; <strong>SafeConfluentRegistryAvroSerializationSchema</strong></p>\n<pre class=\"lang-java prettyprint-override\"><code>/*\n copy past of ConfluentRegistryAvroSerializationSchema\n\n but disable register of schema and call removeProperty(node, &quot;avro.java.string&quot;);\n */\npackage flink;\n\nimport com.fasterxml.jackson.databind.JsonNode;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.node.ArrayNode;\nimport com.fasterxml.jackson.databind.node.ObjectNode;\nimport io.confluent.kafka.schemaregistry.avro.AvroSchema;\nimport io.confluent.kafka.schemaregistry.client.CachedSchemaRegistryClient;\nimport io.confluent.kafka.schemaregistry.client.SchemaRegistryClient;\nimport io.confluent.kafka.schemaregistry.client.rest.exceptions.RestClientException;\nimport io.confluent.kafka.schemaregistry.utils.JacksonMapper;\nimport org.apache.avro.Schema;\nimport org.apache.avro.generic.GenericRecord;\nimport org.apache.avro.specific.SpecificRecord;\nimport org.apache.flink.formats.avro.AvroSerializationSchema;\nimport org.apache.flink.formats.avro.RegistryAvroSerializationSchema;\nimport org.apache.flink.formats.avro.SchemaCoder;\n\nimport javax.annotation.Nullable;\nimport java.io.DataInputStream;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.nio.ByteBuffer;\nimport java.util.Iterator;\nimport java.util.Map;\nimport java.util.Objects;\n\nimport static java.lang.String.format;\n\nclass ConfluentSchemaRegistryCoder implements SchemaCoder {\n\n    private final SchemaRegistryClient schemaRegistryClient;\n    private String subject;\n    private static final int CONFLUENT_MAGIC_BYTE = 0;\n\n    /**\n     * Creates {@link SchemaCoder} that uses provided {@link SchemaRegistryClient} to connect to\n     * schema registry.\n     *\n     * @param schemaRegistryClient client to connect schema registry\n     * @param subject subject of schema registry to produce\n     */\n    public ConfluentSchemaRegistryCoder(String subject, SchemaRegistryClient schemaRegistryClient) {\n        this.schemaRegistryClient = schemaRegistryClient;\n        this.subject = subject;\n    }\n\n    /**\n     * Creates {@link SchemaCoder} that uses provided {@link SchemaRegistryClient} to connect to\n     * schema registry.\n     *\n     * @param schemaRegistryClient client to connect schema registry\n     */\n    public ConfluentSchemaRegistryCoder(SchemaRegistryClient schemaRegistryClient) {\n        this.schemaRegistryClient = schemaRegistryClient;\n    }\n\n    @Override\n    public Schema readSchema(InputStream in) throws IOException {\n        DataInputStream dataInputStream = new DataInputStream(in);\n\n        if (dataInputStream.readByte() != 0) {\n            throw new IOException(&quot;Unknown data format. Magic number does not match&quot;);\n        } else {\n            int schemaId = dataInputStream.readInt();\n\n            try {\n                return schemaRegistryClient.getById(schemaId);\n            } catch (RestClientException e) {\n                throw new IOException(\n                        format(&quot;Could not find schema with id %s in registry&quot;, schemaId), e);\n            }\n        }\n    }\n\n    private static void removeProperty(JsonNode node, String propertyName) {\n        if (node.isObject()) {\n            ObjectNode objectNode = (ObjectNode) node;\n            objectNode.remove(propertyName);\n            Iterator&lt;JsonNode&gt; elements = objectNode.elements();\n            while (elements.hasNext()) {\n                removeProperty(elements.next(), propertyName);\n            }\n        } else if (node.isArray()) {\n            ArrayNode arrayNode = (ArrayNode) node;\n            Iterator&lt;JsonNode&gt; elements = arrayNode.elements();\n            while (elements.hasNext()) {\n                removeProperty(elements.next(), propertyName);\n            }\n        }\n    }\n\n    @Override\n    public void writeSchema(Schema schema, OutputStream out) throws IOException {\n        try {\n            ObjectMapper jsonMapper = JacksonMapper.INSTANCE;\n            JsonNode node = jsonMapper.readTree(schema.toString());\n            removeProperty(node, &quot;avro.java.string&quot;);\n            AvroSchema avroSchema = new AvroSchema(node.toString());\n            schema = avroSchema.rawSchema();\n\n            int registeredId = schemaRegistryClient.getId(subject, schema);\n            out.write(CONFLUENT_MAGIC_BYTE);\n            byte[] schemaIdBytes = ByteBuffer.allocate(4).putInt(registeredId).array();\n            out.write(schemaIdBytes);\n        } catch (RestClientException e) {\n            throw new IOException(&quot;Could not register schema in registry&quot;, e);\n        }\n    }\n}\n\n\nclass CachedSchemaCoderProvider implements SchemaCoder.SchemaCoderProvider {\n\n    private static final long serialVersionUID = 8610401613495438381L;\n    private final String subject;\n    private final String url;\n    private final int identityMapCapacity;\n    private final @Nullable Map&lt;String, ?&gt; registryConfigs;\n\n    CachedSchemaCoderProvider(String url, int identityMapCapacity) {\n        this(null, url, identityMapCapacity, null);\n    }\n\n    CachedSchemaCoderProvider(\n            @Nullable String subject,\n            String url,\n            int identityMapCapacity,\n            @Nullable Map&lt;String, ?&gt; registryConfigs) {\n        this.subject = subject;\n        this.url = Objects.requireNonNull(url);\n        this.identityMapCapacity = identityMapCapacity;\n        this.registryConfigs = registryConfigs;\n    }\n\n    @Override\n    public SchemaCoder get() {\n        return new ConfluentSchemaRegistryCoder(\n                this.subject,\n                new CachedSchemaRegistryClient(url, identityMapCapacity, registryConfigs));\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (this == o) {\n            return true;\n        }\n        if (o == null || getClass() != o.getClass()) {\n            return false;\n        }\n        CachedSchemaCoderProvider that = (CachedSchemaCoderProvider) o;\n        return identityMapCapacity == that.identityMapCapacity\n                &amp;&amp; Objects.equals(subject, that.subject)\n                &amp;&amp; url.equals(that.url)\n                &amp;&amp; Objects.equals(registryConfigs, that.registryConfigs);\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(subject, url, identityMapCapacity, registryConfigs);\n    }\n}\n\n\n/**\n * Serialization schema that serializes to Avro binary format that uses Confluent Schema Registry.\n *\n * @param &lt;T&gt; the type to be serialized\n */\npublic class SafeConfluentRegistryAvroSerializationSchema&lt;T&gt;\n        extends RegistryAvroSerializationSchema&lt;T&gt; {\n\n    private static final int DEFAULT_IDENTITY_MAP_CAPACITY = 1000;\n\n    private static final long serialVersionUID = -1771641202177852775L;\n\n    /**\n     * Creates a Avro serialization schema.\n     *\n     * @param recordClazz class to serialize. Should be either {@link SpecificRecord} or {@link\n     *     GenericRecord}.\n     * @param schema writer's Avro schema. Should be provided if recordClazz is {@link\n     *     GenericRecord}\n     * @param schemaCoderProvider provider for schema coder that writes the writer schema to\n     *     Confluent Schema Registry\n     */\n    private SafeConfluentRegistryAvroSerializationSchema(\n            Class&lt;T&gt; recordClazz,\n            Schema schema,\n            SchemaCoder.SchemaCoderProvider schemaCoderProvider) {\n        super(recordClazz, schema, schemaCoderProvider);\n    }\n\n    /**\n     * Creates {@link AvroSerializationSchema} that produces byte arrays that were generated from\n     * Avro schema and writes the writer schema to Confluent Schema Registry.\n     *\n     * @param tClass the type to be serialized\n     * @param subject subject of schema registry to produce\n     * @param schemaRegistryUrl URL of schema registry to connect\n     * @return serialized record\n     */\n    public static &lt;T extends SpecificRecord&gt;\n    SafeConfluentRegistryAvroSerializationSchema&lt;T&gt; forSpecific(\n            Class&lt;T&gt; tClass, String subject, String schemaRegistryUrl) {\n        return forSpecific(tClass, subject, schemaRegistryUrl, null);\n    }\n\n    /**\n     * Creates {@link AvroSerializationSchema} that produces byte arrays that were generated from\n     * Avro schema and writes the writer schema to Confluent Schema Registry.\n     *\n     * @param tClass the type to be serialized\n     * @param subject subject of schema registry to produce\n     * @param schemaRegistryUrl URL of schema registry to connect\n     * @param registryConfigs map with additional schema registry configs (for example SSL\n     *     properties)\n     * @return serialized record\n     */\n    public static &lt;T extends SpecificRecord&gt;\n    SafeConfluentRegistryAvroSerializationSchema&lt;T&gt; forSpecific(\n            Class&lt;T&gt; tClass,\n            String subject,\n            String schemaRegistryUrl,\n            @Nullable Map&lt;String, ?&gt; registryConfigs) {\n        return new SafeConfluentRegistryAvroSerializationSchema&lt;&gt;(\n                tClass,\n                null,\n                new CachedSchemaCoderProvider(\n                        subject,\n                        schemaRegistryUrl,\n                        DEFAULT_IDENTITY_MAP_CAPACITY,\n                        registryConfigs));\n    }\n\n    /**\n     * Creates {@link AvroSerializationSchema} that produces byte arrays that were generated from\n     * Avro schema and writes the writer schema to Confluent Schema Registry.\n     *\n     * @param subject subject of schema registry to produce\n     * @param schema schema that will be used for serialization\n     * @param schemaRegistryUrl URL of schema registry to connect\n     * @return serialized record\n     */\n    public static SafeConfluentRegistryAvroSerializationSchema&lt;GenericRecord&gt; forGeneric(\n            String subject, Schema schema, String schemaRegistryUrl) {\n        return forGeneric(subject, schema, schemaRegistryUrl, null);\n    }\n\n    /**\n     * Creates {@link AvroSerializationSchema} that produces byte arrays that were generated from\n     * Avro schema and writes the writer schema to Confluent Schema Registry.\n     *\n     * @param subject subject of schema registry to produce\n     * @param schema schema that will be used for serialization\n     * @param schemaRegistryUrl URL of schema registry to connect\n     * @param registryConfigs map with additional schema registry configs (for example SSL\n     *     properties)\n     * @return serialized record\n     */\n    public static SafeConfluentRegistryAvroSerializationSchema&lt;GenericRecord&gt; forGeneric(\n            String subject,\n            Schema schema,\n            String schemaRegistryUrl,\n            @Nullable Map&lt;String, ?&gt; registryConfigs) {\n        return new SafeConfluentRegistryAvroSerializationSchema&lt;&gt;(\n                GenericRecord.class,\n                schema,\n                new CachedSchemaCoderProvider(\n                        subject,\n                        schemaRegistryUrl,\n                        DEFAULT_IDENTITY_MAP_CAPACITY,\n                        registryConfigs));\n    }\n}\n</code></pre>\n",
    "score" : 0,
    "is_accepted" : true,
    "owner" : {
      "account_id" : 8283698,
      "reputation" : 1039,
      "user_id" : 6227500,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/e9be78c5f20b91a891a12dab02b23ca7?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "raphaelauv",
      "link" : "https://stackoverflow.com/users/6227500/raphaelauv"
    },
    "creation_date" : 1755532607,
    "last_activity_date" : 1755625094,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "question_comments" : [ ],
  "answer_comments" : { }
}