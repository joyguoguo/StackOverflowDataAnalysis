{
  "question" : {
    "question_id" : 79567747,
    "title" : "FastQC Stalling Under Heavy System Load (JRE/JVM Issue)",
    "body" : "<p>Terrible title, and I'll update if a more effective way of asking can be suggested.</p>\n<h1>Problem</h1>\n<p>We're running a bioinformatics pipeline that uses FastQC for quality control. The pipeline is written in Nextflow and uses Slurm for job management. Originally, FastQC would take 5-30min to run on a set of samples. However, after updates allowed for significantly greater job parallelization, FastQC will now take up to 15hrs to finish.</p>\n<p>The jobs don't die, they don't fail, they just kinda hang out not really running. This does seem to occur during file-reading operations (based on the log files from FastQC).</p>\n<p>We're pretty sure this is a JVM/JRE issue, we're just not sure how/why (or even how to google it well).</p>\n<h1>Repeatability</h1>\n<p>This doesn't seem to depend on which samples are used.<br />\nIt's very repeatable - reduce the Slurm allocation and runtimes come back down, increase the allocations and runtimes go up. We've demonstrated the impact on the same and different sets of samples.<br />\nAs far as we can tell, it doesn't impact any other processes (trimGalore, several Sentieon tools, RNAseQC, RSeQC).</p>\n<h1>Checks</h1>\n<p>Nextflow logs indicate the we're allocating plenty of resources to each task - currently using ~40% of the allocated RAM, and it will never go over 50% CPU usage (FastQC is single-threaded, we allocated 2 just to be sure).</p>\n<p>We've checked with our cluster IT - the system is not under excessively heavy compute load, the network is below 50% utilization, and disks I/O is below 50% utilization.</p>\n<p>We've attempted to increase the ulimit for the server and for the user - no impact.</p>\n<p><a href=\"https://github.com/s-andrews/FastQC/issues/151\" rel=\"nofollow noreferrer\">Github Issue</a></p>\n<h1>Setting</h1>\n<p>Nextflow 24.04.2.5914<br />\nSlurm<br />\nUbuntu 22.04<br />\nOpenJDK version &quot;21-internal&quot;<br />\nOpenJDK Runtime Environment (build 21-internal-adhoc.conda.src)<br />\nOpenJDK 64-Bit Server VM (build 21-internal-adhoc.conda.src, mixed mode, sharing)</p>\n<h1>Update 1</h1>\n<p>To clarify, there was no system update.<br />\nThe change was to resource requests from slurm for other processes, allowing significantly greater process concurrency.</p>\n<p>The Nextflow run-directory is clean. There's nothing abnormal in the <code>.command.{begin,err,log,out,etc}</code> (I assume b/c the jobs aren't failing).</p>\n<p>The Nextflow output files match ones run before any changes were made, same for log files from <code>fastqc</code> itself.</p>\n<p>Nextflow setup:</p>\n<pre><code>withName: 'run_fastqc1|run_fastqc2' {\n  executor = 'slurm'\n  queue = 'LocalQ'\n  errorStrategy = 'retry'\n  maxRetries = 2\n  cpus = 2\n  memory = { 1.GB * 2 ** (task.attempt - 1)}\n  conda.enabled = true\n  process.conda = &quot;$conda_envs/my_env&quot;\n}\n</code></pre>\n<p>FastQC command:</p>\n<pre><code>fastqc --nogroup -f fastq --threads $cpus -o /my/drive/my/path/ fastq_R1.fastq.gz fastq_R2.fastq.gz\n</code></pre>\n",
    "tags" : [ "java", "jvm", "bioinformatics", "nextflow" ],
    "owner" : {
      "account_id" : 13360806,
      "reputation" : 67,
      "user_id" : 9642895,
      "user_type" : "registered",
      "profile_image" : "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/s256-rj/photo.jpg",
      "display_name" : "GilChrist19",
      "link" : "https://stackoverflow.com/users/9642895/gilchrist19"
    },
    "is_answered" : false,
    "view_count" : 118,
    "answer_count" : 0,
    "score" : 0,
    "last_activity_date" : 1744539794,
    "creation_date" : 1744328837,
    "link" : "https://stackoverflow.com/questions/79567747/fastqc-stalling-under-heavy-system-load-jre-jvm-issue",
    "content_license" : "CC BY-SA 4.0"
  },
  "answers" : [ ],
  "question_comments" : [ {
    "comment_id" : 140414500,
    "post_id" : 79567747,
    "body" : "Just to close the circle from my end, I&#39;ve been reassigned and won&#39;t be looking into this further.",
    "score" : 1,
    "owner" : {
      "account_id" : 13360806,
      "reputation" : 67,
      "user_id" : 9642895,
      "user_type" : "registered",
      "profile_image" : "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/s256-rj/photo.jpg",
      "display_name" : "GilChrist19",
      "link" : "https://stackoverflow.com/users/9642895/gilchrist19"
    },
    "creation_date" : 1746919096,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140358115,
    "post_id" : 79567747,
    "body" : "We are reading from a network drive (but not saturating the disk I/O or bandwidth, we&#39;ve had IT monitoring). We&#39;re using a TMPDIR for intermediate files (local drive, NVMe protocol). Then we put finished analyses on the network drive. You&#39;re right, we&#39;re handling it with multiple processes currently. This has been pushed lower on my todo, so I&#39;ll test and return when I can.",
    "score" : 1,
    "owner" : {
      "account_id" : 13360806,
      "reputation" : 67,
      "user_id" : 9642895,
      "user_type" : "registered",
      "profile_image" : "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/s256-rj/photo.jpg",
      "display_name" : "GilChrist19",
      "link" : "https://stackoverflow.com/users/9642895/gilchrist19"
    },
    "creation_date" : 1745332945,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140358093,
    "post_id" : 79567747,
    "body" : "Sorry for the delayed reply - your <code>process.XXX</code> suggestion was spot on, thank you. Silly mistake on my part.",
    "score" : 0,
    "owner" : {
      "account_id" : 13360806,
      "reputation" : 67,
      "user_id" : 9642895,
      "user_type" : "registered",
      "profile_image" : "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/s256-rj/photo.jpg",
      "display_name" : "GilChrist19",
      "link" : "https://stackoverflow.com/users/9642895/gilchrist19"
    },
    "creation_date" : 1745332574,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140334928,
    "post_id" : 79567747,
    "body" : "Doing this would let you run the workflow somewhere using fast disk (e.g. TMPDIR), then when each task finishes, it would publish the files to <code>&#47;my&#47;drive</code>. The difference would be that instead of having multiple processes (from multiple nodes, potentially) writing to <code>&#47;my&#47;drive</code>, only the <code>nextflow</code> process would have this responsibility. File publishing is asynchronous.",
    "score" : 0,
    "owner" : {
      "account_id" : 391289,
      "reputation" : 55137,
      "user_id" : 751863,
      "user_type" : "registered",
      "accept_rate" : 100,
      "profile_image" : "https://i.sstatic.net/Bb6fb.png?s=256",
      "display_name" : "Steve",
      "link" : "https://stackoverflow.com/users/751863/steve"
    },
    "creation_date" : 1744674605,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140334915,
    "post_id" : 79567747,
    "body" : "Try setting <code>process.executor = &#39;slurm&#39;</code> instead. Then you could set <code>process.queue = &#39;LocalQ&#39;</code> and override it in the process selectors as necessary. So I wonder if this has something to do with how/where the results are being written to. Are you reading from <code>&#47;my&#47;drive</code> and writing to it? Is <code>&#47;my&#47;drive</code> fast or slow disk? Even if you run from multiple locations, you should still write the output files to the process working directory. Writing to directories outside of this will break <code>-resume</code> and portability etc. Use <code>publishDir</code> with  <code>mode: &#39;copy&#39;</code>. You can even parameterise the<code>path</code>.",
    "score" : 0,
    "owner" : {
      "account_id" : 391289,
      "reputation" : 55137,
      "user_id" : 751863,
      "user_type" : "registered",
      "accept_rate" : 100,
      "profile_image" : "https://i.sstatic.net/Bb6fb.png?s=256",
      "display_name" : "Steve",
      "link" : "https://stackoverflow.com/users/751863/steve"
    },
    "creation_date" : 1744673948,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140333484,
    "post_id" : 79567747,
    "body" : "We usually run batches of 12 samples - 12 <code>FastQC</code> processes with 12 <code>TrimGalore</code> processes, which finishes and beings STAR processes, which finish and begin de-duplication processes, etc etc.   We don&#39;t see this issue with 2-4 samples (my testing handful).  I&#39;ve never seen this running a single instance of <code>FastQC</code>.  So it&#39;s definitely an issue of scale, I just can&#39;t figure out where. Other processes (<code>TrimGalore</code>, <code>STAR</code>, etc) don&#39;t demonstrate this behavior",
    "score" : 0,
    "owner" : {
      "account_id" : 13360806,
      "reputation" : 67,
      "user_id" : 9642895,
      "user_type" : "registered",
      "profile_image" : "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/s256-rj/photo.jpg",
      "display_name" : "GilChrist19",
      "link" : "https://stackoverflow.com/users/9642895/gilchrist19"
    },
    "creation_date" : 1744644236,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140333464,
    "post_id" : 79567747,
    "body" : "<code>publishDir</code> only works when files remain within the Nextflow directory - we&#39;re running from different places, so we have to do (or have chosen to do) our own file handling.",
    "score" : 0,
    "owner" : {
      "account_id" : 13360806,
      "reputation" : 67,
      "user_id" : 9642895,
      "user_type" : "registered",
      "profile_image" : "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/s256-rj/photo.jpg",
      "display_name" : "GilChrist19",
      "link" : "https://stackoverflow.com/users/9642895/gilchrist19"
    },
    "creation_date" : 1744643918,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140333433,
    "post_id" : 79567747,
    "body" : "I don&#39;t think <code>conda.enabeled</code> matters within the process selector or within the environment profile. You&#39;re right, it is more appropriate within the environment profile, so it applies to all processes you run together.    The slurm queue must remain within the process selector - it&#39;s not respected within the environment profile (no idea why, easy workaround).    <code>cpus = 1</code> is fine, or fine as 2. <code>FastQC</code> is single-threaded per file, so you&#39;re right I&#39;m over-allocating.    You&#39;re memory statement is a different scaling than I want. Valid only when <code>maxRetries &lt; 3</code>.",
    "score" : 0,
    "owner" : {
      "account_id" : 13360806,
      "reputation" : 67,
      "user_id" : 9642895,
      "user_type" : "registered",
      "profile_image" : "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/s256-rj/photo.jpg",
      "display_name" : "GilChrist19",
      "link" : "https://stackoverflow.com/users/9642895/gilchrist19"
    },
    "creation_date" : 1744643378,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140326838,
    "post_id" : 79567747,
    "body" : "It might be worth including a minimal working example with just the FastQC <code>process</code> and <code>workflow</code> blocks, as well as the configuration you are using. When you run your workflow, approximately how many FastQC jobs are submitted? I guess my question is, what does it take to start seeing the slowdown?",
    "score" : 0,
    "owner" : {
      "account_id" : 391289,
      "reputation" : 55137,
      "user_id" : 751863,
      "user_type" : "registered",
      "accept_rate" : 100,
      "profile_image" : "https://i.sstatic.net/Bb6fb.png?s=256",
      "display_name" : "Steve",
      "link" : "https://stackoverflow.com/users/751863/steve"
    },
    "creation_date" : 1744426764,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140326830,
    "post_id" : 79567747,
    "body" : "So the &#39;updates&#39; are just changes you made to your resource requests in your nextflow.config. Try moving <code>conda.enabled = true</code> to outside of your process selector. I would put this line at the top of your nextflow.config. On the following line set <code>conda.cacheDir = &#47;some&#47;path&#39;</code>. Then, you can replace <code>process.conda = &quot;$conda_envs&#47;my_env&quot;</code> with <code>conda = &#39;0.12.1&#39;</code>. Use the version you want. Use <code>cpus = 1</code> and memory can simply be: <code>memory = { 1.GB * task.attempt }</code>. I would also simplify the command to something like <code>fastqc -q ${reads}</code>. Avoid <code>-o</code> here, use the <code>publishDir</code> directive instead.",
    "score" : 0,
    "owner" : {
      "account_id" : 391289,
      "reputation" : 55137,
      "user_id" : 751863,
      "user_type" : "registered",
      "accept_rate" : 100,
      "profile_image" : "https://i.sstatic.net/Bb6fb.png?s=256",
      "display_name" : "Steve",
      "link" : "https://stackoverflow.com/users/751863/steve"
    },
    "creation_date" : 1744426104,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140326729,
    "post_id" : 79567747,
    "body" : "@Steve -  Question updated.  There were no system/software updates, only resource requests for other processes. This allowed more tasks to run at the same time, which hasn&#39;t impacted the runtime of other tasks, just <code>FastQC</code>.  It is run inside a conda env, and java is installed within that env as well.",
    "score" : 0,
    "owner" : {
      "account_id" : 13360806,
      "reputation" : 67,
      "user_id" : 9642895,
      "user_type" : "registered",
      "profile_image" : "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/s256-rj/photo.jpg",
      "display_name" : "GilChrist19",
      "link" : "https://stackoverflow.com/users/9642895/gilchrist19"
    },
    "creation_date" : 1744420323,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140322802,
    "post_id" : 79567747,
    "body" : "So something changed after some system updates? Do you have FastQC logs from before the updates to compare with? Can you share the relevant Nextflow code and configuration to show how you are running <code>fastqc</code>? Do the task logs (<code>.command.err</code>, <code>.command.out</code>, <code>.command.log</code>) reveal any errors or log anything java related? Some node/cluster specific configuration might be being &#39;picked up&#39; at runtime. Are you running <code>fastqc</code> in a Conda environment?",
    "score" : 0,
    "owner" : {
      "account_id" : 391289,
      "reputation" : 55137,
      "user_id" : 751863,
      "user_type" : "registered",
      "accept_rate" : 100,
      "profile_image" : "https://i.sstatic.net/Bb6fb.png?s=256",
      "display_name" : "Steve",
      "link" : "https://stackoverflow.com/users/751863/steve"
    },
    "creation_date" : 1744335954,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "answer_comments" : { }
}