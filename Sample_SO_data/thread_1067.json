{
  "question" : {
    "question_id" : 79747261,
    "title" : "Apache Flink FileSink compaction extremely slow with many hot buckets/paths",
    "body" : "<p>I have a Flink ETL job that reads from ~13 Kafka topics and writes data into HDFS using a FileSink with compaction enabled.</p>\n<p>Right now, we have around 40 different output paths (buckets), and roughly 30+ of them are hot (receiving data constantly).</p>\n<p>The problem: compaction is extremely slow. When the system is busy, it can take ~7 minutes to compact pending files. This is causing significant delays downstream.</p>\n<p>From what I understand, the FileSink compactor coordinator runs with a fixed parallelism of 1, and it seems to be a bottleneck when managing many active paths.</p>\n<p>The job starts with a KafkaDataSource that reads from all 13 Kafka topics, with parallelism set to number of task slots × replicas to maximize throughput. The data then flows through the main DAG, which performs filtering, processing, and enrichment, and writes to the FileSink, also running at number of task slots × replicas parallelism. After the writers, the CompactorCoordinator stage appears in the DAG with a fixed parallelism of 1, responsible for orchestrating compaction tasks. Finally, the CompactorOperator executes the actual file compactions in parallel, again using number of task slots × replicas for its parallelism.</p>\n<p>Is there any way to parallelize or scale the compactor coordinator in Flink’s FileSink?</p>\n<p>If not, what are the best practices to speed up compaction when you have many hot buckets?</p>\n",
    "tags" : [ "java", "apache-kafka", "hdfs", "apache-flink", "etl" ],
    "owner" : {
      "account_id" : 30419632,
      "reputation" : 1,
      "user_id" : 23311390,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/1fddfc045fd8853fb8ff36bbc19caff7?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Hello",
      "link" : "https://stackoverflow.com/users/23311390/hello"
    },
    "is_answered" : false,
    "view_count" : 87,
    "answer_count" : 0,
    "score" : 0,
    "last_activity_date" : 1756237276,
    "creation_date" : 1756237276,
    "link" : "https://stackoverflow.com/questions/79747261/apache-flink-filesink-compaction-extremely-slow-with-many-hot-buckets-paths",
    "content_license" : "CC BY-SA 4.0"
  },
  "answers" : [ ],
  "question_comments" : [ {
    "comment_id" : 140740593,
    "post_id" : 79747261,
    "body" : "Can it affect reading capabilities and compactions?",
    "score" : 0,
    "owner" : {
      "account_id" : 30419632,
      "reputation" : 1,
      "user_id" : 23311390,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/1fddfc045fd8853fb8ff36bbc19caff7?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Hello",
      "link" : "https://stackoverflow.com/users/23311390/hello"
    },
    "creation_date" : 1758052596,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140740592,
    "post_id" : 79747261,
    "body" : "Not at all. Not all sink subtasks get roughly the same amount of data — each sub-sink can vary: one can be 1 MB per second, another 5 MB per second, and another 100 KB per second. When compaction is disabled, I get too many small files. I have a size threshold of 128 MB and a time threshold of 5 minutes. Regarding the question of the number of partitions: right now it is 13 topics with 96 partitions in total. Each topic has a different throughput — one can be 1 MB and another 10 MB, etc. So no, the data rate across partitions and topics is not the same at all.",
    "score" : 0,
    "owner" : {
      "account_id" : 30419632,
      "reputation" : 1,
      "user_id" : 23311390,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/1fddfc045fd8853fb8ff36bbc19caff7?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Hello",
      "link" : "https://stackoverflow.com/users/23311390/hello"
    },
    "creation_date" : 1758052582,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140696411,
    "post_id" : 79747261,
    "body" : "How many total Kafka partitions are you reading from, across all topics? And is the data rate per partition roughly equal across all topics?",
    "score" : 1,
    "owner" : {
      "account_id" : 82425,
      "reputation" : 9560,
      "user_id" : 231762,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/b5d195db362831baf779f0e4b491c68a?s=256&d=identicon&r=PG",
      "display_name" : "kkrugler",
      "link" : "https://stackoverflow.com/users/231762/kkrugler"
    },
    "creation_date" : 1756309407,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140696406,
    "post_id" : 79747261,
    "body" : "What happened when you didn&#39;t have compaction enabled? Were you getting too many small files? And if so, what is your checkpoint interval and rolling policy for the sink?",
    "score" : 1,
    "owner" : {
      "account_id" : 82425,
      "reputation" : 9560,
      "user_id" : 231762,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/b5d195db362831baf779f0e4b491c68a?s=256&d=identicon&r=PG",
      "display_name" : "kkrugler",
      "link" : "https://stackoverflow.com/users/231762/kkrugler"
    },
    "creation_date" : 1756309371,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140696404,
    "post_id" : 79747261,
    "body" : "Are the sink sub-tasks all receiving roughly the same amount of data per interval?",
    "score" : 1,
    "owner" : {
      "account_id" : 82425,
      "reputation" : 9560,
      "user_id" : 231762,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/b5d195db362831baf779f0e4b491c68a?s=256&d=identicon&r=PG",
      "display_name" : "kkrugler",
      "link" : "https://stackoverflow.com/users/231762/kkrugler"
    },
    "creation_date" : 1756309327,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "answer_comments" : { }
}