{
  "question" : {
    "question_id" : 79674700,
    "title" : "Taylor Series in Java using float",
    "body" : "<p>I am implementing a method <code>berechneCosinus(float x, int ordnung)</code> in Java that should approximate the cosine of x using the Taylor series up to the specified order.</p>\n<p>My questions:</p>\n<p>Can I optimize the computation inside the method, without changing the signatures, in order to exactly match the given test results?</p>\n<p>Here is what I have so far:</p>\n<pre class=\"lang-java prettyprint-override\"><code>public class Taylor {\n\n    public float berechneFak(float x) {\n        if (x &lt;= 1) return 1.0f;\n        int n = Math.round(x);\n        float fak = 1.0f;\n        for (int i = 2; i &lt;= n; i++) {\n            fak *= i;\n        }\n        return fak;\n    }\n\n    public float berechneCosinus(float x, int ordnung) {\n        float pi = 3.14159265f;\n        float zweiPi = 2.0f * pi;\n\n        x = x % zweiPi;\n        if (x &gt; pi) x -= zweiPi;\n        else if (x &lt; -pi) x += zweiPi;\n\n        if (ordnung == 0) return 0.0f;\n\n        int anzahlTerme = (ordnung + 1) / 2;\n\n        float summe = 0.0f;\n        float term = 1.0f;  \n\n        for (int i = 0; i &lt; anzahlTerme; i++) {\n            int n = i * 2; \n            if (i &gt; 0) {\n                term *= -x * x / ((n - 1) * n);  \n            }\n            summe += term;\n        }\n        return summe;\n    }\n}\n</code></pre>\n<p>This is the assignment:</p>\n<pre class=\"lang-java prettyprint-override\"><code>public class Taylor {\n\n\n  public float berechneFak(float x) {\n    // insert code here!\n    // drandenken: Vorlesung!\n    return 0.0f;\n  }\n\n\n  public float berechneCosinus(float x, int ordnung) {\n    float acc = 0.0f;\n    // Ihr Code hierher!\n    return acc;\n  }\n\n}\n</code></pre>\n<p>Test case:</p>\n<p><img src=\"https://i.sstatic.net/4MW8WiLj.png\" alt=\"Testfälle\" /></p>\n<p>Expected / received result:</p>\n<p><img src=\"https://i.sstatic.net/oqtJlMA4.png\" alt=\"Erwartet / Erhaltenes Ergebnis\" /></p>\n<p>I implemented the cosine calculation method using the Taylor series and normalized x to the interval [−π,π]. However, the results slightly differ from the expected values in some test cases. Since I’m not allowed to change the method signatures and can only work with floats, I’m looking for tips on how to improve the accuracy.</p>\n<p>Here is a minimal reproducible example:</p>\n<pre class=\"lang-java prettyprint-override\"><code>public class Taylor {\n    public float berechneCosinus(float x, int ordnung) {\n        if (ordnung == 0) return 0.0f;\n\n        float sum = 0.0f;\n        float term = 1.0f;\n        for (int i = 0; i &lt; (ordnung + 1) / 2; i++) {\n            int n = 2 * i;\n            if (i &gt; 0)\n                term *= -x * x / ((n - 1) * n);\n            sum += term;\n        }\n        return sum;\n    }\n\n    public static void main(String[] args) {\n        Taylor t = new Taylor();\n        float x = 3.14159265f; // approx. PI\n        System.out.printf(&quot;%.6f\\n&quot;, t.berechneCosinus(x, 13));\n        System.out.printf(&quot;%.6f\\n&quot;, t.berechneCosinus(x, 14));\n    }\n}\n</code></pre>\n<p>The actual output is:</p>\n<pre class=\"lang-none prettyprint-override\"><code>-0.999900  \n-0.999900  \n</code></pre>\n<p>The expected output should be:</p>\n<pre class=\"lang-none prettyprint-override\"><code>-0.999899  \n-0.999899\n</code></pre>\n<p>I'm aware of the limitations with floating point; the problem is that the tests check for exactly -0.999899. I'm wondering if it's possible to restructure the calculation to get the expected result. Nonetheless I'm going to ask my prof. Could be also possible that there is an error/mistake in the testing code.</p>\n<h2>Solution</h2>\n<p>Thanks for all the comments and suggestions; I appreciate all the efforts you guys made so far. I asked my prof today and he gave me a hint so I got the answer now.</p>\n<p>I can't say why we should do it like the way he wants it but here is the final code:</p>\n<pre class=\"lang-java prettyprint-override\"><code>public class Taylor {\n\n    public float berechneFak(float x) {\n        float produkt = 1.0f;\n        for (int i = 2; i &lt;= x; i++) {\n            produkt *= i;\n        }\n        return produkt;\n    }\n\n    public float berechneCosinus(float x, int ordnung) {\n        float acc = 0.0f;\n        float a = 1.0f;\n        for (int i = 0; i &lt; ordnung; i += 2) {\n            acc += (a / berechneFak(i)) * Math.pow(x, i);\n            a *= (-1);\n        }\n        return acc;\n    }\n    public static void main(String[] args) {\n        Taylor t = new Taylor();\n        float x = 3.14159265f;\n        for (int ordnung = 0; ordnung &lt; 15; ordnung++) {\n            System.out.printf(&quot;%.6f%n&quot;, t.berechneCosinus(x, ordnung));\n        }\n    }\n}\n</code></pre>\n",
    "tags" : [ "java", "floating-point", "numerical-methods", "approximation", "taylor-series" ],
    "owner" : {
      "account_id" : 42654570,
      "reputation" : 19,
      "user_id" : 30858651,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/900927d77a370d93cf49396868012615?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Andre",
      "link" : "https://stackoverflow.com/users/30858651/andre"
    },
    "is_answered" : true,
    "view_count" : 253,
    "closed_date" : 1765121483,
    "answer_count" : 3,
    "score" : -3,
    "last_activity_date" : 1765050792,
    "creation_date" : 1750533260,
    "link" : "https://stackoverflow.com/questions/79674700/taylor-series-in-java-using-float",
    "closed_reason" : "Needs more focus"
  },
  "answers" : [ {
    "answer_id" : 79686333,
    "question_id" : 79674700,
    "body" : "<p>I pity the OP lumbered with such a silly and inflexible accuracy target for their implementation as shown above. They don't deserve the negative votes that this question got but their professor certainly does!</p>\n<p>By way of introduction I should point out that we would not normally approximate sin(x) over such a wide range as 0-pi because to do so violates one of the important heuristics generally used in series expansions used to approximate functions in computing namely:</p>\n<ol>\n<li>Each successive term in the series satisfies |a<sub>n</sub>x<sup>n</sup>| &gt; |a<sub>n+1</sub>x<sup>n+1</sup>|</li>\n<li>Terms are added together smallest to largest to control rounding error.</li>\n</ol>\n<p>IOW each successive term is a smaller correction to the sum than its predecessor and they are typically summed from highest order term first usually by Horner's method which lends itself to modern computers FMA instructions which can process a combined multiply and add with only one rounding each machine cycle.</p>\n<p>To illustrate how range reduction helps I the test code below does the original range test with different numbers of terms N for argument limits of <code>pi</code>, <code>pi/2</code> and <code>pi/4</code>. The first case evaluation for <code>pi</code> thrashes about wildly at first before eventually settling down. The latter <code>pi/4</code>requires just 4 terms to converge.</p>\n<p>In fact we <strong>can</strong> get away with the wide range in this instance because sin, cos and exp are all highly convergent polynomial series with a factorial in the denominator - although the large alternating terms added to partial sums when x ~ pi do cause some loss of precision at the high end of the range.</p>\n<p>We would normally approximate over a reduced range of pi/2, pi/4 or pi/6. However taking on this challenge head on there are several ways to do it. The different simple methods of summing the Taylor series can give a few possible answers depending on how you add them up and whether or not you accumulate the partial sum into a double precision variable. There is no compelling reason to prefer any one of them over another. The fastest method is as good as any.</p>\n<p>There is really nothing good about the professor's recommended method. It is by far the most computationally expensive way to do it and for good measure it will violate the original specification of computing the Taylor series when N&gt;=14 because the factorial result for 14! cannot be accurately represented in a float32 - the value is truncated.</p>\n<p>The OP's original method was perfectly valid and neatly sidesteps the risk of overflow of x<sup>N</sup> and N! by refining the next term to be added for each iteration inside the summation loop. The only refinement would be to step the loop in increments of 2 and so avoid computing <code>n = 2*i</code>.</p>\n<p>@user85421's comment reminded me of a very old school way to obtain a nearly correct polynomial approximation for cos/sin by nailing the result obtained at a specific point to be exact. Called &quot;shooting&quot; and usually done for boundary value problems it is the simplest and easiest to understand of the more advanced methods to improve polynomial accuracy.</p>\n<p>In this instance we adjust the very last term in x<sup>N</sup> so that it hits the target of <code>cos(pi) = -1</code> exactly. It can be manually tweaked from there to get a crude nearly equal ripple solution that is about 25x more accurate than the classical Taylor series.</p>\n<p>The fundamental problem with the Taylor series is that it is ridiculously over precise near zero and increasingly struggles as it approaches pi. This hints that we might be able to find a compromise set of coefficients that is just good enough everywhere in the chosen range.</p>\n<p>The real magic comes from constructing a Chebyshev equal ripple approximation using the same number of terms. This is harder to do for 32 bit floating point and since a lot of modern CPUs now have double precision arithmetic that is as fast as single precision you often find double precision implementations lurking inside nominally float32 wrappers.</p>\n<p>It is possible to rewrite a Taylor series into a Chebyshev expansion by hand. My results were obtained using a Julia numerical code ARMremez.jl for rational approximations.</p>\n<p>To get the best possible coefficient set for fixed precision working in practice requires a huge optimisation effort and isn't always successful but to get something that is good enough is relatively easy. The code below shows the various options I have discussed and sample coefficients. The framework used tests enough of the range of x values to put tight bounds on worst case absolute error |cos(x)-poly_cos(x)|.</p>\n<p>In real applications of approximation we would usually go for minimum relative error | 1 - poly_cos(x)/cos(x)| (so that ideally all the bits in the mantissa are right). However the zero at pi/2 would make life a bit too interesting for a simple quick demo so I have used absolute error here instead.</p>\n<p>The 6 term Chebyshev approximation is 80x more accurate but the error is in the sense that takes cos(x) outside the valid range <code>|cos(x)| &lt;= 1</code> (highly undesirable). That could easily be fixed by rescaling. They have been written in a hardcoded Horner fixed length polynomial implementation avoiding any loops (and 20-30% faster as a result).</p>\n<p>The worst case error in the 7 term Chebyshev approximation computed in double precision is 1000x better at &lt;9e-8 without any fine tuning. The theoretical limit with high precision arithmetic is 1.1e-8 which is below the 3e-8 Unit in the Last Place (ULP) threshold on 0.5-1.0. There is a good chance that it could be made correctly rounded for float32 with sufficient effort. If not then 8 terms will nail it.</p>\n<p>One advantage of asking students to optimise their polynomial function on a range like 0-pi is that you can exhaustively test it for every possible valid input value <code>x</code> fairly quickly. Something that is usually impossible for double precision functions. A proper framework for doing this much more thoroughly than my hack below was included in a post by @njuffa about <a href=\"https://stackoverflow.com/questions/77741402/fast-implementation-of-complementary-error-function-with-5-digit-accuracy/77741403#77741403\">approximating erfc</a>.</p>\n<p>The test reveals that the OP's solution and the book solution are not that different, but the official recommended method is 30x slower or just 10x slower if you cache N!. This is all down to using <code>pow(x,N)</code> including the slight rounding differences in the sum and repeatedly recomputing factorial N (which leads to inaccuracies for N&gt;14).</p>\n<p>Curiously for a basic Taylor series expansion the worst case error is not always right at the end of the range - something particularly noticeable on the methods using <code>pow()</code></p>\n<p>Here is the results table:</p>\n<div class=\"s-table-container\"><table class=\"s-table\">\n<thead>\n<tr>\n<th>Description</th>\n<th>cos(pi)</th>\n<th>error</th>\n<th>min_error</th>\n<th>x_min</th>\n<th>max_error</th>\n<th>x_max</th>\n<th>time (s)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>prof Taylor</td>\n<td>-0.99989957</td>\n<td>0.000100434</td>\n<td>-1.436e-07</td>\n<td>0.94130510</td>\n<td>0.000100672</td>\n<td>3.14159226</td>\n<td>10.752</td>\n</tr>\n<tr>\n<td>pow  Taylor</td>\n<td>-0.99989957</td>\n<td>0.000100434</td>\n<td>-1.436e-07</td>\n<td>0.94130510</td>\n<td>0.000100672</td>\n<td>3.14159226</td>\n<td>2.748</td>\n</tr>\n<tr>\n<td>your Cosinus</td>\n<td>-0.99989957</td>\n<td>0.000100434</td>\n<td>-1.570e-07</td>\n<td>0.80652559</td>\n<td>0.000100791</td>\n<td>3.14157438</td>\n<td>0.301</td>\n</tr>\n<tr>\n<td>my Taylor</td>\n<td>-0.99989951</td>\n<td>0.000100493</td>\n<td>-5.476e-08</td>\n<td>1.00042307</td>\n<td>0.000100493</td>\n<td>3.14159274</td>\n<td>0.237</td>\n</tr>\n<tr>\n<td>shoot Taylor</td>\n<td>-0.99999595</td>\n<td>4.0531e-06</td>\n<td>-4.155e-06</td>\n<td>2.84360051</td>\n<td>4.172e-06</td>\n<td>3.14159012</td>\n<td>0.26</td>\n</tr>\n<tr>\n<td>Horner Chebyshev 6</td>\n<td>-1.00000095</td>\n<td>-9.537e-07</td>\n<td>-1.330e-06</td>\n<td>3.14106655</td>\n<td>9.502e-07</td>\n<td>2.21509051</td>\n<td>0.177</td>\n</tr>\n<tr>\n<td>double Horner Cheby 7</td>\n<td>-1.00000000</td>\n<td>0</td>\n<td>-7.393e-08</td>\n<td>2.34867692</td>\n<td>8.574e-08</td>\n<td>2.10044718</td>\n<td>0.188</td>\n</tr>\n</tbody>\n</table></div>\n<p>Here is the code that can be used to experiment with the various options. The code is C rather than Java but written in such a way that it should be easily ported to Java.</p>\n<pre><code>#include &lt;stdio.h&gt;\n#include &lt;math.h&gt;  \n#include &lt;time.h&gt;\n\n#define SLOW   // to enable the official book answer \n//#define DIVIDE  // use explicit division vs multiply by precomputed reciprocal \n\ndouble TaylorCn[10], dFac[20], drFac[20];\nfloat shootC6;\nfloat Fac[20];\nfloat C6[7] = { 0.99999922f, -0.499994268f, 0.0416598222f, -0.001385891596f, 2.42044015e-05f, -2.19788836e-07f }; // original 240 bit rounded down to float32 \n// ref float C7[8] = { 0.99999999f, -0.499999892f, 0.0416664902f, -0.001388780783f, 2.47699662e-05f, -2.70797754e-07f, 1.724760709e-9f }; // original 240 bit rounded down to float32\nfloat C7[8] = { 0.99999999f, -0.499999892f, 0.0416664902f, -0.001388780783f, 2.47699662e-05f, -2.707977e-07f, 1.72478e-9f };  // after simple fine tuning\ndouble dC7[8] = { 0.9999999891722795, -0.4999998918375135482, 0.04166649019522770258731, -0.0013887807826936648, 2.47699662157542654e-05, -2.707977544202106e-07, 1.7247607089243954e-09 };\n// Chebeshev equal ripple approximations obtained from modified ARMremez rational approximation code\n// C7 +/- 1.08e-8 (computed using 240bit FP arithmetic - coefficients are not fully optimised for float arithmetic) actually obtain 9e-8 (could do better?)\n// C6 +/- 7.78e-7 actually obtain 1.33e-6 (with fine tuning could do better)\n\nconst float pi = 3.1415926535f;\n\nfloat TaylorCos(float x, int ordnung)    \n{\n    double sum, term,  mx2;\n    sum = term = 1.0;\n    mx2 = -x * x;\n    for (int i = 2; i &lt;= ordnung; i+=2) {\n        term *= mx2 ;\n#ifdef DIVIDE\n        sum += term / Fac[i]; // slower when using divide\n#else\n        sum += term * drFac[i]; // faster to multiply by reciprocal\n#endif\n    }\n    return (float) sum;\n}\n\nfloat fTaylorCos(float x)\n{\n    return TaylorCos(x, 12);\n}\n\nvoid InitTaylor()\n{\n    float x2, x4, x8, x12;\n    TaylorCn[0] = 1.0;\n    for (int i = 1; i &lt; 10; i++) TaylorCn[i] = TaylorCn[i - 1] / (2 * i * (2 * i - 1)); // precomute the coefficients\n    Fac[0] = 1;\n    drFac[0] = dFac[0] = 1;\n    for (int i = 1; i &lt; 20; i++)\n    {\n      Fac[i] = i * Fac[i - 1];\n      dFac[i] = i * dFac[i - 1];\n      drFac[i] = 1.0 / dFac[i];\n      if ((double)Fac[i] != dFac[i]) printf(&quot;float factorial fails for %i! %18.0f should be %18.0f error %10.0f ( %6.5f ppm)\\n&quot;, i, Fac[i], dFac[i], dFac[i]-Fac[i], 1e6*(1.0-Fac[i]/dFac[i]));\n    }\n   x2 = pi * pi;\n   x4 = x2 * x2;\n   x8 = x4 * x4;\n   x12 = x4 * x8;\n   shootC6 = (float)(cos((double)pi) - TaylorCos(pi, 10)) / x12 * 1.00221f;   // fiddle factor for shootC6 with 7 terms  *1.00128;\n}\n\nfloat shootTaylorCos(float x)\n{\n    float x2, x4, x8, x12;\n    x2 = x * x;\n    x4 = x2 * x2;\n    x8 = x4 * x4;\n    x12 = x4 * x8;\n    return TaylorCos(x, 10) + shootC6 * x12;\n}\n\nfloat berechneCosinus(float x, int ordnung) {\n    float sum, term, mx2;\n    sum = term = 1.0f;\n    mx2 = -x * x;\n    for (int i = 1; i &lt;= (ordnung + 1) / 2; i++) {\n        int n = 2 * i;\n        term *= mx2 / ((n-1) * n);\n        sum += term;\n    }\n    return sum;\n}\n\nfloat Cosinus(float x)\n{\n    return berechneCosinus(x, 12);\n}\n\nfloat factorial(int n)\n{\n    float result = 1.0f;    \n    for (int i = 2; i &lt;= n; i++)\n        result *= i;\n    return result;\n}\n\nfloat profTaylorCos_core(float x, int n)\n{\n    float sum, term, mx2;\n    sum = term = 1.0f;\n    for (int i = 2; i &lt;= n; i += 2) {\n        term *= -1;\n        sum += term*pow(x,i)/factorial(i);\n    }\n    return (float)sum;\n}\n\nfloat profTaylorCos(float x)\n{\n    return profTaylorCos_core(x, 12);\n}\n\nfloat powTaylorCos_core(float x, int n)\n{\n    float sum, term;\n    sum = term = 1.0f;\n    for (int i = 2; i &lt;= n; i += 2) {\n        term *= -1;\n        sum += term * pow(x, i) / Fac[i];\n    }\n    return (float)sum;\n}\n\nfloat powTaylorCos(float x)\n{\n    return powTaylorCos_core(x, 12);\n}\n\nfloat Cheby6Cos(float x)\n{\n    float sum, term, x2;\n    sum = term = 1.0f;\n    x2 = x * x;\n    for (int i = 1; i &lt; 6; i++) {\n        term *= x2;\n        sum += term * C6[i]; \n    }\n    return sum;\n}\n\nfloat dHCheby7Cos(float x)\n{\n    double x2 = x*x;\n    return (float)(dC7[0] + x2 * (dC7[1] + x2 * (dC7[2] + x2 * (dC7[3] + x2 * (dC7[4] + x2 * (dC7[5] + x2 * dC7[6])))))); // cos 7 terms\n}\n\nfloat HCheby6Cos(float x)\n{\n    float x2 = x * x;\n    return C6[0] + x2 * (C6[1] + x2 * (C6[2] + x2 * (C6[3] + x2 * (C6[4] + x2 * C6[5])))); // cos 6 terms\n}\n\n\nvoid test(const char *name, float(*myfun)(float), double (*ref_fun)(double), double xstart, double xend)\n{\n    float cospi, cpi_err, x, ox, dx, xmax, xmin;\n    double err, res, ref, maxerr, minerr;\n    time_t start, end;\n    x = xstart;\n    ox = -1.0;\n//    dx = 1.2e-7f;\n    dx = 2.9802322387695312e-8f; // chosen to test key ranges of the function exhaustively\n    maxerr = minerr = 0;\n    xmin = xmax = 0.0;\n    start = clock();\n    while (x &lt;= xend) {\n        res = (*myfun)(x);\n        ref = (*ref_fun)(x);\n        err = res - ref;\n        if (err &gt; maxerr) {\n            maxerr = err;\n            xmax = x;\n        }\n        if (err &lt; minerr) {\n            minerr = err;\n            xmin = x;\n        }\n        x += dx;\n        if (x == ox) dx += dx;\n        ox = x;\n    }\n    end = clock();\n    cospi = (*myfun)(pi);\n    cpi_err = cospi - cos(pi);\n    printf(&quot;%-22s  %10.8f  %12g %12g  @  %10.8f  %12g  @  %10.8f  %g\\n&quot;, name, cospi, cpi_err, minerr, xmin, maxerr, xmax, (float)(end - start) / CLOCKS_PER_SEC);\n}\n\nvoid OriginalTest(const char* name, float(*myfun)(float, int), float target, float x)\n{\n    printf(&quot;%s cos(%10.7f) using terms upto x^N\\n N \\t result  error\\n&quot;,name, x);\n    for (int i = 0; i &lt; 19; i += 2) {\n        float cx, err;\n        cx = (*myfun)(x, i);\n        err = cx - target;\n        printf(&quot;%2i  %-12.9f  %12.5g\\n&quot;, i, cx, err);\n        if (err == 0.0) break;\n    }\n}\n\nint main() {\n    InitTaylor();    // note that factorial 14 cannot be represented accurately as a 32 bit float and is truncated.\n                     // easy sanity check on factorial numbers is to count the number of trailing zeroes.\n\n    float x = pi; // approx. PI\n    OriginalTest(&quot;Taylor Cosinus&quot;, berechneCosinus, cos(x), x);\n    OriginalTest(&quot;Taylor Cosinus&quot;, berechneCosinus, cos(x/2), x/2);\n    OriginalTest(&quot;Taylor Cosinus&quot;, berechneCosinus, cos(x/4), x/4);\n\n    printf(&quot;\\nHow it would actually be done using equal ripple polynomial on 0-pi\\n\\n&quot;);\n    printf(&quot;Chebyshev equal ripple   cos(pi) 6 terms %12.8f (sum order x^0 to x^N)\\n&quot;, Cheby6Cos(x));\n    printf(&quot;Horner optimum Chebyshev cos(pi) 6 terms %12.8f (sum order x^N to x^0)\\n&quot;, HCheby6Cos(x));\n    printf(&quot;Horner optimum Chebyshev cos(pi) 7 terms %12.8f (sum order x^N to x^0)\\n\\n&quot;, dHCheby7Cos(x));\n\n    printf(&quot;Performance and functionality tests of versions - professor's solution is 10x slower ~2s on an i5-12600 (please wait)...\\n&quot;);\n    printf(&quot; Description \\t\\t cos(pi)      error \\t    min_error \\t    x_min\\tmax_error \\t x_max \\t  time\\n&quot;);\n#ifdef SLOW\n    test(&quot;prof Taylor&quot;, profTaylorCos, cos, 0.0, pi);\n    test(&quot;pow  Taylor&quot;, powTaylorCos,  cos, 0.0, pi);\n#endif\n    test(&quot;your Cosinus&quot;,  Cosinus, cos, 0.0, pi);\n    test(&quot;my Taylor&quot;,  fTaylorCos, cos, 0.0, pi);\n    test(&quot;shoot Taylor&quot;, shootTaylorCos, cos, 0.0, pi);\n    test(&quot;Horner Chebyshev 6&quot;,  HCheby6Cos, cos, 0.0, pi);\n    test(&quot;double Horner Cheby 7&quot;, dHCheby7Cos, cos, 0.0, pi);\n    return 0;\n}\n</code></pre>\n<p>It is interesting to make the <code>sum</code> and <code>x2</code> variables double precision and observe the effect that has on the answers. If someone fancies running simulated annealing or another global optimiser to find the best possible optimised Chebyshev 6 &amp; 7 float32 approximations please post the results.</p>\n<p>I agree whole heartedly with Steve Summits final comments. You should think very carefully about risk of overflow of intermediate results and order of summation doing numerical calculations. Numerical analysis using floating point numbers follows different rules to pure mathematics and some rearrangements of an equation are <strong>very much</strong> better than others when you want to compute an accurate numerical value.</p>\n",
    "score" : 3,
    "is_accepted" : false,
    "owner" : {
      "account_id" : 29751986,
      "reputation" : 3646,
      "user_id" : 22801686,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/0af01d17ee99f1f8ec1f8f788950399a?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Martin Brown",
      "link" : "https://stackoverflow.com/users/22801686/martin-brown"
    },
    "creation_date" : 1751386089,
    "last_activity_date" : 1751405199,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "answer_id" : 79680462,
    "question_id" : 79674700,
    "body" : "<blockquote>\n<p>I can't say why we should do it like the way he wants...</p>\n</blockquote>\n<p>That's too bad.  It doesn't sound like someone is doing a very good job at teaching.</p>\n<p>I'm not a numerical analyst, so I'm not sure I can teach you what's going on, either, but as it happens I have studied this example.  Here's what I can tell you about it.</p>\n<p>In general, one of the common mistakes people make when coding floating-point expressions is to type them in straight from the mathematical formulation.  But floating-point arithmetic does not always obey the same rules as pure mathematics, so it's not at all uncommon for the naïve approach to run into trouble.</p>\n<p>In this case your professor's expression</p>\n<pre><code>acc += (a / berechneFak(i)) * Math.pow(x, i);\n</code></pre>\n<p>is more or less straight from the mathematical definition of the Taylor series.  But it's got two, related problems:</p>\n<ol>\n<li>It does a lot of unnecessary multiplication.  At iteration <code>i+1</code>, it essentially recomputes <code>berechneFak(i)</code> and <code>Math.pow(x, i)</code> on the way to computing them for <code>i+1</code>.</li>\n<li>Terms like <code>berechneFak(i)</code> and <code>Math.pow(x, i)</code> can get very big, very fast.  That's not a problem in pure mathematics, but the range and precision of computer floating point numbers are limited.  If a term overflows, it can demolish your results.  When you have something like <code>x = y/z</code>, where <code>y</code> and <code>z</code> are both very big, you may lose precision in the quotient <code>x</code> even though <code>x</code> is nice and small and theoretically perfectly representable.</li>\n</ol>\n<p>Here, there's a great way to address both problems.  If you've already computed the factorial <code>berechneFak(i)</code>, then on the next iteration you can simply multiply it by <code>i+1</code> to get <code>berechneFak(i+1)</code>.  If you've already computed <code>Math.pow(x, i)</code>, then you can simply multiply it by <code>x</code> again to get <code>Math.pow(x, i+1)</code>.  And if you perform both operations on a single running quotient variable <code>term</code>, as you did, you minimize the magnitude of the numbers involved, which reduces the possibilities for both overflow and precision loss.</p>\n<p>So, based on these arguments, your implementation should perform quite a bit <em>better</em> than the one suggested by your instructor.</p>\n<p>But for this particular Taylor series, the problem with the arguments I've presented is that, in my experience, they don't end up making much difference in practice.  The efficiency argument is probably real.  But it ends up being hard to show that the hypothetical inaccuracies due to overflow and precision loss will actually occur.</p>\n<p>Assuming you've reduced the range of the input <code>x</code> properly, <code>x</code> won't be large and so <code>Math.pow(x, i)</code> won't grow so fast.  And when you're computing <code>y/z</code>, even when <code>y</code> and <code>z</code> are large, the properties of division and of IEEE-754 floating point mean that you usually get a good result — you don't lose so much precision — after all.  Finally, as I mentioned in a comment, the Taylor series for sin and cos are so darn good that even a naïve implementation tends to converge to a good answer, and quickly.  (That's why, for the problem you chose, your implementation and the professor's gave practically identical results.)</p>\n<p>In my experience, when it comes to sine and cosine, the only way to demonstrate that the &quot;better&quot; implementation really is better is to deliberately omit the range reduction step.  For example, using the improved technique, in single precision, and computing the sine instead of the cosine, if you try to compute sin(14) — that is, 14 radians — after 20 iterations you'll get 0.9817389, which is somewhat close to the correct answer of 0.9879668.  But the naïve approach gives 2.082662, which is not only completely wrong, it's obviously not a sine value at all.</p>\n<p>(I'd like to present that worked-out example here, but as I mentioned it's for sine instead of cosine, and I've been investigating it using C, not Java.)</p>\n<p>What's the bottom line?  There are three or four take-home lessons, I think:</p>\n<p>(1) In general, beware of typing in mathematical expressions straight from the definition.</p>\n<p>(2) In general, well-chosen rearrangements, which are theoretically mathematically equivalent but which work around the various limitations of floating point, can be an excellent idea.</p>\n<p>(3) It sounds like you might not always want to take this particular instructor's teachings to heart.</p>\n<p>But also,</p>\n<p>(4) As I mentioned, I am not a numerical analyst, so I might not really know what I'm talking about here, either.</p>\n",
    "score" : 1,
    "is_accepted" : false,
    "owner" : {
      "account_id" : 4865492,
      "reputation" : 49215,
      "user_id" : 3923896,
      "user_type" : "registered",
      "accept_rate" : 69,
      "profile_image" : "https://i.sstatic.net/AcZuX.png?s=256",
      "display_name" : "Steve Summit",
      "link" : "https://stackoverflow.com/users/3923896/steve-summit"
    },
    "creation_date" : 1750939746,
    "last_activity_date" : 1750945642,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "answer_id" : 79839101,
    "question_id" : 79674700,
    "body" : "<p>The Taylor series for exponential, goniometrical and hyperbolic functions are very similar: there are only subtle differences in the sign of each term, and whether you need only the even terms (cos and cosh), only the odd terms (sin and sinh) or all (exp and expm). Note: expm stands here for exp(-x)<br />\nThey can therefore very concisely be combined in a single loop, as in the java code below<br />\nAlthough for these functions the Taylor series do converge for every value of the argument x (arbitrary large real or complex), it is only practical to use them as approximations for these functions for moderate values (say absolute value below 1)</p>\n<pre class=\"lang-java prettyprint-override\"><code>// initial values, in this example for maximum 10 iterations.\n// A dynamic termination criterion can be added if you wish: \n// stop when the absolute value of t is small enough\n        int i = 0, s = 1, maxit=10;\n        double exp = 1, expm = 1, sin = 0, cos = 1, sinh = 0, cosh = 1, t = 1;\n// the iteration loop itself\n        while (i &lt; maxit) {\n            i++;\n            t *= x;\n            t /= i;\n            System.out.println(&quot;i=&quot; + i + &quot;: t=&quot; + t);  // some output to trace the performance of the algorithm\n            exp += t;\n            if (i % 2 == 0) {\n                cos += s * t;\n                cosh += t;\n                expm += t;\n            } else {\n                sin += s * t;\n                sinh += t;\n                expm -= t;\n                s = -s;\n            }\n        }\n        // test values to judge the accuracy of the results\n        // the theoretical values are: t1=1 t2=1 t3=0 t4=1\n        double t1 = sin * sin + cos * cos;\n        double t2 = cosh * cosh - sinh * sinh;\n        double t3=exp-cosh-sinh;\n        double t4=exp*expm;\n</code></pre>\n",
    "score" : 0,
    "is_accepted" : false,
    "owner" : {
      "account_id" : 44846172,
      "reputation" : 9,
      "user_id" : 31966058,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/7e8944b11e539fd566d17f9f2b5ad1b0?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "ardvb",
      "link" : "https://stackoverflow.com/users/31966058/ardvb"
    },
    "creation_date" : 1764951624,
    "last_activity_date" : 1765050792,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "question_comments" : [ {
    "comment_id" : 140544462,
    "post_id" : 79674700,
    "body" : "if you have an <b>answer</b> please add it as an <b>answer</b> (text box and button at the end of this page), not in the question (you should be able to answer your own question -- see <a href=\"https://meta.stackoverflow.com/q/400492/85421\">Posting my work as an answer or including it in the question if it is complete, but not necessarily the best answer?</a>, mainly its accepted answer ((also there is no need to add <code>SOLVED</code>, <code>CLOSED</code>, or whatever to the title))",
    "score" : 3,
    "owner" : {
      "account_id" : 31180,
      "reputation" : 29752,
      "user_id" : 85421,
      "user_type" : "registered",
      "profile_image" : "https://i.sstatic.net/kKvXH.gif?s=256",
      "display_name" : "user85421",
      "link" : "https://stackoverflow.com/users/85421/user85421"
    },
    "creation_date" : 1750945851,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140539653,
    "post_id" : 79674700,
    "body" : "Using <code>Math.Pow(x, i)</code> and computing the factorial again from scratch for every term suggests that your professor doesn&#39;t understand numerical analysis or efficiency.",
    "score" : 3,
    "owner" : {
      "account_id" : 29751986,
      "reputation" : 3646,
      "user_id" : 22801686,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/0af01d17ee99f1f8ec1f8f788950399a?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Martin Brown",
      "link" : "https://stackoverflow.com/users/22801686/martin-brown"
    },
    "creation_date" : 1750803886,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140534922,
    "post_id" : 79674700,
    "body" : "For input values larger <code>pi&#47;2</code> you can use the fact that <code>cos(x+pi) = -cos(pi)</code>, i.e. you only need to calculate the series in the interval <code>[-pi&#47;2, pi&#47;2]</code> (you could further reduce the interval by also computing <code>sin</code> by using the identity <code>cos(x+pi&#47;2) = -sin(x)</code>). For a correct <code>pi</code>-reduction you should be aware that you cannot precisely represent <code>pi</code> as <code>float</code>, but that is probably beyond the scope of what you are supposed to do for your exercise.",
    "score" : 0,
    "owner" : {
      "account_id" : 9249248,
      "reputation" : 19352,
      "user_id" : 6870253,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/d09b743dfdefefddd54bc32ca2c0e415?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "chtz",
      "link" : "https://stackoverflow.com/users/6870253/chtz"
    },
    "creation_date" : 1750678201,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140532770,
    "post_id" : 79674700,
    "body" : "Minor point. If the order of the approximation for <code>cos(x)</code> is <code>0</code> you should return the term in <code>x^0</code> namely <code>1.0</code> rather than <code>0.0</code> at present. Computing the reciprocal factorials once and storing them in an array and then using multiply and add inside main loop would be faster (but the rounding errors would be different).",
    "score" : 0,
    "owner" : {
      "account_id" : 29751986,
      "reputation" : 3646,
      "user_id" : 22801686,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/0af01d17ee99f1f8ec1f8f788950399a?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Martin Brown",
      "link" : "https://stackoverflow.com/users/22801686/martin-brown"
    },
    "creation_date" : 1750587784,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140532466,
    "post_id" : 79674700,
    "body" : "Note that because you&#39;re using <code>(ordnung + 1)&#47;2</code> as the limit on your <code>for</code> loop, you&#39;ll always get the same result for <code>ordnung = 13</code> and <code>ordnung = 14</code>.",
    "score" : 0,
    "owner" : {
      "account_id" : 1085259,
      "reputation" : 80183,
      "user_id" : 1081110,
      "user_type" : "registered",
      "profile_image" : "https://i.sstatic.net/Fp4Pm.jpg?s=256",
      "display_name" : "Dawood ibn Kareem",
      "link" : "https://stackoverflow.com/users/1081110/dawood-ibn-kareem"
    },
    "creation_date" : 1750568102,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140532167,
    "post_id" : 79674700,
    "body" : "(( if the <i>prof</i> does not consider both these values as a valid answer, consider changing them [not really, probably not possible, but it shows that they do not understand floating point, neither Taylor series themself - unless they want you to explain/prove/calculate that this discrepancy is <i>expected</i> !?] ))",
    "score" : 0,
    "owner" : {
      "account_id" : 31180,
      "reputation" : 29752,
      "user_id" : 85421,
      "user_type" : "registered",
      "profile_image" : "https://i.sstatic.net/kKvXH.gif?s=256",
      "display_name" : "user85421",
      "link" : "https://stackoverflow.com/users/85421/user85421"
    },
    "creation_date" : 1750543238,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140532160,
    "post_id" : 79674700,
    "body" : "by the way, the posted method is returning <code>-0.99989957</code> - rounding to nearest value (with 6 digits), as done by <code>printf</code>, will give <code>-0.999900</code> (actual output); <i>truncating</i>  the value (e.g. using <code>RoundingMode.DOWN)</code> or <code>...CEILING</code>) will result in the expected value <code>-0,999899</code>",
    "score" : 0,
    "owner" : {
      "account_id" : 31180,
      "reputation" : 29752,
      "user_id" : 85421,
      "user_type" : "registered",
      "profile_image" : "https://i.sstatic.net/kKvXH.gif?s=256",
      "display_name" : "user85421",
      "link" : "https://stackoverflow.com/users/85421/user85421"
    },
    "creation_date" : 1750542843,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140532158,
    "post_id" : 79674700,
    "body" : "It is worth computing all the terms and adding them together from smallest to largest to minimise the effect of rounding. Your answer is actually slightly <b>better</b> than the official book answer. You should stand your ground and argue that your Taylor implementation is more nearly correct than the official &quot;book&quot; answer. Initialising the sum to <code>x</code> and taking the <code>if</code> statement out of the loop is worthwhile for other reasons.",
    "score" : 0,
    "owner" : {
      "account_id" : 29751986,
      "reputation" : 3646,
      "user_id" : 22801686,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/0af01d17ee99f1f8ec1f8f788950399a?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Martin Brown",
      "link" : "https://stackoverflow.com/users/22801686/martin-brown"
    },
    "creation_date" : 1750542729,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140532138,
    "post_id" : 79674700,
    "body" : "Presumably the intent here is to learn how poor implementations magnify problems like cascading precision loss, leading to poor results; and how to improve those poor implementations.  But the Taylor series for sin and cos are so darn good (at least over [-π,π]) that even a na&#239;ve implementation tends to give great results.  It&#39;s actually pretty hard to find a nice, pedagogical example which can demonstrate interesting differences between na&#239;ve and sophisticated implementations.",
    "score" : 0,
    "owner" : {
      "account_id" : 4865492,
      "reputation" : 49215,
      "user_id" : 3923896,
      "user_type" : "registered",
      "accept_rate" : 69,
      "profile_image" : "https://i.sstatic.net/AcZuX.png?s=256",
      "display_name" : "Steve Summit",
      "link" : "https://stackoverflow.com/users/3923896/steve-summit"
    },
    "creation_date" : 1750541272,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140532126,
    "post_id" : 79674700,
    "body" : "@Andre This is kind of a meaningless question, on several levels.  Yes, it&#39;s possible to improve the posted code, but shooting for an answer of exactly -0.999899 is crazy.  The posted code is actually doing better at getting the &quot;correct&quot; answer, which of course is -1.0, even when you take the limited precision of <code>float</code> into account.  Six places past the decimal isn&#39;t even enough to see exactly how close or far you are to the &quot;expected&quot; result.",
    "score" : 1,
    "owner" : {
      "account_id" : 4865492,
      "reputation" : 49215,
      "user_id" : 3923896,
      "user_type" : "registered",
      "accept_rate" : 69,
      "profile_image" : "https://i.sstatic.net/AcZuX.png?s=256",
      "display_name" : "Steve Summit",
      "link" : "https://stackoverflow.com/users/3923896/steve-summit"
    },
    "creation_date" : 1750540775,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140532091,
    "post_id" : 79674700,
    "body" : "But then again, all of that was pointed out <a href=\"https://stackoverflow.com/staging-ground/79674488\">in staging ground</a>. Why was this posted, with all the major changes reviews?",
    "score" : 4,
    "owner" : {
      "account_id" : 1888781,
      "reputation" : 2498,
      "user_id" : 1707427,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/4d1a2608ee35e2df7d2400a02e62bb20?s=256&d=identicon&r=PG",
      "display_name" : "S&#246;ren",
      "link" : "https://stackoverflow.com/users/1707427/s%c3%b6ren"
    },
    "creation_date" : 1750538817,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140531996,
    "post_id" : 79674700,
    "body" : "<a href=\"//meta.stackoverflow.com/q/285551\">Please do not upload images of test data.</a>",
    "score" : 5,
    "owner" : {
      "account_id" : 1888781,
      "reputation" : 2498,
      "user_id" : 1707427,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/4d1a2608ee35e2df7d2400a02e62bb20?s=256&d=identicon&r=PG",
      "display_name" : "S&#246;ren",
      "link" : "https://stackoverflow.com/users/1707427/s%c3%b6ren"
    },
    "creation_date" : 1750534247,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "answer_comments" : { }
}