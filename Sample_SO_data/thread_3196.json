{
  "question" : {
    "question_id" : 79566130,
    "title" : "how to stream S3 objects to zip stream and zip stream to s3 in java springboot?",
    "body" : "<p>i am using ec2 with 1GB ram and 8GB storage. and this code works very fast if total size of files are under 500-600mb, slower if around 1GB and if the size is 10GB then it's starts using less and less of my 200Mbps internet, and uses around 200-1000kbps? is there any way i can use it without using up my ec2 memory and storage?</p>\n<pre><code> private void streamFilesFromS3ToZipToS3(ZippingTask zippingTask) {\n        try {\n            // Update task status to PROCESSING\n            zippingTask.setStatus(ZipTaskStatus.PROCESSING);\n            zippingTaskService.save(zippingTask);\n\n            String folderS3Path = zippingTask.getFolder().getS3Path();\n            String folderName = zippingTask.getFolder().getFolderName();\n            String uuid = UUID.randomUUID().toString();\n            String zipKey = String.format(&quot;preSignedZips/%s/%s.zip&quot;, uuid, folderName);\n\n            List&lt;S3Object&gt; s3Objects = s3Handler.getAllObjectsUnderPrefix(folderS3Path);\n            int zippedFiles = 0;\n\n            // Create and upload zip to S3\n            ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();\n            try (ZipOutputStream zipOut = new ZipOutputStream(byteArrayOutputStream)) {\n                for (S3Object s3Object : s3Objects) {\n                    String key = s3Object.key();\n//                    if (!key.endsWith(&quot;/&quot;) ) { // Skip folders\n                    if (!key.equals(zippingTask.getFolder().getS3Path())) { // Skip folders\n                        try (InputStream objectData = s3Handler.getObjectInputStream(key)) {\n                            ZipEntry zipEntry = new ZipEntry(key.substring(folderS3Path.length()));\n                            zipOut.putNextEntry(zipEntry);\n                            IOUtils.copy(objectData, zipOut);\n                            zipOut.closeEntry();\n\n                            log.info(&quot;Zipped file: {}&quot;, key);\n\n                            zippingTask.setProgress((++zippedFiles) * 100 / s3Objects.size());\n                            zippingTaskService.save(zippingTask);\n                        }\n                    }\n                }\n            }\n\n            // Upload zip to S3\n            s3Handler.uploadInputStream(new ByteArrayInputStream(byteArrayOutputStream.toByteArray()), zipKey);\n//            String zipPreSignedUrl = s3Handler.generatePreSignedUrlForSingleFile(zipKey);\n            String zipPreSignedUrl = s3Handler.generatePreSignedUrlForSingleFileWithExpirationDuration(zipKey, Duration.ofDays(1));\n\n            // Update task status\n            zippingTask.setStatus(ZipTaskStatus.COMPLETE);\n            zippingTask.setZipS3Key(zipKey);\n            zippingTask.setPresignedUrl(zipPreSignedUrl);\n            zippingTaskService.save(zippingTask);\n\n            // Send email\n            String userEmail = zippingTask.getUser().getEmail();\n            emailServices.sendZipCompletionEmail(userEmail, folderName, zipPreSignedUrl);\n\n        } catch (Exception e) {\n            log.error(&quot;Error processing zip task: {}&quot;, e.getMessage());\n            zippingTask.setStatus(ZipTaskStatus.ERROR);\n            zippingTask.setErrorMessage(e.getMessage());\n            zippingTaskService.save(zippingTask);\n        }\n    }\n</code></pre>\n<pre><code>    public void uploadInputStream(ByteArrayInputStream byteArrayInputStream, String zipKey) {\n        PutObjectRequest putObjectRequest = PutObjectRequest.builder()\n                .bucket(bucketName)\n                .key(zipKey)\n                .build();\n\n        RequestBody requestBody = RequestBody.fromInputStream(byteArrayInputStream, byteArrayInputStream.available());\n        s3Client.putObject(putObjectRequest, requestBody);\n    }\n</code></pre>\n",
    "tags" : [ "java", "amazon-web-services", "amazon-s3", "zip" ],
    "owner" : {
      "account_id" : 13234666,
      "reputation" : 167,
      "user_id" : 9557169,
      "user_type" : "registered",
      "profile_image" : "https://i.sstatic.net/hmgut.jpg?s=256",
      "display_name" : "Manan Domadiya",
      "link" : "https://stackoverflow.com/users/9557169/manan-domadiya"
    },
    "is_answered" : true,
    "view_count" : 119,
    "answer_count" : 1,
    "score" : 0,
    "last_activity_date" : 1744377813,
    "creation_date" : 1744274096,
    "link" : "https://stackoverflow.com/questions/79566130/how-to-stream-s3-objects-to-zip-stream-and-zip-stream-to-s3-in-java-springboot",
    "content_license" : "CC BY-SA 4.0"
  },
  "answers" : [ {
    "answer_id" : 79568941,
    "question_id" : 79566130,
    "body" : "<p>i have done it finally, using pipedOutputstream and pipedInputstream</p>\n<pre><code>//    this function is used to zip the files from S3 and upload zip to S3\n    public void streamFromS3ToS3ViaZip(ZippingTask zippingTask) {\n        // Update task status to PROCESSING\n        zippingTask.setStatus(ZipTaskStatus.PROCESSING);\n        zippingTaskService.save(zippingTask);\n\n        String folderS3Path = zippingTask.getFolder().getS3Path();\n        String folderName = zippingTask.getFolder().getFolderName();\n        String uuid = UUID.randomUUID().toString().split(&quot;-&quot;)[0];\n        String zipKey = String.format(&quot;preSignedZips/%s/%s.zip&quot;, uuid, folderName);\n        final int zipExpirationDays = 3;\n\n\n        final CountDownLatch zipCompletionLatch = new CountDownLatch(1);\n        final AtomicBoolean zipFailed = new AtomicBoolean(false);\n        final AtomicReference&lt;Exception&gt; zipException = new AtomicReference&lt;&gt;();\n        final AtomicLong totalOriginalBytes = new AtomicLong(0);\n        final AtomicLong totalCompressedBytes = new AtomicLong(0);\n\n        try {\n            // Create an S3 multipart upload session\n            CreateMultipartUploadResponse createResponse = s3Handler.getS3Client().createMultipartUpload(\n                    CreateMultipartUploadRequest.builder()\n                            .bucket(s3Handler.getBucketName())\n                            .key(zipKey)\n                            .contentType(&quot;application/zip&quot;)\n                            .build()\n            );\n            String uploadId = createResponse.uploadId();\n\n            // Use a pipe with a reasonably sized buffer\n            final PipedOutputStream pipedOut = new PipedOutputStream();\n            final PipedInputStream pipedIn = new PipedInputStream(pipedOut, 8 * 1024 * 1024); // 8MB buffer\n\n            Thread zipThread = new Thread(() -&gt; {\n                try (\n                        BufferedOutputStream bufferedOut = new BufferedOutputStream(pipedOut, 1 * 1024 * 1024);\n                        ZipOutputStream zipOut = new ZipOutputStream(bufferedOut)\n                ) {\n                    // Fast compression level\n                    zipOut.setLevel(Deflater.NO_COMPRESSION);\n\n                    List&lt;S3Object&gt; files = s3Handler.getAllObjectsUnderPrefix(folderS3Path);\n                    int totalFiles = files.size();\n                    long totalFileSize = files.stream().mapToLong(S3Object::size).sum();\n                    long zippedFileSize = 0;\n                    int processedFiles = 0;\n\n                    for (S3Object s3Object : files) {\n//                        log.info(&quot;Processing file: {}, size : {} MB&quot;, s3Object.key(), String.format(&quot;%.2f&quot;, s3Object.size() / (1024.0 * 1024.0)));\n                        // Skip folders\n                        String key = s3Object.key();\n                        if (key.equals(folderS3Path)) {\n                            processedFiles++;\n                            continue;\n                        }\n\n                        String zipEntryName = key.substring(folderS3Path.length());\n                        if (zipEntryName.startsWith(&quot;/&quot;)) {\n                            zipEntryName = zipEntryName.substring(1);\n                        }\n\n                        try (InputStream s3In = s3Handler.getObjectInputStream(key)) {\n                            zipOut.putNextEntry(new ZipEntry(zipEntryName));\n                            byte[] buffer = new byte[1 * 1024 * 1024]; // 1MB buffer for reading\n                            int len;\n                            long fileSize = 0;\n                            while ((len = s3In.read(buffer)) &gt; 0) {\n                                zipOut.write(buffer, 0, len);\n                                fileSize += len;\n                            }\n                            totalOriginalBytes.addAndGet(fileSize);\n                            zipOut.closeEntry();\n\n                            zippedFileSize += s3Object.size();\n\n                            processedFiles++;\n                            if (processedFiles % 10 == 0 || processedFiles == totalFiles) {\n//                                log.info(&quot;ZIP progress: {}/{} files ({} %), Total original data: {} MB&quot;,\n//                                        processedFiles, totalFiles,\n//                                        totalFiles &gt; 0 ? (processedFiles * 100 / totalFiles) : 0,\n//                                        String.format(&quot;%.2f&quot;, totalOriginalBytes.get() / (1024.0 * 1024.0)));\n\n\n//                            zippingTask.setProgress(processedFiles * 100 / totalFiles);\n                                int progress = (int) (zippedFileSize * 100 / totalFileSize);\n                                zippingTask.setProgress(progress);\n                                zippingTaskService.save(zippingTask);\n//                                log.debug(&quot;Updated progress for task {}: {}%&quot;, zippingTask.getId(), progress);\n                            }\n\n                        }\n                    }\n\n                    zipOut.finish();\n                    log.info(&quot;\uD83D\uDCE6 ZIP creation finished - Original data size: {} MB&quot;,\n                            String.format(&quot;%.2f&quot;, totalOriginalBytes.get() / (1024.0 * 1024.0)));\n                } catch (Exception e) {\n                    zipFailed.set(true);\n                    zipException.set(e);\n                    log.error(&quot;❌ Error zipping: {}&quot;, e.getMessage(), e);\n                } finally {\n                    try {\n                        pipedOut.close();\n                    } catch (IOException ignore) {\n                    }\n                    zipCompletionLatch.countDown();\n                }\n            }, &quot;zip-thread-&quot; + zipKey);\n\n            Thread uploadThread = new Thread(() -&gt; {\n                List&lt;CompletedPart&gt; completedParts = new ArrayList&lt;&gt;();\n                int partNumber = 1;\n                long uploadedBytes = 0;\n                long startTime = System.currentTimeMillis();\n\n                try {\n                    // Use chunked upload - AWS requires minimum 5MB parts except for last part\n                    final int PART_SIZE = 10 * 1024 * 1024; // 10MB chunks\n                    byte[] buffer = new byte[PART_SIZE];\n\n                    int bytesRead;\n                    while ((bytesRead = readFully(pipedIn, buffer, 0, buffer.length)) &gt; 0) {\n                        ByteBuffer byteBuffer = ByteBuffer.wrap(buffer, 0, bytesRead);\n\n                        // Upload part\n                        UploadPartResponse uploadPartResponse = s3Handler.getS3Client().uploadPart(\n                                UploadPartRequest.builder()\n                                        .bucket(s3Handler.getBucketName())\n                                        .key(zipKey)\n                                        .uploadId(uploadId)\n                                        .partNumber(partNumber)\n                                        .contentLength((long) bytesRead)\n                                        .build(),\n                                RequestBody.fromByteBuffer(byteBuffer)\n                        );\n\n                        completedParts.add(\n                                CompletedPart.builder()\n                                        .partNumber(partNumber)\n                                        .eTag(uploadPartResponse.eTag())\n                                        .build()\n                        );\n\n                        uploadedBytes += bytesRead;\n                        totalCompressedBytes.set(uploadedBytes);\n\n                        log.debug(&quot;Uploaded part {} - {} MB (total: {} MB)&quot;,\n                                partNumber,\n                                String.format(&quot;%.2f&quot;, bytesRead / (1024.0 * 1024.0)),\n                                String.format(&quot;%.2f&quot;, uploadedBytes / (1024.0 * 1024.0)));\n\n                        partNumber++;\n                    }\n\n                    // Complete the multipart upload\n                    s3Handler.getS3Client().completeMultipartUpload(\n                            CompleteMultipartUploadRequest.builder()\n                                    .bucket(s3Handler.getBucketName())\n                                    .key(zipKey)\n                                    .uploadId(uploadId)\n                                    .multipartUpload(\n                                            CompletedMultipartUpload.builder()\n                                                    .parts(completedParts)\n                                                    .build()\n                                    )\n                                    .build()\n                    );\n\n                    long endTime = System.currentTimeMillis();\n                    double uploadSizeMB = uploadedBytes / (1024.0 * 1024.0);\n                    double durationSeconds = (endTime - startTime) / 1000.0;\n                    double mbPerSecond = durationSeconds &gt; 0 ? uploadSizeMB / durationSeconds : 0;\n                    double compressionRatio = totalOriginalBytes.get() &gt; 0 ?\n                            (double) uploadedBytes / totalOriginalBytes.get() * 100 : 0;\n\n                    log.info(&quot;\uD83D\uDCE4 Upload complete: {} - Original: {} MB, Compressed: {} MB ({}%), Duration: {} seconds, Speed: {} MB/s&quot;,\n                            zipKey,\n                            String.format(&quot;%.2f&quot;, totalOriginalBytes.get() / (1024.0 * 1024.0)),\n                            String.format(&quot;%.2f&quot;, uploadSizeMB),\n                            String.format(&quot;%.1f&quot;, compressionRatio),\n                            String.format(&quot;%.2f&quot;, durationSeconds),\n                            String.format(&quot;%.2f&quot;, mbPerSecond));\n                } catch (Exception e) {\n                    log.error(&quot;❌ Error uploading: {}&quot;, e.getMessage(), e);\n\n                    // Abort the multipart upload on failure\n                    try {\n                        s3Handler.getS3Client().abortMultipartUpload(\n                                AbortMultipartUploadRequest.builder()\n                                        .bucket(s3Handler.getBucketName())\n                                        .key(zipKey)\n                                        .uploadId(uploadId)\n                                        .build()\n                        );\n                    } catch (Exception abortException) {\n                        log.error(&quot;Failed to abort multipart upload: {}&quot;, abortException.getMessage());\n                    }\n                } finally {\n                    try {\n                        pipedIn.close();\n                    } catch (IOException ignore) {\n                    }\n                }\n            }, &quot;upload-thread-&quot; + zipKey);\n\n            zipThread.setPriority(Thread.MAX_PRIORITY);\n            uploadThread.setPriority(Thread.MAX_PRIORITY);\n\n            uploadThread.start();\n            zipThread.start();\n\n            zipThread.join();\n            uploadThread.join();\n\n            String zipPreSignedUrl = s3Handler.generatePreSignedUrlForSingleFileWithExpirationDuration(zipKey, Duration.ofDays(zipExpirationDays));\n\n            // Update task status\n            zippingTask.setStatus(ZipTaskStatus.COMPLETE);\n            zippingTask.setZipS3Key(zipKey);\n            zippingTask.setPresignedUrl(zipPreSignedUrl);\n            zippingTask.setExpiresAt(LocalDateTime.now(ZoneOffset.UTC).plusDays(zipExpirationDays));\n            zippingTaskService.save(zippingTask);\n\n            // Send email\n            String userEmail = zippingTask.getUser().getEmail();\n            emailServices.sendZipCompletionEmail(userEmail, folderName, zipPreSignedUrl);\n\n\n            if (zipFailed.get() &amp;&amp; zipException.get() != null) {\n                throw zipException.get();\n            }\n        } catch (Exception e) {\n            log.error(&quot;\uD83D\uDCA5 Failed zip+upload: {}&quot;, e.getMessage(), e);\n            throw new RuntimeException(&quot;Failed to zip and upload to S3&quot;, e);\n        }\n    }\n\n    // Helper method to read a full chunk from an input stream\n    private int readFully(InputStream input, byte[] buffer, int offset, int length) throws IOException {\n        int bytesRead = 0;\n        int result;\n        while (bytesRead &lt; length) {\n            result = input.read(buffer, offset + bytesRead, length - bytesRead);\n            if (result == -1) {\n                break;\n            }\n            bytesRead += result;\n        }\n        return bytesRead;\n    }\n</code></pre>\n",
    "score" : 0,
    "is_accepted" : true,
    "owner" : {
      "account_id" : 13234666,
      "reputation" : 167,
      "user_id" : 9557169,
      "user_type" : "registered",
      "profile_image" : "https://i.sstatic.net/hmgut.jpg?s=256",
      "display_name" : "Manan Domadiya",
      "link" : "https://stackoverflow.com/users/9557169/manan-domadiya"
    },
    "creation_date" : 1744377813,
    "last_activity_date" : 1744377813,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "question_comments" : [ {
    "comment_id" : 140321284,
    "post_id" : 79566130,
    "body" : "@Manan Domadiya, In extension to M.Deinum, ByteArrayOutputStream and ByteArrayInputStream are in-memory buffers, and not scalable Better Approach: Stream ZIP directly to S3 (no buffering)  Pipe S3 objects into a ZipOutputStream Back the ZipOutputStream with a PipedOutputStream, and Send that stream to S3 without writing everything to memory let me know if you need help with code.",
    "score" : 0,
    "owner" : {
      "account_id" : 7645025,
      "reputation" : 440,
      "user_id" : 5795975,
      "user_type" : "registered",
      "profile_image" : "https://lh6.googleusercontent.com/-6KwPUS4RnyA/AAAAAAAAAAI/AAAAAAAAC8w/auZqreI45x0/s256-rj/photo.jpg",
      "display_name" : "Vijay",
      "link" : "https://stackoverflow.com/users/5795975/vijay"
    },
    "creation_date" : 1744300459,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140319634,
    "post_id" : 79566130,
    "body" : "The <code>ByteArrayInputStream</code> and <code>ByteArrayOutputStream</code> are in-memory they allocate a <code>byte[]</code> for the size needed (it will progressivly grow). The short answer is don&#39;t use those as those will fill up your memory. You probably should directly stream to S3 instead of using these intermediate streams .",
    "score" : 2,
    "owner" : {
      "account_id" : 3192259,
      "reputation" : 126800,
      "user_id" : 2696260,
      "user_type" : "registered",
      "profile_image" : "https://i.sstatic.net/qHEzx.png?s=256",
      "display_name" : "M. Deinum",
      "link" : "https://stackoverflow.com/users/2696260/m-deinum"
    },
    "creation_date" : 1744276390,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "answer_comments" : { }
}