{
  "question" : {
    "question_id" : 79675833,
    "title" : "Why is this code 5 times slower in C# compared to Java?",
    "body" : "<p>First of all we create a random binary file with 100.000.000 bytes. I used Python for this:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import random\nimport os\n\ndef Main():\n    length = 100000000\n    randomArray = random.randbytes(length)\n    desktopPath = os.path.normpath(os.path.expanduser(&quot;~/Desktop&quot;))\n    fullPath=os.path.join(desktopPath,&quot;RandomFile.dat&quot;)\n    if os.path.isfile(fullPath):\n        print(&quot;File already exists.&quot;)\n        return\n    with open(fullPath, &quot;wb&quot;) as file:\n        file.write(randomArray)\n        print(&quot;The file has been created.&quot;)\n\nMain()\n</code></pre>\n<p>After this we find how many of these bytes were greater than 100 using C# and Java.</p>\n<p>C#:</p>\n<pre class=\"lang-cs prettyprint-override\"><code>using System.Diagnostics;\n\nnamespace TestYouTube\n{\n    public class Program\n    {\n        //finished\n        public static void Main(string[] args)\n        {\n            string desktopPath = Environment.GetFolderPath(Environment.SpecialFolder.Desktop);\n            string fullPath = Path.Combine(desktopPath, &quot;RandomFile.dat&quot;);\n            if (!File.Exists(fullPath))\n            {\n                Console.WriteLine(&quot;The file does not exist.&quot;);\n                return;\n            }\n            byte[] byteArray = File.ReadAllBytes(fullPath);\n            int[] intArray = ByteArrayToIntArray(byteArray);\n            Stopwatch stopwatch = new Stopwatch();\n            stopwatch.Start();\n            int count = TestSpeed(intArray);\n            stopwatch.Stop();\n            Console.WriteLine($&quot;Count = {count}&quot;);\n            Console.WriteLine($&quot;Elapsed: {stopwatch.Elapsed.TotalSeconds} seconds&quot;);\n            Console.ReadLine();\n        }\n\n        //finished\n        private static int[] ByteArrayToIntArray(byte[] byteArray)\n        {\n            if (byteArray == null) return null;\n            if (byteArray.Length == 0) return Array.Empty&lt;int&gt;();\n            int[] intArray = new int[byteArray.Length];\n            for (int i = 0; i &lt; intArray.Length; i++)\n            {\n                intArray[i] = byteArray[i];\n            }\n            return intArray;\n        }\n\n        //finished\n        private static int TestSpeed(int[] array)\n        {\n            if (array == null) throw new ArgumentNullException();\n            if (array.Length == 0) throw new ArgumentException();\n            int count = 0;\n            foreach (int element in array)\n            {\n                if (element &gt; 100)\n                {\n                    count++;\n                }\n            }\n            return count;\n        }\n    }\n}\n</code></pre>\n<p>Java:</p>\n<pre class=\"lang-java prettyprint-override\"><code>import javax.swing.filechooser.*;\nimport java.io.*;\nimport java.nio.file.*;\n\npublic class Main\n{\n    public static void main(String[] args) throws IOException\n    {\n        FileSystemView view = FileSystemView.getFileSystemView();\n        File file = view.getHomeDirectory();\n        String desktopPath = file.getPath();\n        Path fullPath = Paths.get(desktopPath,&quot;RandomFile.dat&quot;);\n        File randomFile=new File(fullPath.toString());\n        if (!randomFile.exists() || randomFile.isDirectory())\n        {\n            System.out.println(&quot;The file does not exist.&quot;);\n            return;\n        }\n        byte[] array = Files.readAllBytes(randomFile.toPath());\n        int[] intArray=ByteArrayToUnsignedByteArray(array);\n        long start = System.currentTimeMillis();\n        int count=TestSpeed(intArray);\n        long end = System.currentTimeMillis();\n        long elapsed=end-start;\n        double elapsedSeconds=((double)elapsed)/1000;\n        System.out.printf(&quot;Count = %d\\n&quot;,count);\n        System.out.printf(&quot;Elapsed: %f seconds\\n&quot;,elapsedSeconds);\n    }\n\n    private static int ByteToUnsignedByte(byte b)\n    {\n        return b &amp; 0b11111111;\n    }\n\n    private static int[] ByteArrayToUnsignedByteArray(byte[] byteArray)\n    {\n        if (byteArray==null) return null;\n        if (byteArray.length==0) return new int[0];\n        int[] newArray=new int[byteArray.length];\n        for (int i=0;i&lt;byteArray.length;i++)\n        {\n            int element=ByteToUnsignedByte(byteArray[i]);\n            newArray[i]=element;\n        }\n        return newArray;\n    }\n\n    private static int TestSpeed(int[] byteArray)\n    {\n        if (byteArray==null) throw new IllegalArgumentException(&quot;The array must not be null.&quot;);\n        if (byteArray.length==0) throw new IllegalArgumentException(&quot;The array length must be non zero.&quot;);\n        int count=0;\n        for (int element : byteArray)\n        {\n            if (element&gt;100)\n            {\n                count++;\n            }\n        }\n        return count;\n    }\n}\n</code></pre>\n<p>Please note that we only measure the time of the function TestSpeed in both languages.</p>\n<p>Results:\nC#:<br />\nCount = 60542647<br />\nElapsed: 0,4286155 seconds</p>\n<p>Java:<br />\nCount = 60542647<br />\nElapsed: 0,077000 seconds</p>\n<p>I ran the code multiple times and the result is about the same. C# is about 5 times slower than Java. Please note that I ran the code from &quot;Release&quot; and also I used &quot;Start Without Debbuging&quot;.</p>\n<p>Does anybody know why this happens? What am I doing wrong?</p>\n<hr />\n<p>According to comments it's better to benchmark the C# code with a benchmark library so I used BenchmarkDotNet for this. The results:<br />\n<code>TestSpeed Mean: 411.2 ms</code><br />\nWhich is not really different from Stopwatch.</p>\n<ul>\n<li>.NET version: .NET 9.0,</li>\n<li>Java openjdk version &quot;24.0.1&quot; 2025-04-15,</li>\n<li>OS: Microsoft Windows [Version 10.0.19045.5965],</li>\n<li>CPU name: AMD Athlon Gold 3150U with Radeon Graphics (dual core Zen 1)</li>\n</ul>\n",
    "tags" : [ "java", "c#", "performance", "benchmarking", "microbenchmark" ],
    "owner" : {
      "account_id" : 42679246,
      "reputation" : 379,
      "user_id" : 30869176,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/e8c2f3e4f8519a81500e2c8f44b0b208?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Vasilis Kontopoulos",
      "link" : "https://stackoverflow.com/users/30869176/vasilis-kontopoulos"
    },
    "is_answered" : true,
    "view_count" : 9449,
    "answer_count" : 5,
    "score" : 27,
    "last_activity_date" : 1751035279,
    "creation_date" : 1750666109,
    "link" : "https://stackoverflow.com/questions/79675833/why-is-this-code-5-times-slower-in-c-compared-to-java",
    "content_license" : "CC BY-SA 4.0"
  },
  "answers" : [ {
    "answer_id" : 79676396,
    "question_id" : 79675833,
    "body" : "<p><a href=\"https://stackoverflow.com/questions/79675833/why-is-this-code-5-times-slower-in-c-sharp-compared-to-java/79676247#79676247\">Matthew Watson's</a> and <a href=\"https://stackoverflow.com/questions/79675833/why-is-this-code-5-times-slower-in-c-sharp-compared-to-java/79676180#79676180\">Charlieface's answers</a> actually explain the reason for this question,\nbecause compared to CLR, <a href=\"https://wiki.openjdk.org/pages/viewpage.action?pageId=20415918\" rel=\"noreferrer\">JVM has implemented more loop optimizations</a>, including <a href=\"https://en.wikipedia.org/wiki/Automatic_vectorization\" rel=\"noreferrer\">vectorization</a> and <a href=\"https://en.wikipedia.org/wiki/Loop_unrolling\" rel=\"noreferrer\">loop unrolling</a>, which allows the JVM to use fewer <code>jump</code> and <code>inc</code> instructions and save more time when the loop length is very long.</p>\n<p>There is <a href=\"https://github.com/dotnet/runtime/issues/65342\" rel=\"noreferrer\">an issue</a> on GitHub that tracks the progress of .NET loop optimizations. unfortunately the above optimizations is still ongoing.</p>\n",
    "score" : 32,
    "is_accepted" : false,
    "owner" : {
      "account_id" : 8238102,
      "reputation" : 30152,
      "user_id" : 6196568,
      "user_type" : "registered",
      "profile_image" : "https://i.sstatic.net/cHprk.png?s=256",
      "display_name" : "shingo",
      "link" : "https://stackoverflow.com/users/6196568/shingo"
    },
    "creation_date" : 1750691647,
    "last_activity_date" : 1750726196,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "answer_id" : 79676383,
    "question_id" : 79675833,
    "body" : "<p>I've disassembled your <code>TestSpeed</code> Java method (by the way, you ought to call it <code>testSpeed</code> to keep to Java naming conventions). This is on Linux (x64), but the results should be similar on Windows. Evidently, the JVM compiler has a number of compilation stages, each time with more optimization than the previous stage. I'm not an assembly language expert, but I think this shows that in C1 compilation, it generated a simple loop, similar to that generated by the C# runtime, but in the C2 generated code it has unrolled the loop, thus speeding it up.</p>\n<p>So, it seems, the JVM compiler optimizes better than the .NET one in this particular case.</p>\n<p>The <code>TestSpeed</code> method is shown below with line numbers for cross-reference with the assembly listing:</p>\n<pre class=\"lang-java prettyprint-override\"><code>28  private static int TestSpeed(int[] byteArray)\n29  {\n30      int count=0;\n31      for (int element : byteArray)\n32          if (element&gt;100)\n33              count++;\n34      return count;\n35  }\n</code></pre>\n<p>And the assembly listing generated with<br />\n<code>java -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly</code><br />\nwith <code>hsdis-amd64.so</code> in the <code>LD_LIBRARY_PATH</code>:</p>\n<pre class=\"lang-none prettyprint-override\"><code>============================= C1-compiled nmethod ==============================\n----------------------------------- Assembly -----------------------------------\n\nCompiled method (c1)     498   20 %     3       org.example.App::TestSpeed @ 10 (40 bytes)\n total in heap  [0x00007d32b5403510,0x00007d32b5403ae0] = 1488\n relocation     [0x00007d32b5403670,0x00007d32b54036b0] = 64\n main code      [0x00007d32b54036c0,0x00007d32b54038e0] = 544\n stub code      [0x00007d32b54038e0,0x00007d32b5403910] = 48\n oops           [0x00007d32b5403910,0x00007d32b5403918] = 8\n metadata       [0x00007d32b5403918,0x00007d32b5403920] = 8\n scopes data    [0x00007d32b5403920,0x00007d32b5403998] = 120\n scopes pcs     [0x00007d32b5403998,0x00007d32b5403ab8] = 288\n dependencies   [0x00007d32b5403ab8,0x00007d32b5403ac0] = 8\n nul chk table  [0x00007d32b5403ac0,0x00007d32b5403ae0] = 32\n\n[Disassembly]\n--------------------------------------------------------------------------------\n[Constant Pool (empty)]\n\n--------------------------------------------------------------------------------\n\n[Verified Entry Point]\n  # {method} {0x00007d323f4006c0} 'TestSpeed' '([I)I' in 'org/example/App'\n  0x00007d32b54036c0:   mov    %eax,-0x14000(%rsp)\n  0x00007d32b54036c7:   push   %rbp\n  0x00007d32b54036c8:   sub    $0x40,%rsp\n  0x00007d32b54036cc:   movabs $0x7d323f400ac8,%rdi         ;   {metadata(method data for {method} {0x00007d323f4006c0} 'TestSpeed' '([I)I' in 'org/example/App')}\n  0x00007d32b54036d6:   mov    0xf4(%rdi),%ebx\n  0x00007d32b54036dc:   add    $0x2,%ebx\n  0x00007d32b54036df:   mov    %ebx,0xf4(%rdi)\n  0x00007d32b54036e5:   and    $0x7fe,%ebx\n  0x00007d32b54036eb:   cmp    $0x0,%ebx\n  0x00007d32b54036ee:   je     0x00007d32b5403827           ;*iconst_0 {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@0 (line 30)\n  0x00007d32b54036f4:   mov    0xc(%rsi),%edi               ; implicit exception: dispatches to 0x00007d32b5403848\n                                                            ;*arraylength {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@5 (line 31)\n  0x00007d32b54036f7:   mov    $0x0,%ebx\n  0x00007d32b54036fc:   mov    $0x0,%eax\n  0x00007d32b5403701:   jmp    0x00007d32b5403791           ;*iload {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@10 (line 31)\n  0x00007d32b5403706:   xchg   %ax,%ax\n  0x00007d32b5403708:   cmp    0xc(%rsi),%ebx               ; implicit exception: dispatches to 0x00007d32b540384d\n  0x00007d32b540370b:   jae    0x00007d32b5403857\n  0x00007d32b5403711:   movslq %ebx,%rdx\n  0x00007d32b5403714:   mov    0x10(%rsi,%rdx,4),%edx       ;*iaload {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@19 (line 31)\n  0x00007d32b5403718:   cmp    $0x64,%edx\n  0x00007d32b540371b:   movabs $0x7d323f400ac8,%rdx         ;   {metadata(method data for {method} {0x00007d323f4006c0} 'TestSpeed' '([I)I' in 'org/example/App')}\n  0x00007d32b5403725:   mov    $0x158,%rcx\n  0x00007d32b540372c:   jle    0x00007d32b5403739\n  0x00007d32b5403732:   mov    $0x168,%rcx\n  0x00007d32b5403739:   mov    (%rdx,%rcx,1),%r8\n  0x00007d32b540373d:   lea    0x1(%r8),%r8\n  0x00007d32b5403741:   mov    %r8,(%rdx,%rcx,1)\n  0x00007d32b5403745:   jle    0x00007d32b540374d           ;*if_icmple {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@26 (line 32)\n  0x00007d32b540374b:   inc    %eax\n  0x00007d32b540374d:   inc    %ebx\n  0x00007d32b540374f:   movabs $0x7d323f400ac8,%rdx         ;   {metadata(method data for {method} {0x00007d323f4006c0} 'TestSpeed' '([I)I' in 'org/example/App')}\n  0x00007d32b5403759:   mov    0xf8(%rdx),%ecx\n  0x00007d32b540375f:   add    $0x2,%ecx\n  0x00007d32b5403762:   mov    %ecx,0xf8(%rdx)\n  0x00007d32b5403768:   and    $0x3ffe,%ecx\n  0x00007d32b540376e:   cmp    $0x0,%ecx\n  0x00007d32b5403771:   je     0x00007d32b5403865           ;*goto {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@35 (line 31)\n  0x00007d32b5403777:   mov    0x348(%r15),%r10             ; ImmutableOopMap {rsi=Oop }\n                                                            ;*goto {reexecute=1 rethrow=0 return_oop=0}\n                                                            ; - (reexecute) org.example.App::TestSpeed@35 (line 31)\n  0x00007d32b540377e:   test   %eax,(%r10)                  ;   {poll}\n  0x00007d32b5403781:   movabs $0x7d323f400ac8,%rdx         ;   {metadata(method data for {method} {0x00007d323f4006c0} 'TestSpeed' '([I)I' in 'org/example/App')}\n  0x00007d32b540378b:   incl   0x178(%rdx)                  ;*goto {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@35 (line 31)\n  0x00007d32b5403791:   cmp    %edi,%ebx\n  0x00007d32b5403793:   movabs $0x7d323f400ac8,%rdx         ;   {metadata(method data for {method} {0x00007d323f4006c0} 'TestSpeed' '([I)I' in 'org/example/App')}\n  0x00007d32b540379d:   mov    $0x148,%rcx\n  0x00007d32b54037a4:   jl     0x00007d32b54037b1\n  0x00007d32b54037aa:   mov    $0x138,%rcx\n  0x00007d32b54037b1:   mov    (%rdx,%rcx,1),%r8\n  0x00007d32b54037b5:   lea    0x1(%r8),%r8\n  0x00007d32b54037b9:   mov    %r8,(%rdx,%rcx,1)\n  0x00007d32b54037bd:   jl     0x00007d32b5403708           ;*if_icmpge {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@13 (line 31)\n  0x00007d32b54037c3:   add    $0x40,%rsp\n  0x00007d32b54037c7:   pop    %rbp\n  0x00007d32b54037c8:   cmp    0x340(%r15),%rsp             ;   {poll_return}\n  0x00007d32b54037cf:   ja     0x00007d32b5403886\n  0x00007d32b54037d5:   ret                                 ;*ireturn {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@39 (line 34)\n  0x00007d32b54037d6:   mov    %eax,-0x14000(%rsp)\n  0x00007d32b54037dd:   push   %rbp\n  0x00007d32b54037de:   sub    $0x40,%rsp\n  0x00007d32b54037e2:   mov    0x20(%rsi),%ebx\n  0x00007d32b54037e5:   mov    0x18(%rsi),%rax\n  0x00007d32b54037e9:   mov    0x10(%rsi),%edx\n  0x00007d32b54037ec:   mov    0x8(%rsi),%ecx\n  0x00007d32b54037ef:   mov    %rsi,%rdi\n  0x00007d32b54037f2:   mov    %ebx,0x30(%rsp)\n  0x00007d32b54037f6:   mov    %rax,0x28(%rsp)\n  0x00007d32b54037fb:   mov    %edx,0x24(%rsp)\n  0x00007d32b54037ff:   mov    %ecx,0x20(%rsp)\n  0x00007d32b5403803:   call   0x00007d32d4700830           ;   {runtime_call SharedRuntime::OSR_migration_end(long*)}\n  0x00007d32b5403808:   mov    0x20(%rsp),%ecx\n  0x00007d32b540380c:   mov    %rcx,%rbx\n  0x00007d32b540380f:   mov    0x24(%rsp),%edx\n  0x00007d32b5403813:   mov    %rdx,%rdi\n  0x00007d32b5403816:   mov    0x28(%rsp),%rax\n  0x00007d32b540381b:   mov    %rax,%rsi\n  0x00007d32b540381e:   mov    0x30(%rsp),%eax\n  0x00007d32b5403822:   jmp    0x00007d32b5403791\n  0x00007d32b5403827:   movabs $0x7d323f4006c0,%r10         ;   {metadata({method} {0x00007d323f4006c0} 'TestSpeed' '([I)I' in 'org/example/App')}\n  0x00007d32b5403831:   mov    %r10,0x8(%rsp)\n  0x00007d32b5403836:   movq   $0xffffffffffffffff,(%rsp)\n  0x00007d32b540383e:   call   0x00007d32bca2f280           ; ImmutableOopMap {rsi=Oop }\n                                                            ;*synchronization entry\n                                                            ; - org.example.App::TestSpeed@-1 (line 30)\n                                                            ;   {runtime_call counter_overflow Runtime1 stub}\n  0x00007d32b5403843:   jmp    0x00007d32b54036f4\n  0x00007d32b5403848:   call   0x00007d32bca295a0           ; ImmutableOopMap {rsi=Oop }\n                                                            ;*arraylength {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@5 (line 31)\n                                                            ;   {runtime_call throw_null_pointer_exception Runtime1 stub}\n  0x00007d32b540384d:   call   0x00007d32bca295a0           ; ImmutableOopMap {rsi=Oop }\n                                                            ;*iaload {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@19 (line 31)\n                                                            ;   {runtime_call throw_null_pointer_exception Runtime1 stub}\n  0x00007d32b5403852:   call   0x00007d32bca295a0           ; ImmutableOopMap {rsi=Oop }\n                                                            ;*iaload {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@19 (line 31)\n                                                            ;   {runtime_call throw_null_pointer_exception Runtime1 stub}\n  0x00007d32b5403857:   mov    %rbx,(%rsp)\n  0x00007d32b540385b:   mov    %rsi,0x8(%rsp)\n  0x00007d32b5403860:   call   0x00007d32bca28ca0           ; ImmutableOopMap {rsi=Oop }\n                                                            ;*iaload {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@19 (line 31)\n                                                            ;   {runtime_call throw_range_check_failed Runtime1 stub}\n  0x00007d32b5403865:   movabs $0x7d323f4006c0,%r10         ;   {metadata({method} {0x00007d323f4006c0} 'TestSpeed' '([I)I' in 'org/example/App')}\n  0x00007d32b540386f:   mov    %r10,0x8(%rsp)\n  0x00007d32b5403874:   movq   $0x23,(%rsp)\n  0x00007d32b540387c:   call   0x00007d32bca2f280           ; ImmutableOopMap {rsi=Oop }\n                                                            ;*goto {reexecute=1 rethrow=0 return_oop=0}\n                                                            ; - (reexecute) org.example.App::TestSpeed@35 (line 31)\n                                                            ;   {runtime_call counter_overflow Runtime1 stub}\n  0x00007d32b5403881:   jmp    0x00007d32b5403777\n  0x00007d32b5403886:   movabs $0x7d32b54037c8,%r10         ;   {internal_word}\n  0x00007d32b5403890:   mov    %r10,0x358(%r15)\n  0x00007d32b5403897:   jmp    0x00007d32bc98e700           ;   {runtime_call SafepointBlob}\n  0x00007d32b540389c:   nop\n  0x00007d32b540389d:   nop\n  0x00007d32b540389e:   mov    0x3d0(%r15),%rax\n  0x00007d32b54038a5:   movq   $0x0,0x3d0(%r15)\n  0x00007d32b54038b0:   movq   $0x0,0x3d8(%r15)\n  0x00007d32b54038bb:   add    $0x40,%rsp\n  0x00007d32b54038bf:   pop    %rbp\n  0x00007d32b54038c0:   jmp    0x00007d32bc99b600           ;   {runtime_call unwind_exception Runtime1 stub}\n  0x00007d32b54038c5:   hlt    \n  0x00007d32b54038c6:   hlt    \n ... many hlt instructions as padding ...\n  0x00007d32b54038df:   hlt\n[Exception Handler]\n  0x00007d32b54038e0:   call   0x00007d32bca2b980           ;   {no_reloc}\n  0x00007d32b54038e5:   movabs $0x7d32d49cbfc8,%rdi         ;   {external_word}\n  0x00007d32b54038ef:   and    $0xfffffffffffffff0,%rsp\n  0x00007d32b54038f3:   call   0x00007d32d451c6f0           ;   {runtime_call MacroAssembler::debug64(char*, long, long*)}\n  0x00007d32b54038f8:   hlt    \n[Deopt Handler Code]\n  0x00007d32b54038f9:   movabs $0x7d32b54038f9,%r10         ;   {section_word}\n  0x00007d32b5403903:   push   %r10\n  0x00007d32b5403905:   jmp    0x00007d32bc98d9a0           ;   {runtime_call DeoptimizationBlob}\n  0x00007d32b540390a:   hlt\n  0x00007d32b540390b:   hlt\n  0x00007d32b540390c:   hlt\n  0x00007d32b540390d:   hlt\n  0x00007d32b540390e:   hlt\n  0x00007d32b540390f:   hlt\n--------------------------------------------------------------------------------\n[/Disassembly]\n</code></pre>\n<p>(This section added by @PeterCordes.)</p>\n<p>The C1 code doesn't use any <code>cmovcc</code> (conditional-move) or <code>setcc</code> (condition into 0/1 integer) instructions.  It looks like it's just branching over <code>inc</code> instructions.</p>\n<p>The C2 code does if-conversion (from branchy source to branchless assembly), avoiding the slowdown of branch mispredictions on your random data.  (<em><a href=\"https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster\">Why is processing a sorted array faster than processing an unsorted array?</a></em> is a very similar problem, also looping over an array and conditionally adding.)  C# is probably not doing this, which would explain it being 5x slower.</p>\n<p>Java unrolls by 8, and does all 8 loads before any compares.  This is excessive; out-of-order exec and hardware prefetch will already do a good job here; it could have avoided saving/restoring so many registers outside the loop by using <code>cmp</code> with memory.  (It also costs some I-cache footprint, but the JIT compiler knows this is a long-running very hot loop.)</p>\n<p>Once it has values loaded, the <code>if(element &gt; 100) { count++; }</code> is implemented as <code>count = (element&gt;100) ? count+1 : count;</code>, with blocks of asm like this:</p>\n<pre><code># count in EDX, element in EDI\n   mov    %edx,%r11d\n   inc    %r11d            # r11d = edx+1.  Could have been an lea 1(%rdx), %r11d\n   cmp    $0x64,%edi       # compare element against 100\n   cmovle %edx,%r11d       # keep the un-incremented count if 100 &gt;= element\n# next block uses count = r11d\n</code></pre>\n<p>This has critical path latency of at least 2 cycles from old count to new count (through the <code>mov</code> + <code>inc</code> + <code>cmov</code>).  3 cycles on CPUs that don't do <a href=\"https://stackoverflow.com/questions/44169342/can-x86s-mov-really-be-free-why-cant-i-reproduce-this-at-all\">mov-elimination</a>, like Ice Lake (disabled for errata) and AMD Bulldozer-family.  (Zen 1 does do mov-elimination on integer and XMM registers).  So the bottleneck is one compare+increment per 2 clock cycles, and Zen 1 should achieve that even with <code>int</code>s coming all the way from DRAM, even without loop unrolling.</p>\n<p>It would be faster to generate a 0 / 1 integer from the compare and add that.  Like <code>cmp $100, %edi</code> ; <code>setg %al</code> / <code>add %eax, %edx</code>.  (Assuming EAX is xor-zeroed once per unrolled loop.)  3 single-uop instructions vs. 4, but more importantly the critical path latency through <code>count</code> is only 1 cycle, an <code>add</code>.  Out-of-order exec can handle the <code>cmp</code>/<code>setg</code> work as soon as <code>element</code> is ready, not needing <code>count</code>.</p>\n<p>If Java had the value-range information to realize this could be an unsigned compare, it could have used <code>cmp $101, %edi</code> ; <code>sbb $-1, %edx</code> (to add 1 if no carry, or add 0 if carry, when <code>x</code> is unsigned-below 101). Converting from bytes to int on the fly would give the compiler more info, and avoid a separate unpack loop + cache footprint.  But HotSpot isn't even looking for LEA as a copy-and-add peephole optimization, so probably won't try to use CF instead of materializing a 0/1 integer.</p>\n<p>See also <em><a href=\"https://stackoverflow.com/questions/28875325/gcc-optimization-flag-o3-makes-code-slower\">gcc optimization flag -O3 makes code slower than -O2</a></em> for a very similar case of branchless code-gen with a longer critical path than necessary.</p>\n<p>TL:DR: Java could be going about twice as fast if it did <code>count += (int)(element &gt; 100)</code> instead of <code>count = (element&gt;100) ? count+1 : count;</code>.<br />\nAuto-vectorizing with SIMD could go <em>much</em> faster, like GCC and Clang do.</p>\n<p>C2 disassembly:</p>\n<pre><code>============================= C2-compiled nmethod ==============================\n----------------------------------- Assembly -----------------------------------\n\nCompiled method (c2)     503   21 %     4       org.example.App::TestSpeed @ 10 (40 bytes)\n total in heap  [0x00007d32bcecc090,0x00007d32bcecc6c0] = 1584\n relocation     [0x00007d32bcecc1f0,0x00007d32bcecc208] = 24\n main code      [0x00007d32bcecc220,0x00007d32bcecc4a0] = 640\n stub code      [0x00007d32bcecc4a0,0x00007d32bcecc4b8] = 24\n oops           [0x00007d32bcecc4b8,0x00007d32bcecc4c0] = 8\n metadata       [0x00007d32bcecc4c0,0x00007d32bcecc4d0] = 16\n scopes data    [0x00007d32bcecc4d0,0x00007d32bcecc568] = 152\n scopes pcs     [0x00007d32bcecc568,0x00007d32bcecc6a8] = 320\n dependencies   [0x00007d32bcecc6a8,0x00007d32bcecc6b0] = 8\n nul chk table  [0x00007d32bcecc6b0,0x00007d32bcecc6c0] = 16\n\n[Disassembly]\n--------------------------------------------------------------------------------\n[Constant Pool (empty)]\n\n--------------------------------------------------------------------------------\n\n[Verified Entry Point]\n  # {method} {0x00007d323f4006c0} 'TestSpeed' '([I)I' in 'org/example/App'\n  0x00007d32bcecc220:   call   0x00007d32d463d440           ;   {runtime_call os::breakpoint()}\n  0x00007d32bcecc225:   data16 data16 nopw 0x0(%rax,%rax,1)\n  0x00007d32bcecc230:   mov    %eax,-0x14000(%rsp)\n  0x00007d32bcecc237:   push   %rbp\n  0x00007d32bcecc238:   sub    $0x30,%rsp\n  0x00007d32bcecc23c:   mov    0x18(%rsi),%r14\n  0x00007d32bcecc240:   mov    0x20(%rsi),%ebp\n  0x00007d32bcecc243:   mov    0x10(%rsi),%r13d\n  0x00007d32bcecc247:   mov    0x8(%rsi),%ebx\n  0x00007d32bcecc24a:   mov    %rsi,%rdi\n  0x00007d32bcecc24d:   movabs $0x7d32d4700830,%r10\n  0x00007d32bcecc257:   call   *%r10\n  0x00007d32bcecc25a:   nopw   0x0(%rax,%rax,1)\n  0x00007d32bcecc260:   mov    0x8(%r14),%r11d              ; implicit exception: dispatches to 0x00007d32bcecc47c\n  0x00007d32bcecc264:   cmp    $0x6c38,%r11d                ;   {metadata({type array int})}\n  0x00007d32bcecc26b:   jne    0x00007d32bcecc464           ;*iload {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@10 (line 31)\n  0x00007d32bcecc271:   cmp    %r13d,%ebx\n  0x00007d32bcecc274:   jge    0x00007d32bcecc42a           ;*if_icmpge {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@13 (line 31)\n  0x00007d32bcecc27a:   mov    0xc(%r14),%r10d\n  0x00007d32bcecc27e:   mov    %ebx,%r11d\n  0x00007d32bcecc281:   inc    %r11d\n  0x00007d32bcecc284:   movslq %r11d,%r8\n  0x00007d32bcecc287:   xor    %r9d,%r9d\n  0x00007d32bcecc28a:   test   %r11d,%r11d\n  0x00007d32bcecc28d:   cmovl  %r9,%r8\n  0x00007d32bcecc291:   mov    %r8d,%r11d\n  0x00007d32bcecc294:   cmp    %r13d,%r11d\n  0x00007d32bcecc297:   cmovg  %r13d,%r11d                  ;*iaload {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@19 (line 31)\n  0x00007d32bcecc29b:   nopl   0x0(%rax,%rax,1)\n  0x00007d32bcecc2a0:   cmp    %r10d,%ebx\n  0x00007d32bcecc2a3:   jae    0x00007d32bcecc444\n  0x00007d32bcecc2a9:   mov    0x10(%r14,%rbx,4),%r9d\n  0x00007d32bcecc2ae:   mov    %ebp,%edx\n  0x00007d32bcecc2b0:   inc    %edx\n  0x00007d32bcecc2b2:   cmp    $0x64,%r9d\n  0x00007d32bcecc2b6:   cmovle %ebp,%edx\n  0x00007d32bcecc2b9:   inc    %ebx                         ;*iinc {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@32 (line 31)\n  0x00007d32bcecc2bb:   nopl   0x0(%rax,%rax,1)\n  0x00007d32bcecc2c0:   cmp    %r11d,%ebx\n  0x00007d32bcecc2c3:   jge    0x00007d32bcecc2c9           ;*if_icmpge {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@13 (line 31)\n  0x00007d32bcecc2c5:   mov    %edx,%ebp\n  0x00007d32bcecc2c7:   jmp    0x00007d32bcecc29b\n  0x00007d32bcecc2c9:   movslq %r10d,%r11\n  0x00007d32bcecc2cc:   movslq %r13d,%r8\n  0x00007d32bcecc2cf:   cmp    %r11,%r8\n  0x00007d32bcecc2d2:   cmovl  %r8,%r11\n  0x00007d32bcecc2d6:   add    $0xfffffffffffffff9,%r11\n  0x00007d32bcecc2da:   mov    $0xffffffff80000000,%r8\n  0x00007d32bcecc2e1:   cmp    $0xffffffff80000000,%r11\n  0x00007d32bcecc2e8:   cmovl  %r8,%r11\n  0x00007d32bcecc2ec:   mov    %r11d,%r11d\n  0x00007d32bcecc2ef:   cmp    %r11d,%ebx\n  0x00007d32bcecc2f2:   jge    0x00007d32bcecc3fa           ;*goto {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@35 (line 31)\n  0x00007d32bcecc2f8:   jmp    0x00007d32bcecc31b\n  0x00007d32bcecc2fa:   mov    0x348(%r15),%r10             ; ImmutableOopMap {r14=Oop }\n                                                            ;*goto {reexecute=1 rethrow=0 return_oop=0}\n                                                            ; - (reexecute) org.example.App::TestSpeed@35 (line 31)\n  0x00007d32bcecc301:   test   %eax,(%r10)                  ;*goto {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@35 (line 31)\n                                                            ;   {poll}\n  0x00007d32bcecc304:   cmp    (%rsp),%ebx\n  0x00007d32bcecc307:   jge    0x00007d32bcecc3f0\n  0x00007d32bcecc30d:   vmovd  %xmm0,%r13d\n  0x00007d32bcecc312:   vmovd  %xmm1,%r10d\n  0x00007d32bcecc317:   mov    (%rsp),%r11d\n  0x00007d32bcecc31b:   mov    %r11d,%ebp\n  0x00007d32bcecc31e:   sub    %ebx,%ebp\n  0x00007d32bcecc320:   xor    %r9d,%r9d\n  0x00007d32bcecc323:   cmp    %ebx,%r11d\n  0x00007d32bcecc326:   cmovl  %r9d,%ebp\n  0x00007d32bcecc32a:   cmp    $0x1f40,%ebp\n  0x00007d32bcecc330:   mov    $0x1f40,%r9d\n  0x00007d32bcecc336:   cmova  %r9d,%ebp\n  0x00007d32bcecc33a:   add    %ebx,%ebp\n  0x00007d32bcecc33c:   vmovd  %r13d,%xmm0\n  0x00007d32bcecc341:   vmovd  %r10d,%xmm1\n  0x00007d32bcecc346:   mov    %r11d,(%rsp)\n  0x00007d32bcecc34a:   nopw   0x0(%rax,%rax,1)             ;*iaload {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@19 (line 31)\n  0x00007d32bcecc350:   mov    0x10(%r14,%rbx,4),%r10d\n  0x00007d32bcecc355:   movslq %ebx,%rsi\n  0x00007d32bcecc358:   mov    0x2c(%r14,%rsi,4),%r13d\n  0x00007d32bcecc35d:   mov    0x14(%r14,%rsi,4),%r11d\n  0x00007d32bcecc362:   mov    0x28(%r14,%rsi,4),%r9d\n  0x00007d32bcecc367:   mov    0x24(%r14,%rsi,4),%r8d\n  0x00007d32bcecc36c:   mov    0x20(%r14,%rsi,4),%edi\n  0x00007d32bcecc371:   mov    0x1c(%r14,%rsi,4),%ecx\n  0x00007d32bcecc376:   mov    0x18(%r14,%rsi,4),%eax\n  0x00007d32bcecc37b:   mov    %edx,%esi\n  0x00007d32bcecc37d:   inc    %esi\n  0x00007d32bcecc37f:   cmp    $0x64,%r10d\n  0x00007d32bcecc383:   cmovle %edx,%esi\n  0x00007d32bcecc386:   mov    %esi,%edx\n  0x00007d32bcecc388:   inc    %edx\n  0x00007d32bcecc38a:   cmp    $0x64,%r11d\n  0x00007d32bcecc38e:   cmovle %esi,%edx\n  0x00007d32bcecc391:   mov    %edx,%r11d\n  0x00007d32bcecc394:   inc    %r11d\n  0x00007d32bcecc397:   cmp    $0x64,%eax\n  0x00007d32bcecc39a:   cmovle %edx,%r11d\n  0x00007d32bcecc39e:   mov    %r11d,%edx\n  0x00007d32bcecc3a1:   inc    %edx\n  0x00007d32bcecc3a3:   cmp    $0x64,%ecx\n  0x00007d32bcecc3a6:   cmovle %r11d,%edx\n  0x00007d32bcecc3aa:   mov    %edx,%r11d\n  0x00007d32bcecc3ad:   inc    %r11d\n  0x00007d32bcecc3b0:   cmp    $0x64,%edi\n  0x00007d32bcecc3b3:   cmovle %edx,%r11d\n  0x00007d32bcecc3b7:   mov    %r11d,%r10d\n  0x00007d32bcecc3ba:   inc    %r10d\n  0x00007d32bcecc3bd:   cmp    $0x64,%r8d\n  0x00007d32bcecc3c1:   cmovle %r11d,%r10d\n  0x00007d32bcecc3c5:   mov    %r10d,%r8d\n  0x00007d32bcecc3c8:   inc    %r8d\n  0x00007d32bcecc3cb:   cmp    $0x64,%r9d\n  0x00007d32bcecc3cf:   cmovle %r10d,%r8d\n  0x00007d32bcecc3d3:   mov    %r8d,%edx\n  0x00007d32bcecc3d6:   inc    %edx\n  0x00007d32bcecc3d8:   cmp    $0x64,%r13d\n  0x00007d32bcecc3dc:   cmovle %r8d,%edx\n  0x00007d32bcecc3e0:   add    $0x8,%ebx                    ;*iinc {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@32 (line 31)\n  0x00007d32bcecc3e3:   cmp    %ebp,%ebx\n  0x00007d32bcecc3e5:   jl     0x00007d32bcecc350           ;*if_icmpge {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@13 (line 31)\n  0x00007d32bcecc3eb:   jmp    0x00007d32bcecc2fa\n  0x00007d32bcecc3f0:   vmovd  %xmm0,%r13d\n  0x00007d32bcecc3f5:   vmovd  %xmm1,%r10d\n  0x00007d32bcecc3fa:   nopw   0x0(%rax,%rax,1)\n  0x00007d32bcecc400:   cmp    %r13d,%ebx\n  0x00007d32bcecc403:   jge    0x00007d32bcecc460\n  0x00007d32bcecc409:   jmp    0x00007d32bcecc40e\n  0x00007d32bcecc40b:   nop\n  0x00007d32bcecc40c:   mov    %ebp,%edx                    ;*iaload {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@19 (line 31)\n  0x00007d32bcecc40e:   cmp    %r10d,%ebx\n  0x00007d32bcecc411:   jae    0x00007d32bcecc446\n  0x00007d32bcecc413:   mov    0x10(%r14,%rbx,4),%r11d\n  0x00007d32bcecc418:   mov    %edx,%ebp\n  0x00007d32bcecc41a:   inc    %ebp\n  0x00007d32bcecc41c:   cmp    $0x64,%r11d\n  0x00007d32bcecc420:   cmovle %edx,%ebp\n  0x00007d32bcecc423:   inc    %ebx                         ;*iinc {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@32 (line 31)\n  0x00007d32bcecc425:   cmp    %r13d,%ebx\n  0x00007d32bcecc428:   jl     0x00007d32bcecc40c           ;*if_icmpge {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@13 (line 31)\n  0x00007d32bcecc42a:   mov    $0xffffff45,%esi\n  0x00007d32bcecc42f:   mov    %r14,(%rsp)\n  0x00007d32bcecc433:   mov    %ebx,0x10(%rsp)\n  0x00007d32bcecc437:   mov    %r13d,0x14(%rsp)\n  0x00007d32bcecc43c:   data16 xchg %ax,%ax\n  0x00007d32bcecc43f:   call   0x00007d32bc98d600           ; ImmutableOopMap {[0]=Oop }\n                                                            ;*if_icmpge {reexecute=1 rethrow=0 return_oop=0}\n                                                            ; - (reexecute) org.example.App::TestSpeed@13 (line 31)\n                                                            ;   {runtime_call UncommonTrapBlob}\n  0x00007d32bcecc444:   mov    %ebp,%edx\n  0x00007d32bcecc446:   mov    $0xffffffe4,%esi\n  0x00007d32bcecc44b:   mov    %edx,%ebp\n  0x00007d32bcecc44d:   mov    %r13d,0x8(%rsp)\n  0x00007d32bcecc452:   mov    %r14,0x10(%rsp)\n  0x00007d32bcecc457:   mov    %ebx,0x18(%rsp)\n  0x00007d32bcecc45b:   call   0x00007d32bc98d600           ; ImmutableOopMap {[16]=Oop }\n                                                            ;*iaload {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@19 (line 31)\n                                                            ;   {runtime_call UncommonTrapBlob}\n  0x00007d32bcecc460:   mov    %edx,%ebp\n  0x00007d32bcecc462:   jmp    0x00007d32bcecc42a\n  0x00007d32bcecc464:   mov    $0xffffff8d,%esi\n  0x00007d32bcecc469:   mov    %r14,(%rsp)\n  0x00007d32bcecc46d:   mov    %r13d,0x8(%rsp)\n  0x00007d32bcecc472:   mov    %ebx,0xc(%rsp)\n  0x00007d32bcecc476:   nop\n  0x00007d32bcecc477:   call   0x00007d32bc98d600           ; ImmutableOopMap {[0]=Oop }\n                                                            ;*iload {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@10 (line 31)\n                                                            ;   {runtime_call UncommonTrapBlob}\n  0x00007d32bcecc47c:   mov    $0xffffff76,%esi\n  0x00007d32bcecc481:   mov    %r13d,(%rsp)\n  0x00007d32bcecc485:   mov    %ebx,0x4(%rsp)\n  0x00007d32bcecc489:   xchg   %ax,%ax\n  0x00007d32bcecc48b:   call   0x00007d32bc98d600           ; ImmutableOopMap {}\n                                                            ;*iload {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - org.example.App::TestSpeed@10 (line 31)\n                                                            ;   {runtime_call UncommonTrapBlob}\n  0x00007d32bcecc490:   hlt\n  ... 14 more hlt instructions ...\n  0x00007d32bcecc49f:   hlt\n[Exception Handler]\n  0x00007d32bcecc4a0:   jmp    0x00007d32bc99bc00           ;   {no_reloc}\n[Deopt Handler Code]\n  0x00007d32bcecc4a5:   call   0x00007d32bcecc4aa\n  0x00007d32bcecc4aa:   subq   $0x5,(%rsp)\n  0x00007d32bcecc4af:   jmp    0x00007d32bc98d9a0           ;   {runtime_call DeoptimizationBlob}\n  0x00007d32bcecc4b4:   hlt\n  0x00007d32bcecc4b5:   hlt\n  0x00007d32bcecc4b6:   hlt\n  0x00007d32bcecc4b7:   hlt\n--------------------------------------------------------------------------------\n[/Disassembly]\n</code></pre>\n",
    "score" : 26,
    "is_accepted" : true,
    "owner" : {
      "account_id" : 19118721,
      "reputation" : 12499,
      "user_id" : 13963086,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/9df2c3c4c87d8050b8fd6a59c88c7133?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "k314159",
      "link" : "https://stackoverflow.com/users/13963086/k314159"
    },
    "creation_date" : 1750691148,
    "last_activity_date" : 1750829473,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "answer_id" : 79680585,
    "question_id" : 79675833,
    "body" : "<p><strong>TL:DR/summary:</strong> C# is slow because of branch mispredicts, but writing the source differently can fix that.  Java makes branchless scalar asm which is ok but about 2x (or more) slower than it could be.  Everyone's been focusing on loop unrolling but that's irrelevant here due to the loop-carried dependency-chain latency bottleneck for Java's branchless strategy.</p>\n<p>C/C++ compilers (GCC and Clang) auto-vectorize in a fairly clunky way, but still much faster, or make pretty good branchless scalar asm if you tell them not to vectorize.  Manually vectorizing with intrinsics for SSE2, AVX2, or NEON can go even faster (in C# or C++ or C or any language with usable intrinsics for packed-compares and arch-specific tricks like <code>psadbw</code> to horizontal sum bytes).  About 1 vector (16 or 32 bytes) per clock cycle if memory bandwidth weren't a bottleneck. (32 elements, or only 8 if you unpacked your bytes to <code>int</code>s.)</p>\n<hr />\n<h2>C# makes branchy assembly for your <code>if</code>, so your random pattern of elements to be counted causes branch mispredicts</h2>\n<p>To make your C# code faster than Java (or at least equal), use this:</p>\n<pre class=\"lang-cs prettyprint-override\"><code>   count += (element &gt; 100) ? 1 : 0;  // C# or Java\n</code></pre>\n<p>(<a href=\"https://sharplab.io/#v2:EYLgHgbALANALiAhgZwLYB8ACAmAjAWAChMBmAAhzIGEyBvIsxpxgBwCcBLAN0TgFMKuCGQ4A7OGQAqfZHADKLPnwAmACjFwA2gF0yiNm0QBPAJQNmTeoQs2yAejscAZmVX7DRsgF4vZUQFcAG0CTMjgACzYAewB3Pz44gEE2AHN/VD5xADkgwIBRMABjPhY4DijRVRMAbnNbJgdnV3djADoAGUyUiO9fAAZQiOi40QSyZLSM8QLi0vLKmrr6kXEyQqj/Vf7a62XGJyi2PkRC8NcNMj5AvimJMT0DYzNdvas9mybVK5vMiQA+Mi4PoDJbvOigsFMdabOAAalhO0hTAAvhCbKiXstMAB2NYbcSI2wYtFkdjcXgCTBCFYSaSyBRKZQAfWAhlEp2uyGQLKM/GQqmAvL4OgeHme9Te70aLjcj08Pj8uUGkVi8SSqXSvxywRmJTKFSqhL20uaco6XR6CoGYRVIzGE010yKevmhpJzAu0K2ZD6RuWByOJzO6lW31uK1FT3dlmjNgcZEF/BEyDIm2QHBSo2UEaoAGJWoxJOEOCn1qgWBxOWEomRUFEuAAvMBkBt8aIAWj4YH4omUYhSZECUUQymQBbIyETAhLE4zWYTQuQsYsXoksN8X2u4YBQOtAH5AWQQD6/fUMWCcXiYaeUUQSWSeEmqcILnT5IoVCy2RyZNzCnWuB5PkBSFEUWlMElJWNRwZXA3pFWCZVhjVcYNVubV8mdOYDUWTF6hNWUPHNURujOK0kNVUZ1UmX5dWwhYbw+VZV28E9lwDY5TnOUMt1+CNwPFd4oMheMAClEB4AByFNZEMfgUiMcc8zxctKxkEQJDgGtWUQdlwhkGAyFExIyHrNs9CMgBZAAFMgYmLLiZzEZBdL4cdVBM0RDlQRBAlJNtkAqOyNkCbN/GQARRIAITyQSkXjIsZxiELs1kSs/OAARkrYCLLi4TIRBcDgJD7bMywra5q2oGy7HaPJEjsKhLIAeQANWXZgWI3MM+J3YFQgPVdYVwI8rwJCwEuLFMksOCLDOUCpJJKmsIhLZdz3eS9V0YshiUIPa70IIA\" rel=\"nofollow noreferrer\">Sharplab.io with x64 asm for this and the original</a>).<br />\nC# .NET Framework for x64 compiles this to <code>cmp</code> ; <code>setg</code>(0/1 byte) ; <code>movzx</code>(zero-extend to 32-bit) ; <code>add</code>.  Not ideal asm (movzx could be avoided by zeroing a reg outside the loop, or even using <code>cmp</code>/<code>sbb $-1, %reg</code> like GCC and Clang do), but still better than Java's worse branchless strategy which has longer critical-path latency for the loop-carried dependency chain through <code>count</code>.  The above code might hand-hold Java into making better asm, which could make its loop unrolling useful.</p>\n<pre class=\"lang-cs prettyprint-override\"><code>   // Java's if-conversion strategy.  C# compiles it to worse branching than the if!\n   // and it would still be worse than the above for this use-case if it compiled as written, to cmp/lea/cmov\n   count = (element &gt; 100) ? count+1 : count;    // This is worse, don't do this\n</code></pre>\n<p>This also works on <code>byte[] array</code> data without any special tricks, since C# <code>byte</code> is unsigned like <code>uint</code>.  Widening u8 on the fly to i32 or u32 is very cheap on modern CPUs, same cost as 32-bit load.  It's a total disaster for overall performance to allocate another 4x as much memory and expand into it before doing any useful work on your data, but you left that loop out of your timed region.  Usually you want to aim for <em>more</em> computational intensity: more work per time your data gets loaded into L1d cache or into registers.  And keeping your data in a compact representation and not copying it (let alone expanding it) means a smaller cache footprint and less memory traffic for the same amount of work.</p>\n<p>In Java, hopefully the JIT does something good with <code>int elem = 0xFF &amp; (int)elem_byte;</code>.  But even if it's dumb and uses <code>movsx</code> (sign-extending load) + <code>and</code>, instead of <code>movzx</code> (zero-extending load) or simply <code>cmp byte [mem], 100</code>, it's still cheaper to do this as part of the compare loop.  It does make things maybe less comparable between C# and Java if you want to know how they perform for a loop where they more easily could have made the same asm.  Timing a loop over the byte array would include the Java &quot;tax&quot; in what you're microbenchmarking for the language which doesn't provide unsigned 8-bit integers, if it fails to optimize source which could still compile to unsigned compares on bytes.</p>\n<hr />\n<h2>Branch mispredictions</h2>\n<p>See <em><a href=\"https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array\">Why is processing a sorted array faster than processing an unsorted array?</a></em> for details about that.  (When that question was asked, C++ and Java compilers were like C# is now, making branchy machine code from source that uses a similar <code>if()</code>.  It's a <em>very</em> similar problem, doing <code>if (elem &gt;= 128) sum += elem;</code> instead of <code>if (elem &gt; 100) ++count;</code>.  C++ compilers now auto-vectorize, and Java makes branchless asm.)</p>\n<p><strong>Branch mispredicts account for most if not all of the 5x speed difference.</strong> Java's unrolling is pretty much irrelevant, especially on your Zen 1 CPU (pipeline is 5 uops wide), especially the slow way Java made branchless code with a 2 cycle critical path latency instead of 1.</p>\n<hr />\n<h2>C#'s asm</h2>\n<p><a href=\"https://Sharplab.io/\" rel=\"nofollow noreferrer\">https://Sharplab.io/</a> AFAIK gets the .NET framework JIT to optimize as much as possible.  It doesn't run your code, since it still works when you give it just a function with no caller that would pass it the right data, so unlike the HotSpot JIT or <code>gcc -fprofile-generate</code>/<code>-fprofile-use</code> or similar PGO (Profile-Guided Optimization) options, it doesn't have profiling information to let it know which branches are unpredictable or which loops are hot (and thus worth unrolling at the cost of more binary size and I-cache / I-TLB footprint, and worth spending more compile time on to run more optimization passes.)  GCC <code>-O3</code> doesn't enable <code>-funroll-loops</code> either; <code>-funroll-loops</code> is only on manually or as part of <code>-fprofile-use</code> PGO.  Clang does unroll by default, but only for small loops; the fewer instructions in the loop body, the more it unrolls.</p>\n<p>Anyway, C#'s inner loop from the <code>if()</code> version of the function looks like this.  Even though the source uses <code>foreach (int element in array)</code>, the compiler invents a 32-bit array index and redoes sign-extension to 64-bit every iteration.  With crap likes this, no wonder there's such benefit to wide pipelines in modern CPUs.</p>\n<p>Update: .NET x64 (<em>not</em> framework) on <a href=\"https://sharplab.io/#v2:EYLgxg9gTgpgtADwGwBYA0AXEBDAzgWwB8ABAJgEYBYAKGIAYACY8gOgDkBXfGKASzFwBuGvSasAShwB2GXtxYBJGTwgAHAMo8AbvxhCRAZiakGAYQYBvGgxsNrth6r5bsGGGKQNeMhgBU9GOqqMDAAJgAU3hgA2gC6DNhQUNgAngCU9g42VtRZeQwA9AW8AGYM4YnJKQwAvDUMUhwANk1pDBgAFlAQAO4NMH0AglAA5lwwMpwtAKIIYDCqshBS4WnCufkORaXllaksADITI5219XRtnd19UgMMw2PcMrPzi7zLq+ubDlEMkNIYWoMOhfb42ErQGDYMAdcq/GBNGBPQHeBJJVIZDZgnJgvI7cIIpETQEAPgY5DoF0yuOy1JpDn+MgA1EzQfSGABfOn5LlY77EADsfwgALZWV53JsTl4LjcHi8Pn8uECwTCAH1gMkpDDEbhcBqUm5cOFgIaYHE0VVMZscbjtmUKujqnUGs1Wu0ur1+kNRuNJm6Xgslis1pKsvbdk7DsdTi6Lh7rt77r7kYG3h9Q3zNr9GYDzmLNhDYNDYZEfITkQrLRiww5beyigxTXLeLgGNJcLwRrdQlXTABiFg2XwdVvC/CqXi69oQBj4CBaABeCAYi5UcBgCDcUlC3hGDCaEGwoVwQ4YuGb7jHne7YSbZtwtfyuYYTPqBMRlbJFPjAH5yQwIDAgWPJPjYgrCqKYYSlmtjSrK7jMJ4vxKiqIShBqWo6no+pgPOWgGkaJpmhaezpGG9bfBGjpVGcrotJcno3HcDx+hgUxNGmwafGBhTFA6ZHRlIJywnGjGJrcPqPMSXHvCGIF4j4L75rxRZQjCcLlp+xJVmR1q4pRNKNgAUtgLgAORtsqyRuCMKRngO46TtOvCAhgs6atg2odHoaAMMZgwMAuPAJP5ACyAAKDA9KOGljt4uBeTAZ7hIFUjQPg2BNAwwRQLgyzRSKTS9hwuDuMZABC0z6Q2BR+KObY9EVvbKlO2XAO4TV5e4MBaBMXhlK5DC7r2kATlO7juWYkUFAc0yDAUphhQA8gAarxDIij474Vjp36Um0/65ky5CAZBMiCOGdUjvFjXQGVfmhMs5mAk9HqtrxvI0hBuYKZyNA0DBAPUEAA==\" rel=\"nofollow noreferrer\">Sharplab</a> (<code>; Core CLR 9.0.525.21509 on x64</code>) makes less clunky asm, avoiding the <code>movsxd</code> sign-extension of an array index, and uses <code>cmp [mem], 100</code> instead of a separate load.  It also avoids an indexed addressing-mode for the branchy version, but unfortunately not for branchless.  And it still uses <code>cmp</code>/<code>setcc</code>/<code>movzx</code> instead of <code>xor</code>-zero/<code>cmp</code>/<code>setcc</code>.</p>\n<p>The asm below is from .NET Framework - <code>; Desktop CLR 4.8.9305.0 on x64</code> on <a href=\"https://sharplab.io/#v2:EYLgHgbALANALiAhgZwLYB8ACAmAjAWAChMBmAAhzIGEyBvIsxpxgBwCcBLAN0TgFMKuCGQ4A7OGQAqfZHADKLPnwAmACjFwA2gF0yiNm0QBPAJQNmTeoQs2yAejscAZmVX7DRsgF4vZUQFcAG0CTMjgACzYAewB3Pz44gEE2AHN/VD5xADkgwIBRMABjPhY4DijRVRMAbnNbJgdnV3djADoAGUyUiO9fAAZQiOi40QSyZLSM8QLi0vLKmrr6kXEyQqj/Vf7a62XGJyi2PkRC8NcNMj5AvimJMT0DYzNdvas9mybVK5vMiQA+Mi4PoDJbvOigsFMdabOAAalhO0hTAAvhCbKiXstMAB2NYbcSI2wYtFkdjcXgCTBCFYSaSyBRKZQAfWAhlEp2uyGQLKM/GQqmAvL4OgeHme9Te70aLjcj08Pj8uUGkVi8SSqXSvxywRmJTKFSqhL20uaco6XR6CoGYRVIzGE010yKevmhpJzAu0K2ZD6RuWByOJzO6lW31uK1FT3dlmjNgcZEF/BEyDIm2QHBSo2UEaoAGJWoxJOEOCn1qgWBxOWEomRUFEuAAvMBkBt8aIAWj4YH4omUYhSZECUUQymQBbIyETAhLE4zWYTQuQsYsXoksN8X2u4YBQOtAH5AWQQD6/fUMWCcXiYaeUUQSWSeEmqcILnT5IoVCy2RyZNzCnWuB5PkBSFEUWlMElJWNRwZXA3pFWCZVhjVcYNVubV8mdOYDUWTF6hNWUPHNURujOK0kNVUZ1UmX5dWwhYbw+VZV28E9lwDY5TnOUMt1+CNwPFd4oMheMAClEB4AByFNZEMfgUiMcc8zxctKxkEQJDgGtWUQdlwhkGAyFExIyHrNs9CMgBZAAFMgYmLLiZzEZBdL4cdVBM0RDlQRBAlJNtkAqOyNkCbN/GQARRIAITyQSkXjIsZxiELs1kSs/OAARkrYCLLi4TIRBcDgJD7bMywra5q2oGy7HaPJEjsKhLIAeQANWXZgWI3MM+J3YFQgPVdYVwI8rwJCwEuLFMksOCLDOUCpJJKmsIhLZdz3eS9V0YshiUIPa70IIA\" rel=\"nofollow noreferrer\">Sharplab</a>.</p>\n<pre><code># before this, zero idx and count, and branch over the loop if length==0\n                              # do {\n    L0010: movsxd r9, ecx           # sign-extend idx to pointer width for use in an addressing-mode\n    L0013: cmp dword [rdx+r9*4+0x10], 0x64   # array[idx]; I guess C# arrays have 16 bytes of metadata before the actual array.\n    L0019: jle L001d            # if (elem &lt;= 100) goto skip_increment\n    L001b: inc eax              # ++count\n    L001d: inc ecx              # ++idx\n    L001f: cmp r8d, ecx\n    L0022: jg L0010           # }while(length &gt; idx)\n</code></pre>\n<p>With the <code>count += (element&gt;100);</code> version, on a byte array:</p>\n<pre><code>                             # do{\n    L0010: movsxd r9, ecx\n    L0013: movzx r9d, byte [rdx+r9+0x10]  # separately load, with zero-extension.  Unscaled index this time because byte elements\n    L0019: cmp r9d, 0x64        # int compare\n    L001d: setg r9b             # r9b (low byte of R9) = 0 or 1, upper bits unmodified, g = signed Greater\n    L0021: movzx r9d, r9b       # zero-extend into the full R9 (explicitly to 32, implicitly to 64)\n    L0025: add eax, r9d         # count += cmp_result\n    L0028: inc ecx              # ++idx\n    L002a: cmp r8d, ecx\n    L002d: jg L0010           # }while(length &gt; idx)\n</code></pre>\n<p>With macro-fusion of <code>cmp</code>/<code>jg</code> into a single uop, this is 8 uops, 7 of which need an ALU execution unit.  (The load runs on a separate port).  Probably only Intel <a href=\"https://chipsandcheese.com/p/skymont-intels-e-cores-reach-for-the-sky\" rel=\"nofollow noreferrer\">Skymont E-cores</a> can run it at 1 compare per cycle; other cores will bottleneck on the front-end and/or integer ALU ports thanks to C# doing everything it could to waste instructions inside the loop, including redoing sign-extension (movsxd) of a 32-bit index despite using foreach (int element in array) instead of manual indexing. (Lion Cove P-cores and Zen 5 are 8-wide but &quot;only&quot; have 6 integer ALU ports, so close to 1/clock, unlike Skymont which is also 8-wide but has 8 integer ALU ports and 3 branch execution units.)</p>\n<p>(I don't know if Skymont can keep the <code>cmp</code> micro-fused into a single uop, with the indexed addressing mode and an immediate.  Skylake can't.  So it might even by 9 uops on most Intel CPUs, still 8 on AMD.)</p>\n<p>This is like an exercise in how many instructions we can waste inside the loop.  Redoing sign-extension of an index invented by the runtime is the most egregious sin, but that's present in the branchy version, too.  Loop unrolling would help with the branchless version; instruction throughput is the bottleneck for it on most CPUs.</p>\n<p>Even with an <code>int</code> array, we still get a separate <code>mov</code> instead of <code>cmp [mem], 100</code>.  Same amount of work for the back-end execution units, but takes more slots in other parts of the pipeline (decode, the reorder buffer (ROB), and issue/rename.  Or dispatch, to use the non-Intel terminology for sending a uop from the front-end to the back-end, as in the diagram of your CPU core in <a href=\"https://en.wikichip.org/wiki/amd/microarchitectures/zen#Individual_Core\" rel=\"nofollow noreferrer\">https://en.wikichip.org/wiki/amd/microarchitectures/zen#Individual_Core</a>)</p>\n<p>The choice of <code>movzx r9d, r9b</code> instead of into a different register like r10d defeats mov-elimination, so this instruction needs an execution unit.  (<a href=\"https://stackoverflow.com/questions/44169342/can-x86s-mov-really-be-free-why-cant-i-reproduce-this-at-all\">Intel CPUs since Ivy Bridge could otherwise eliminated it</a>.  But IIRC, AMD CPUs don't eliminate <code>movzx</code>, only 32 and 64-bit <code>mov reg,reg</code>, so that wouldn't have helped when tuning for your Zen 1.  What would have helped is xor-zeroing a register outside the loop and doing <code>setg</code> into the low byte of it.  That would create another loop-carried dependency chain since the low byte isn't renamed separately from the full register, except on old Intel P6-family, and <code>setcc</code> is inconveniently designed to only write a byte instead of a whole register width.  Intel APX will eventually fix that; until then see the <code>setcc</code> section of <em><a href=\"https://stackoverflow.com/questions/33666617/what-is-the-best-way-to-set-a-register-to-zero-in-x86-assembly-xor-mov-or-and\">What is the best way to set a register to zero in x86 assembly: xor, mov or and?</a></em>.  Unrolling and zeroing xor-zeroing a register once per 4 or more <code>setcc</code> instructions would be good.)</p>\n<p>Sharplab doesn't have an AArch64 target to check if it's using <code>cinc</code> (conditional-increment according to a flag condition).  AArch64 is perfect for this problem.</p>\n<p>Smarter compilers (like GCC or Clang, if told not to auto-vectorize: <a href=\"https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAMzwBtMA7AQwFtMQByARg9KtQYEAysib0QXACx8BBAKoBnTAAUAHpwAMvAFYgATKVpMGoZAFI9AIQuXSS%2BsgJ4BlRugDCqWgFcWDfRqkbgAyeAyYAHK%2BAEaYxCDSAA6oCoTODJ4%2BfgGkyalOAqHhUSyx8dL2mI7pQgRMxASZvv56gZXVArX1BEWRMXEJdnUNTdmtQ929JWUJAJR2qN7EyOwcFgDMYcg%2BWADUZuvuYsAkhAgsB9hmGgCCG1s7mPuHCgT4ggB0CJfXd7dhBF2aG8ggA%2BkxoqgAG6YLgaDSg6IATwImAUEG8AIAHKDAQAqdBMOqkXapABemFxu3qxCYSKEeAps1%2BZgA7NZbrsubsAUDFoJngARXYaA4cm7c3b8Yi7CDkymAvBCkVinnPdzU4i0%2BmMzCqmw2PCzfbs36SyV4Kiywl1MwAVkseHtwsuuzhGmZnPN3uBggNVjFZu5bMFQa5xEwBCWDD5IIIgduIZZif%2BAt9BFBwAI7tBAPWeggeb0VIJRKYJPlVJpdIZTJZpq9XN56eVovW4sl0tllcVrdVSoOGurOop%2BoDViNJo73p5VogNqY9sdzue2Dd8M9EpnkvT/us7bDJtDjd2EajxBju4PidZx5uHHmtE4dt4/g4WlIqE47j3pMWyyeDY9F4AhNAfeYAGsQHWO0PgATjtDQADYsS4dZWTtVl1nhO0kMMThJFfMDP04XgFBAQJQPfB9SDgWAkDQFhEjoOJyEoRjmPoeJtmMYBWjhPg6FRYhyIgaJiOiMJ6iRTgeFISTmGIJEAHlom0KoqLkxi2EEZSGFoGTqNILBom8YAjloWhyO4XgsBYXjxCM/AI2qGFrI/TBVCqbxUVk3gAUwJ8jNoPBolpJTPCwYiCGIPAWD80gYWISElEFTB7JMEKTDA%2BYqCMYAFAANTwTAAHdlMSRgEv4QQRDEdgpBkQRFBUdQjN0dZDF4lA90MULyMgeZUESAoGGsgBaZT1l2cb7OWb51kFVQsSQ8akMkcaoWm8aAHUxFoGaqAYVBNo004KV4aE4lirABogeZ2lG1wGA8LxmgkIIXqmfp4i4XIUjSARRn8P68kBhhvtKAY/semphkaN7shhwKNLhyYwj6KHfomEZEZBnGegx6ZoYe/8Vn0R9nyIoyvw4XZltW9agSMExdlaD4uA%2BDRZVwQgSH2PR81mECcvmBBMCYLB4nu0goOwj5WS4O04KxO09DgjQ4PWJCkM6oLCNIN8P1psiKNIKitHmOjEBQVAmJYsgKAgDiHZAYAlb%2BmhaGE0TxKMhTpISgOlNU9THAS7TGAIPSDOIkyzIsqyErshzVg/ZzUbc4jPO83ybPIQRAuIkKwukyK05A2L4vzpKUswNKMuALLQGo3L8qKkrysqt85Jq4RRHERq%2B5atRiN0P6WdMXqS7uoaRvSCappmubkAWpaVrWjatpmvbLK5cajpOmLMEwU7HHOzBLqSm60XgB6UY6fwIDcYH9GkEIiZ%2B/QDDB0bX70JIANRqQxmHoAwsNOjw3/hUB%2Bo0ugNBAQMMBBNoEE0QfEMBpMljkz0JTDgL5DbEVpvTDeTNgDIGQG6WCXAeb4CIDKICwtzai1ltBdYHx1icK4dw7h%2BEOAGyNpdUidgzYW3Anw4ChCabCLEbMeYSVUguEkEAA%3D\" rel=\"nofollow noreferrer\"><strong>Godbolt</strong></a>) do much better, even avoiding materializing a 0/1 integer in a register at all, but rather adding the carry flag directly from the compare result.  Or rather, subtracting it and <code>-1</code>, since on x86 CF is set (by <code>sub</code>/<code>cmp</code>) for &quot;below&quot;, cleared for &quot;above&quot;; it's a &quot;borrow&quot; output from subtraction.  GCC's loop is 4 uops, and can run at 1/cycle on CPUs as old as Broadwell (for single-uop <code>sbb</code> with a non-zero immediate) or your Zen 1.</p>\n<pre><code># GCC 15 -O3 -fno-tree-vectorize for a loop doing:  if(data[i] &gt; 100) count++;  \n.L4:                        # do{\n        cmp     BYTE PTR [rdi], 101    # set flags from   elem - 101.  Carry Flag = 1 if elem is below 101\n        sbb     eax, -1        # count -= (-1 + CF)  // += 1 for elem &gt;= 101, += 0 otherwise\n        add     rdi, 1         # ptr++\n        cmp     rdi, rsi\n        jne     .L4         # }while(ptr != endp)\n</code></pre>\n<p>Using a non-indexed addressing-mode prevents <a href=\"https://stackoverflow.com/questions/26046634/micro-fusion-and-addressing-modes\">un-lamination</a>) at issue/rename after <a href=\"https://stackoverflow.com/questions/56413517/what-is-instruction-fusion-in-contemporary-x86-processors\">micro-fusion </a> in the decoder.</p>\n<p>Clang uses the same <code>cmp</code>/<code>sbb</code> peephole optimization, but unrolls the loop by 8.  This doesn't help for long-running loops except on really old CPUs with less than 4 execution units, like Sandy/Ivy Bridge.  If it had unrolled with multiple registers holding separate counts (aka multiple accumulators) to add at the end, it could do 2 elements / cycle, limited by load ports.  (2 loads per clock on older CPUs like Zen 1, 3 scalar loads per clock on many newer CPUs).</p>\n<p>With signed <code>int</code> elements, the compare result isn't the carry flag, so there's nothing like the <code>sbb</code> trick.  GCC uses xor-zeroing (inside the loop) / cmp / setcc / add.  Same front-end uop count as C#, but xor-zeroing is literally as cheap as a NOP on Sandybridge-family and I think on Zen; no back-end execution unit needed.  And of course it doesn't redo sign-extension of an index inside the loop, so only 7 uops, 5 of which need an ALU execution port.</p>\n<hr />\n<h2>Java makes branchless scalar asm.  Its unrolling isn't useful here.</h2>\n<p>Making branchless machine code / assembly from source that uses an <code>if</code> is called &quot;if conversion&quot; optimization.  In technical terminology, if-conversion is turning a control dependency into a data dependency.</p>\n<p>See <a href=\"https://stackoverflow.com/questions/79675833/why-is-this-code-5-times-slower-in-c-sharp-compared-to-java/79676383#79676383\">@k314159's answer</a> for the Java asm, and my comments on it.</p>\n<p>Java makes branchless asm using a worse strategy that can be represented in high-level source as <code>count = (element &gt; 100) ? count+1 : count;</code>, which has 2 operations on the critical path from old <code>count</code> to new <code>count</code>: increment and <code>cmov</code> (conditional select using an ALU operation whose inputs are the compare result in FLAGS, <code>count</code>, <code>count+1</code>).  AArch64 has a similar <code>csel</code> instruction, but also a <code>csinc</code> / <code>cinc</code> instruction that can conditionally increment as well as select, based on a flag condition.</p>\n<p>See <em><a href=\"https://stackoverflow.com/questions/28875325/gcc-optimization-flag-o3-makes-code-slower\">gcc optimization flag -O3 makes code slower than -O2</a></em> for a very similar case of branchless code-gen with a longer critical path than necessary.</p>\n<p>Unrolling helps with throughput bottlenecks (front-end decode and alloc/rename into the back end, and execution ports), not with <a href=\"https://stackoverflow.com/questions/36739118/dependency-chain-analysis\">loop-carried dependency-chain</a> latency bottlenecks.</p>\n<p>Even with this <code>cmov</code> strategy instead of materializing a 0/1 integer to add, it could have unrolled better with multiple accumulators for <code>count</code> (like <code>count1</code>, <code>count2</code> etc), summing at the end; <a href=\"https://stackoverflow.com/questions/45113527/why-does-mulss-take-only-3-cycles-on-haswell-different-from-agners-instruction\">that's a common technique for hiding floating-point ALU latency</a>.  A compiler is allowed to do it for you with integer math because it's associative, unlike FP math with rounding error.  But that's not what the HotSpot JIT does, so it could be going about 2x faster (1 element per cycle) without even vectorizing.  Or even more on wider CPUs like Arrow Lake or Zen 5, with multiple accumulators.</p>\n<h2>SIMD vectorization</h2>\n<p>Neither JIT (C# or Java) is doing this for you.  Modern ahead-of-time compilers do (GCC and Clang), making asm that's much faster than scalar but still far from optimal.</p>\n<p>With SSE2 or AVX2 used efficiently, you'd easily bottleneck on memory bandwidth, or close to L2 cache bandwidth (32 bytes per cycle) if data was hot in L2 or L1d.  Same for NEON/ASIMD or SVE on AArch64.<br />\nWith auto-vectorized machine code from GCC or Clang, you wouldn't be going that fast.  Maybe fast enough to keep up with DRAM bandwidth of like 8 to 16 bytes per cycle on a desktop/laptop, even with byte elements.  With 32-bit <code>int</code> elements, there's less unpacking/widening work per vector (using GCC/Clang's bad strategy) and the data is less dense, so even auto-vectorized C++ should just bottleneck on DRAM bandwidth for your large problem size.  Manually vectorizing would be useful to let you go faster with hot caches, and waste less execution resources so the other logical core sharing a physical core can get more done.</p>\n<p>See my comments under Matthew Watson's answer for more about SIMD.  And his answer for C# with intrinsics doing an ok job, but horizontally summing the compare result inside the inner loop.  Charlieface's answer shows <code>Vector.Subtract</code> to increment a vector of counts with the 0 / -1 compare-result vector.</p>\n<p>The problem of accumulating byte compare results into a total count is the same as in <em><a href=\"https://stackoverflow.com/questions/54541129/how-to-count-character-occurrences-using-simd\">How to count character occurrences using SIMD</a></em>, where chtz's answer shows C++ with AVX2 intrinsics which accumulate counts in separate bytes for an inner loop of up to 255 iterations (the max before any element could overflow), then hsum with <code>vpsadbw</code> against a zeroed register and accumulate those 64-bit counts into another vector which you hsum outside the outer loop.</p>\n<p>x86 before AVX-512 only has two integer compare predicates: equal and signed-greater.  So to do unsigned above or below, one trick is <code>x &gt; y</code> as <code>min(x,y) != y</code>; Clang does it that way, actually spending an XOR to invert the compare results from <code>vpcmpeqb</code>.  Or using unsigned-saturating subtraction + cmpeq like GCC does.  That's part of how GCC/Clang auto-vectorize, but they widen to 32-bit for every compare-result, inefficiently not even using <code>psadbw</code>.  Or worse to 64-bit elements if your sum variable is 64-bit.  Especially with AVX2 where the top 128 bits is less convenient to get at.</p>\n<p>You can see GCC/Clang in the above Godbolt link; take out <code>-fno-tree-vectorize</code> from the command line options.</p>\n<p>Saturating subtraction isn't available for arch-agnostic <code>System.Numerics</code> <a href=\"https://learn.microsoft.com/en-us/dotnet/api/system.numerics.vector.min?view=net-9.0\" rel=\"nofollow noreferrer\">vectors</a>, so you'd have to use <a href=\"https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics.x86.avx2.subtractsaturate?view=net-9.0\" rel=\"nofollow noreferrer\"><code>Avx2.SubtractSaturate</code></a> on <code>Vector256</code> from <code>System.Runtime.Intrinsics.X86</code> to do it that way, which would make it x86-only.  But packed-min, packed-max, and equality are available.  So is XOR and compare for greater-than, so you could XOR with 128 to range-shift unsigned to signed, and do <code>(x^128) &gt; (100^128)</code>.  With the threshold reused across many vectors, XORing it as part of the setup is negligible.  Or <code>Max(v, thresh+1) == v</code> should only be true when <code>v&gt;thresh</code>.</p>\n<p><strong><a href=\"https://stackoverflow.com/questions/79675833/why-is-this-code-5-times-slower-in-c-sharp-compared-to-java/79676180#79676180\">Charlieface's version</a> compiles nicely for <code>int</code> input</strong>.</p>\n<p>For <code>byte</code> input, this is my rough attempt at doing something non-terrible with intrinsics in C#, despite not having access to efficient horizontal-sum of unsigned bytes (<code>vpsadbw</code>).  And working around the compiler which wanted to use AVX-512 unsigned byte compares on Sharplab for <code>.GreaterThan</code>, but instead of doing a merge-masking add or sub, it turned the mask back into a vector with <code>vpmovm2b</code>, so it's no better than just using AVX2 to emulate unsigned compares.  In fact it's worse; AVX-512 compares only run on one port on Intel CPUs, vs. <code>vpcmpgtb</code> with a YMM destination (instead of a <code>k</code> mask register) running on more ports.</p>\n<pre><code>...  // trimmed to fit in 30k char limit\n  Vector&lt;ushort&gt; outercount = new();\n  for (; i &lt; unrolled_size_limit; )\n  {\n    Vector&lt;byte&gt; vcount0 = new();  // Unroll with two u8 accumulator vectors to hide latency\n    Vector&lt;byte&gt; vcount1 = new();\n    for(int j=0; j&lt;255; ++j) {\n        // Maybe use LoadUnsafe or something to avoid bounds checks?\n        var v = new Vector&lt;byte&gt;(array.Slice(i, vectorSize));\n        var max = Vector.Max(v, vthresh_plus_1);\n        var mask = Vector.Equals(max, v);  // true when v &gt;(unsigned) thresh\n        vcount0 -= mask;\n\n        v = new Vector&lt;byte&gt;(array.Slice(i+vectorSize, vectorSize));\n        max = Vector.Max(v, vthresh_plus_1);\n        vcount1 -= Vector.Equals(max, v);\n\n        i += 2 * vectorSize;\n    }\n...\n</code></pre>\n<p><a href=\"https://sharplab.io/#v2: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=\" rel=\"nofollow noreferrer\">Sharplab</a> with this and Charlieface's <code>Vector&lt;int&gt;</code> version, which I don't think I ended up modifying significantly since it was already good.</p>\n<p>This has bounds-checks on each vector load inside the inner loop, so that sucks a lot for throughput, like an extra <code>mov</code>+<code>lea</code>+<code>cmp/ja</code>.  Maybe using <code>MemoryMarshal.Cast</code> can do the check once, outside the loop?  As in <em><a href=\"https://stackoverflow.com/questions/67605744/writing-a-vector-sum-function-with-simd-system-numerics-and-making-it-faster-t\">Writing a vector sum function with SIMD (System.Numerics) and making it faster than a for loop</a></em></p>\n<p><code>v == max(v, thresh+1)</code> forces the compiler to load into a register instead of using a memory source operand for <code>vpmaxub</code>.  I really should have used XOR / signed compare for greater.</p>\n<p>The inner loop from <code>L0039:</code> to <code>dec</code>/<code>jne short L0039</code> is 19 uops for CPUs that handle 256-bit vectors as a single uop.  (Unlike Zen 1, where they're 2 uops each).  So maybe 2x 32-byte vectors per 4 clock cycles, or 16 byte elements per clock, on 5-wide CPUs with 256-bit vector ALUs, like Ice Lake or Zen 2.  Intel might bottleneck on back-end ALU ports; AMD has separate ports for integer vs. SIMD and there's a good mix of both, plus 2 loads.</p>\n<p>By comparison, the not-unrolled inner loop from Charlieface's version actually does still have the bounds checking, too.  10 uops for 1 vector, again about 2 cycles per 32 bytes or 16 bytes per cycle.</p>\n<p>The outer loop code that widens to <code>Vector&lt;UInt16&gt;</code> is much worse than <code>vpsadbw</code>, but only runs every 2x255 vectors.</p>\n",
    "score" : 11,
    "is_accepted" : false,
    "owner" : {
      "account_id" : 78868,
      "reputation" : 377570,
      "user_id" : 224132,
      "user_type" : "registered",
      "accept_rate" : 83,
      "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
      "display_name" : "Peter Cordes",
      "link" : "https://stackoverflow.com/users/224132/peter-cordes"
    },
    "creation_date" : 1750944595,
    "last_activity_date" : 1751017392,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "answer_id" : 79676247,
    "question_id" : 79675833,
    "body" : "<p>This is not an answer to the actual question, but just a demonstration of how you could optimise the C# code to use SIMD vectors.</p>\n<p>I believe that the most likely answer is &quot;because Java is using SIMD vector optimisations and C# is not&quot; - but to prove this we would need to see the actual ASM generated for the Java.</p>\n<p>If the Java is using SIMD, it might be doing something like this:</p>\n<pre><code>static int testSpeedVectorised(ReadOnlySpan&lt;int&gt; array)\n{\n    if (array.Length == 0)\n        throw new ArgumentException();\n\n    const int THRESHOLD = 100;\n\n    int count = 0;\n    int vectorSize = Vector&lt;int&gt;.Count;\n    var threshold = new Vector&lt;int&gt;(THRESHOLD);\n\n    // Vectorised loop\n    int i = 0;\n\n    for (; i &lt;= array.Length - vectorSize; i += vectorSize)\n    {\n        var v = new Vector&lt;int&gt;(array.Slice(i, vectorSize));\n        var mask = Vector.GreaterThan(v, threshold);\n        // Each 'true' in mask is -1, so Vector.Sum(mask) is negative of the match count.\n        // Therefore, we subtract it from count rather than adding it.\n        count -= Vector.Sum(mask);\n    }\n\n    // Handle the leftover values that didn't fit in a Vector&lt;int&gt;\n    for (; i &lt; array.Length; i++)\n    {\n        if (array[i] &gt; THRESHOLD)\n            count++;\n    }\n\n    return count;\n}\n</code></pre>\n<p>If you really REALLY want to, you can write a multithreaded version of the SIMD version to make it even faster:</p>\n<pre><code>[MethodImpl(MethodImplOptions.AggressiveOptimization)]\nstatic int testSpeedMultithreadedVectorised(int[] array)\n{\n    if (array.Length == 0)\n        throw new ArgumentException();\n\n    const int THRESHOLD  = 100;\n    int       vectorSize = Vector&lt;int&gt;.Count;\n    int       length     = array.Length;\n    const int BLOCK_SIZE = 1_000_000; // Might not be optimal, adjust as needed.\n\n    int total = 0;\n\n    Parallel.For(\n        0,\n        (length + BLOCK_SIZE - 1) / BLOCK_SIZE,\n        () =&gt; 0, // Initial local count for each thread\n        (blockIndex, _ /* state - not used */, localCount) =&gt;\n        {\n            int start = blockIndex * BLOCK_SIZE;\n            int end   = Math.Min(start + BLOCK_SIZE, length);\n\n            int i         = start;\n            var threshold = new Vector&lt;int&gt;(THRESHOLD);\n\n            for (; i &lt;= end - vectorSize; i += vectorSize)\n            {\n                var v    = new Vector&lt;int&gt;(array, i);\n                var mask = Vector.GreaterThan(v, threshold);\n                // Each 'true' in mask is -1, so Vector.Sum(mask) is negative of the match count.\n                // Therefore, we subtract it from count rather than adding it.\n                localCount -= Vector.Sum(mask);\n            }\n\n            // Handle the leftover values that didn't fit in a Vector&lt;int&gt;\n            for (; i &lt; end; i++)\n            {\n                if (array[i] &gt; THRESHOLD)\n                    localCount++;\n            }\n\n            return localCount;\n        },\n\n        localCount =&gt; Interlocked.Add(ref total, localCount)\n    );\n\n    return total;\n}\n</code></pre>\n<p>The benchmark results are as follows:</p>\n<pre class=\"lang-none prettyprint-override\"><code>| Method                           | Mean       | Error     | StdDev    | Allocated |\n|--------------------------------- |-----------:|----------:|----------:|----------:|\n| TestSpeed                        | 288.823 ms | 2.8061 ms | 2.6248 ms |     200 B |\n| TestSpeedVectorised              |  20.204 ms | 0.3636 ms | 0.3401 ms |      12 B |\n| TestSpeedMultithreadedVectorised |   6.554 ms | 0.0168 ms | 0.0157 ms |    7844 B |\n</code></pre>\n<p>As you can see, the optimised versions are significantly faster.</p>\n<hr />\n<h1>Update</h1>\n<p>I have incorporated the suggestions from other answers into my benchmarks.</p>\n<p>However, I have <em>not</em> attempted to optimise for using a byte array, since I think that is a distraction from the requirement of checking which values of an <code>int</code> array exceed a particular threshold.</p>\n<p>To drive this point home, the test data is an array of 10 million <code>int</code> values between 0 and 10_000 inclusive and the threshold is 5_000.</p>\n<h1>Benchmark Code</h1>\n<ul>\n<li><p><code>Original()</code> is the original C# code from the OP.</p>\n</li>\n<li><p><code>Optimised()</code> rewrites the inner loop to use the suggestion from u/PeterCordes.</p>\n</li>\n<li><p><code>Vectorised()</code> is my original vector approach.</p>\n</li>\n<li><p><code>BetterVectorised()</code> incorporates a suggestion from /u/CharlieFace</p>\n</li>\n<li><p><code>MtVectorised()</code> is the multithreaded version of <code>Vectorised()</code>.</p>\n</li>\n<li><p><code>MtBetterVectorised()</code> is the multithreaded version of <code>BetterVectorised()</code>.</p>\n<pre><code>using System.Numerics;\nusing System.Runtime.CompilerServices;\nusing BenchmarkDotNet.Attributes;\nnamespace ConsoleApp1;\n\n[MemoryDiagnoser]\npublic class Benchmark\n{\n    private int[] _array = null!;\n\n    [GlobalSetup] \n    public void Setup()\n    {\n        var rng = new Random(321312);\n        _array = new int[100_000_000];\n\n        for (int i = 0; i &lt; _array.Length; i++)\n        {\n            _array[i] = rng.Next(0, 10_001); // Random values between 0 and 10_000.\n        }\n    }\n\n    [Benchmark(Baseline = true)]\n    public int Original()\n    {\n        return testSpeed(_array);\n    }\n\n    [Benchmark]\n    public int Optimised()\n    {\n        return testSpeedOptimised(_array);\n    }\n\n    [Benchmark]\n    public int Vectorised()\n    {\n        return testSpeedVectorised(_array);\n    }\n\n    [Benchmark]\n    public int BetterVectorised()\n    {\n        return testSpeedVectorisedOptimised(_array);\n    }\n\n    [Benchmark]\n    public int MtVectorised()\n    {\n        return testSpeedMultithreadedVectorised(_array);\n    }\n\n    [Benchmark]\n    public int MtBetterVectorised()\n    {\n        return testSpeedMultithreadedVectorisedOptimised(_array);\n    }\n\n    [MethodImpl(MethodImplOptions.AggressiveOptimization)]\n    static int testSpeedVectorised(ReadOnlySpan&lt;int&gt; array)\n    {\n        if (array.Length == 0) \n            throw new ArgumentException();\n\n        const int THRESHOLD = 5_000;\n\n        int count = 0;\n        int vectorSize = Vector&lt;int&gt;.Count;\n        int i = 0;\n        var threshold = new Vector&lt;int&gt;(THRESHOLD);\n\n        // Vectorized loop\n        for (; i &lt;= array.Length - vectorSize; i += vectorSize)\n        {\n            var v = new Vector&lt;int&gt;(array.Slice(i, vectorSize));\n            var mask = Vector.GreaterThan(v, threshold);\n            // Each 'true' in mask is -1, so Vector.Sum(mask) is negative of the match count.\n            // Therefore, we subtract it from count rather than adding it.\n            count -= Vector.Sum(mask);\n        }\n\n        // Remainder loop\n        for (; i &lt; array.Length; i++)\n        {\n            if (array[i] &gt; THRESHOLD)\n                count++;\n        }\n\n        return count;\n    }\n\n    [MethodImpl(MethodImplOptions.AggressiveOptimization)]\n    static int testSpeedVectorisedOptimised(ReadOnlySpan&lt;int&gt; array)\n    {\n        if (array.Length == 0)\n            throw new ArgumentException();\n\n        const int THRESHOLD = 5_000;\n\n        Vector&lt;int&gt; count      = new();\n        int         vectorSize = Vector&lt;int&gt;.Count;\n        var         threshold  = new Vector&lt;int&gt;(THRESHOLD);\n\n        // Vectorised loop\n        int i = 0;\n\n        for (; i &lt;= array.Length - vectorSize; i += vectorSize)\n        {\n            var v    = new Vector&lt;int&gt;(array.Slice(i, vectorSize));\n            var mask = Vector.GreaterThan(v, threshold);\n            count = Vector.Subtract(count, mask);\n        }\n\n        var totalCount = Vector.Sum(count);\n\n        // Handle the leftover values that didn't fit in a Vector&lt;int&gt;\n        for (; i &lt; array.Length; i++)\n        {\n            if (array[i] &gt; THRESHOLD)\n                totalCount++;\n        }\n\n        return totalCount;\n    }\n\n    [MethodImpl(MethodImplOptions.AggressiveOptimization)]\n    static int testSpeedMultithreadedVectorised(int[] array)\n    {\n        if (array.Length == 0)\n            throw new ArgumentException();\n\n        const int THRESHOLD  = 5_000;\n        int       vectorSize = Vector&lt;int&gt;.Count;\n        int       length     = array.Length;\n        const int BLOCK_SIZE = 1_000_000; // Might not be optimal, adjust as needed.\n\n        int total = 0;\n\n        Parallel.For(\n            0,\n            (length + BLOCK_SIZE - 1) / BLOCK_SIZE,\n            () =&gt; 0, // Initial local count for each thread\n            (chunkIdx, _ /* state - not used */, localCount) =&gt;\n            {\n                int start = chunkIdx * BLOCK_SIZE;\n                int end   = Math.Min(start + BLOCK_SIZE, length);\n\n                int i         = start;\n                var threshold = new Vector&lt;int&gt;(THRESHOLD);\n\n                for (; i &lt;= end - vectorSize; i += vectorSize)\n                {\n                    var v    = new Vector&lt;int&gt;(array, i);\n                    var mask = Vector.GreaterThan(v, threshold);\n                    // Each 'true' in mask is -1, so Vector.Sum(mask) is negative of the match count.\n                    // Therefore, we subtract it from count rather than adding it.\n                    localCount -= Vector.Sum(mask);\n                }\n\n                // Handle the leftover values that didn't fit in a Vector&lt;int&gt;\n                for (; i &lt; end; i++)\n                {\n                    if (array[i] &gt; THRESHOLD)\n                        localCount++;\n                }\n\n                return localCount;\n            },\n\n            localCount =&gt; Interlocked.Add(ref total, localCount)\n        );\n\n        return total;\n    }\n\n    [MethodImpl(MethodImplOptions.AggressiveOptimization)]\n    static int testSpeedMultithreadedVectorisedOptimised(int[] array)\n    {\n        if (array.Length == 0)\n            throw new ArgumentException();\n\n        const int THRESHOLD  = 5_000;\n        int       vectorSize = Vector&lt;int&gt;.Count;\n        int       length     = array.Length;\n        const int BLOCK_SIZE = 1_000_000; // Might not be optimal, adjust as needed.\n\n        int total = 0;\n\n        Parallel.For(\n            0,\n            (length + BLOCK_SIZE - 1) / BLOCK_SIZE,\n            () =&gt; 0, // Initial local count for each thread\n            (chunkIdx, _ /* state - not used */, localCount) =&gt;\n            {\n                int start = chunkIdx * BLOCK_SIZE;\n                int end   = Math.Min(start + BLOCK_SIZE, length);\n                Vector&lt;int&gt; count = new();\n\n                int i         = start;\n                var threshold = new Vector&lt;int&gt;(THRESHOLD);\n\n                for (; i &lt;= end - vectorSize; i += vectorSize)\n                {\n                    var v    = new Vector&lt;int&gt;(array, i);\n                    var mask = Vector.GreaterThan(v, threshold);\n                    count = Vector.Subtract(count, mask);\n                }\n\n                localCount += Vector.Sum(count);\n\n                // Handle the leftover values that didn't fit in a Vector&lt;int&gt;\n                for (; i &lt; end; i++)\n                {\n                    if (array[i] &gt; THRESHOLD)\n                        localCount++;\n                }\n\n                return localCount;\n            },\n\n            localCount =&gt; Interlocked.Add(ref total, localCount)\n        );\n\n        return total;\n    }\n\n    [MethodImpl(MethodImplOptions.AggressiveOptimization)]\n    static int testSpeed(ReadOnlySpan&lt;int&gt; array)\n    {\n        const int THRESHOLD = 5_000;\n\n        int count = 0;\n\n        foreach (int element in array)\n        {\n            if (element &gt; THRESHOLD)\n            {\n                count++;\n            }\n        }\n\n        return count;\n    }\n\n    [MethodImpl(MethodImplOptions.AggressiveOptimization)]\n    static int testSpeedOptimised(ReadOnlySpan&lt;int&gt; array)\n    {\n        const int THRESHOLD = 5_000;\n\n        int count = 0;\n\n        foreach (int element in array)\n        {\n            count += element &gt; THRESHOLD ? 1 : 0;\n        }\n\n        return count;\n    }\n}\n</code></pre>\n</li>\n</ul>\n<h1>Results</h1>\n<pre><code>| Method             | Mean       | Error     | StdDev    | Ratio | Allocated | Alloc Ratio |\n|------------------- |-----------:|----------:|----------:|------:|----------:|------------:|\n| Original           | 317.927 ms | 2.0464 ms | 1.9142 ms |  1.00 |     200 B |        1.00 |\n| Optimised          |  44.469 ms | 0.4871 ms | 0.4557 ms |  0.14 |      33 B |        0.17 |\n| Vectorised         |  20.041 ms | 0.3954 ms | 0.3698 ms |  0.06 |      12 B |        0.06 |\n| BetterVectorised   |  16.191 ms | 0.2009 ms | 0.1879 ms |  0.05 |      12 B |        0.06 |\n| MtVectorised       |   6.755 ms | 0.0590 ms | 0.0523 ms |  0.02 |    7806 B |       39.03 |\n| MtBetterVectorised |   6.590 ms | 0.1058 ms | 0.0990 ms |  0.02 |    7824 B |       39.12 |\n</code></pre>\n<h1>Observations</h1>\n<ul>\n<li>The simple inner loop change to <code>count += (element &gt; 100) ? 1 : 0;</code> suggested by u/PeterCordes makes a huge difference, making it seven times faster.</li>\n<li>The <code>BetterVectorised()</code> version makes minor difference.</li>\n<li>The multithreaded vectorised version is around fifty times faster than the original version, at the expense of around 8K of additional memory usage.</li>\n</ul>\n",
    "score" : 7,
    "is_accepted" : false,
    "owner" : {
      "account_id" : 37150,
      "reputation" : 111091,
      "user_id" : 106159,
      "user_type" : "registered",
      "accept_rate" : 93,
      "profile_image" : "https://i.sstatic.net/Qfp6z.png?s=256",
      "display_name" : "Matthew Watson",
      "link" : "https://stackoverflow.com/users/106159/matthew-watson"
    },
    "creation_date" : 1750684809,
    "last_activity_date" : 1751019280,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "answer_id" : 79676180,
    "question_id" : 79675833,
    "body" : "<p>You could try with a <code>for</code> loop rather than a <code>foreach</code>, but it seems the ASM is the same for those.</p>\n<p>Either way, you need to use a tool such as BenchmarkDotNet for accurate results, do not rely on the stopwatch.</p>\n<pre class=\"lang-cs prettyprint-override\"><code>int[] _array;\n\n[GlobalSetup]\npublic static void Setup()\n{\n    string desktopPath = Environment.GetFolderPath(Environment.SpecialFolder.Desktop);\n    string fullPath = Path.Combine(desktopPath, &quot;RandomFile.dat&quot;);\n    if (!File.Exists(fullPath))\n    {\n        Console.WriteLine(&quot;The file does not exist.&quot;);\n        return;\n    }\n    byte[] byteArray = File.ReadAllBytes(fullPath);\n    _array = ByteArrayToIntArray(byteArray);\n}\n\n[Benchmark]\n[MethodImplAttribute(MethodImplOptions.AggressiveOptimization)]\npublic static int TestSpeed()\n{\n    var array = _array;\n    if (array == null) throw new ArgumentNullException(nameof(array));\n    if (array.Length == 0) throw new ArgumentException(&quot;Empty array&quot;, nameof(array));\n    int count = 0;\n    for (var i = 0; i &lt; array.Length; i++)\n    {\n        if (array[i] &gt; 100)\n            count++;\n    }\n    return count;\n}\n</code></pre>\n<p>You may also find that unrolling it will speed it up significantly. Try either 128- or 256-bit unroll, so either 4 or 8 step, depending on your processor. Removing branching is also likely to give a good speedup.</p>\n<pre class=\"lang-cs prettyprint-override\"><code>[Benchmark]\n[MethodImplAttribute(MethodImplOptions.AggressiveOptimization)]\npublic static int TestSpeed2()\n{\n    var array = _array;\n    if (array == null) throw new ArgumentNullException(nameof(array));\n    if (array.Length == 0) throw new ArgumentException(&quot;Empty array&quot;, nameof(array));\n    int count = 0;\n    int i = 0;\n    for (; i &lt; array.Length - 8; i += 8)\n    {\n        var temp0 = array[i] &gt; 100;\n        var temp1 = array[i + 1] &gt; 100;\n        var temp2 = array[i + 2] &gt; 100;\n        var temp3 = array[i + 3] &gt; 100;\n        var temp4 = array[i + 4] &gt; 100;\n        var temp5 = array[i + 5] &gt; 100;\n        var temp6 = array[i + 6] &gt; 100;\n        var temp7 = array[i + 7] &gt; 100;\n        count +=\n            Unsafe.As&lt;bool, int&gt;(ref temp0) +\n            Unsafe.As&lt;bool, int&gt;(ref temp1) +\n            Unsafe.As&lt;bool, int&gt;(ref temp2) +\n            Unsafe.As&lt;bool, int&gt;(ref temp3) +\n            Unsafe.As&lt;bool, int&gt;(ref temp4) +\n            Unsafe.As&lt;bool, int&gt;(ref temp5) +\n            Unsafe.As&lt;bool, int&gt;(ref temp6) +\n            Unsafe.As&lt;bool, int&gt;(ref temp7);\n    }\n    for (; i &lt; array.Length; i++)\n    {\n        if (array[i] &gt; 100)\n        {\n            count++;\n        }\n    }\n    return count;\n}\n</code></pre>\n<p>You could even try using SIMD, with <code>Vector&lt;int&gt;</code>. A faster version of @MatthewWilson's parallelizes the summing, then horizontally sums only the final result, rather than horizontally summing on each loop. You can also use <code>Unsafe.Add</code> to avoid bounds checks.</p>\n<pre class=\"lang-cs prettyprint-override\"><code>[MethodImplAttribute(MethodImplOptions.AggressiveOptimization)]\npublic static int testSpeedVectorised(ReadOnlySpan&lt;int&gt; array)\n{\n    if (array.Length == 0) \n        throw new ArgumentException();\n\n    const int THRESHOLD = 100;\n\n    Vector&lt;int&gt; count = new();\n    int vectorSize = Vector&lt;int&gt;.Count;\n    // initialize vector with all values the same\n    var threshold = new Vector&lt;int&gt;(THRESHOLD);\n\n    // Vectorised loop\n    int i = 0;\n    ref int start = ref MemoryMarshal.GetReference(array);\n    for (; i &lt;= array.Length - vectorSize; i += vectorSize)\n    {\n        var v = new Vector&lt;int&gt;(MemoryMarshal.CreateReadOnlySpan(Unsafe.Add(ref start, i), vectorSize));\n        var mask = Vector.GreaterThan(v, threshold);\n        // Each 'true' in mask is -1, so we use Vector.Subtract rather than Vector.Add\n        // Therefore, we subtract it from count rather than adding it.\n        count = Vector.Subtract(count, mask);\n    }\n\n    var totalCount = Vector.Sum(count);\n    // Handle the leftover values that didn't fit in a Vector&lt;int&gt;\n    for (; i &lt; array.Length; i++)\n    {\n        if (Unsafe.Add(ref start, i) &gt; THRESHOLD)\n            totalCount++;\n    }\n\n    return totalCount;\n}\n</code></pre>\n",
    "score" : 3,
    "is_accepted" : false,
    "owner" : {
      "account_id" : 20264817,
      "reputation" : 78793,
      "user_id" : 14868997,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/40cbeeb90667c9a8c1830f615a9b2899?s=256&d=identicon&r=PG",
      "display_name" : "Charlieface",
      "link" : "https://stackoverflow.com/users/14868997/charlieface"
    },
    "creation_date" : 1750681874,
    "last_activity_date" : 1751035279,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "question_comments" : [ {
    "comment_id" : 140553828,
    "post_id" : 79675833,
    "body" : "@MatthewWatson I&#39;d expect so, but I&#39;d also benchmark it to verify ;)",
    "score" : 0,
    "owner" : {
      "account_id" : 26882,
      "reputation" : 1,
      "user_id" : 70345,
      "user_type" : "registered",
      "accept_rate" : 69,
      "profile_image" : "https://i.sstatic.net/aV45a.jpg?s=256",
      "display_name" : "Ian Kemp - SO dead by AI greed",
      "link" : "https://stackoverflow.com/users/70345/ian-kemp-so-dead-by-ai-greed"
    },
    "creation_date" : 1751302154,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140546759,
    "post_id" : 79675833,
    "body" : "@IanKemp-SOdeadbyAIgreed I agree, the byte array is weird. I assumed that the byte array was just being used to initialise some random ints, so I ignored that in my answer. However, using Linq to count the elements larger than 100 is definitely slower than a hand-rolled loop.",
    "score" : 3,
    "owner" : {
      "account_id" : 37150,
      "reputation" : 111091,
      "user_id" : 106159,
      "user_type" : "registered",
      "accept_rate" : 93,
      "profile_image" : "https://i.sstatic.net/Qfp6z.png?s=256",
      "display_name" : "Matthew Watson",
      "link" : "https://stackoverflow.com/users/106159/matthew-watson"
    },
    "creation_date" : 1751016325,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140541741,
    "post_id" : 79675833,
    "body" : "I&#39;m confused as to the relevance of these benchmarks, which are doing some honestly bizarre things. Why are we bothering to convert an array of byte to an array of int; why aren&#39;t we using LINQ to count the number of elements that are larger than 100? It&#39;s trivial to produce a benchmark that shows that something is slow or fast, but whether a benchmark is even relevant in the first place is the first question to ask.",
    "score" : 2,
    "owner" : {
      "account_id" : 26882,
      "reputation" : 1,
      "user_id" : 70345,
      "user_type" : "registered",
      "accept_rate" : 69,
      "profile_image" : "https://i.sstatic.net/aV45a.jpg?s=256",
      "display_name" : "Ian Kemp - SO dead by AI greed",
      "link" : "https://stackoverflow.com/users/70345/ian-kemp-so-dead-by-ai-greed"
    },
    "creation_date" : 1750865501,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140537882,
    "post_id" : 79675833,
    "body" : "@k314159 and rustyx: Predictability does actually matter a lot, since Java uses branchless asm but C# presumably doesn&#39;t, which is why it&#39;s slower.  Predictable data (e.g. all true or all false) would be a good test to see if that speeds up the C# version to match or beat Java.",
    "score" : 0,
    "owner" : {
      "account_id" : 78868,
      "reputation" : 377570,
      "user_id" : 224132,
      "user_type" : "registered",
      "accept_rate" : 83,
      "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
      "display_name" : "Peter Cordes",
      "link" : "https://stackoverflow.com/users/224132/peter-cordes"
    },
    "creation_date" : 1750761987,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140537869,
    "post_id" : 79675833,
    "body" : "You left <code>ByteArrayToIntArray</code> out of your timing.  That step is totally pointless; can&#39;t C# express the concept of a loop over u8 data?",
    "score" : 0,
    "owner" : {
      "account_id" : 78868,
      "reputation" : 377570,
      "user_id" : 224132,
      "user_type" : "registered",
      "accept_rate" : 83,
      "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
      "display_name" : "Peter Cordes",
      "link" : "https://stackoverflow.com/users/224132/peter-cordes"
    },
    "creation_date" : 1750761775,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140536782,
    "post_id" : 79675833,
    "body" : "Why are Java and C# different? Because they have a different focus, and because; <a href=\"https://en.wikipedia.org/wiki/Full-employment_theorem\" rel=\"nofollow noreferrer\">en.wikipedia.org/wiki/Full-employment_theorem</a>.",
    "score" : 0,
    "owner" : {
      "account_id" : 5171453,
      "reputation" : 11603,
      "user_id" : 4139809,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/950022a8882128ae019d3c0bda011723?s=256&d=identicon&r=PG",
      "display_name" : "Jeremy Lakeman",
      "link" : "https://stackoverflow.com/users/4139809/jeremy-lakeman"
    },
    "creation_date" : 1750732334,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140535281,
    "post_id" : 79675833,
    "body" : "@rustyx I disagree, as using <code>i % 7 + 99</code> makes the test too predictable and dependent on the CPU&#39;s branch prediction logic. (On the other hand, it doesn&#39;t matter as long as both the Java and C# versions use the same data.)",
    "score" : 1,
    "owner" : {
      "account_id" : 19118721,
      "reputation" : 12499,
      "user_id" : 13963086,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/9df2c3c4c87d8050b8fd6a59c88c7133?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "k314159",
      "link" : "https://stackoverflow.com/users/13963086/k314159"
    },
    "creation_date" : 1750686016,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140535256,
    "post_id" : 79675833,
    "body" : "BTW you can replace the file part by generating the int array manually beforehand e.g. <code>for (int i = 0; i &lt; len; i++) { intArray[i] = i % 7 + 99; }</code>, the end result is the same since the test is DRAM-bound anyway, given the array size.",
    "score" : 0,
    "owner" : {
      "account_id" : 225072,
      "reputation" : 86496,
      "user_id" : 485343,
      "user_type" : "registered",
      "accept_rate" : 75,
      "profile_image" : "https://www.gravatar.com/avatar/e18b024a122df74275dd2c4486e8a2b4?s=256&d=identicon&r=PG",
      "display_name" : "rustyx",
      "link" : "https://stackoverflow.com/users/485343/rustyx"
    },
    "creation_date" : 1750685582,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140535247,
    "post_id" : 79675833,
    "body" : "You should also state the exact versions of Java, C#, and the operating system that you&#39;re using. Your hardware may be important as well.",
    "score" : 3,
    "owner" : {
      "account_id" : 8532578,
      "reputation" : 49904,
      "user_id" : 6395627,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/af0f9bfe593f36642a032cd7ea611e7d?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Slaw",
      "link" : "https://stackoverflow.com/users/6395627/slaw"
    },
    "creation_date" : 1750685396,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140535245,
    "post_id" : 79675833,
    "body" : "Based on the comments, the lack of a micro-benchmarking framework in both your tests is serving as a (legitimate) distraction. You may want rewrite both your tests using such a framework and then <a href=\"https://stackoverflow.com/posts/79675833/edit\">edit</a> your question to replace your current tests. Use <i>Java Microbenchmark Harness</i> (JMH) for Java and, according to other comments, <i>BenchmarkDotNet</i> for C#. You may also want to include the native code generated by each language&#39;s JIT. <a href=\"https://stackoverflow.com/a/15146962/6395627\">This Q&amp;A</a> should help with that in Java. Not sure how to do the same in C#.",
    "score" : 4,
    "owner" : {
      "account_id" : 8532578,
      "reputation" : 49904,
      "user_id" : 6395627,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/af0f9bfe593f36642a032cd7ea611e7d?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Slaw",
      "link" : "https://stackoverflow.com/users/6395627/slaw"
    },
    "creation_date" : 1750685338,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140535212,
    "post_id" : 79675833,
    "body" : "I do think the most likely answer is &quot;because Java is using SIMD vector optimisations and C# is not&quot;. But to prove this we would need to see the actual ASM generated for the Java.",
    "score" : 0,
    "owner" : {
      "account_id" : 37150,
      "reputation" : 111091,
      "user_id" : 106159,
      "user_type" : "registered",
      "accept_rate" : 93,
      "profile_image" : "https://i.sstatic.net/Qfp6z.png?s=256",
      "display_name" : "Matthew Watson",
      "link" : "https://stackoverflow.com/users/106159/matthew-watson"
    },
    "creation_date" : 1750684607,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140535179,
    "post_id" : 79675833,
    "body" : "@ShirazAhmed No it does not matter how much time the conversion took because I simply do not measure time from this part...",
    "score" : 0,
    "owner" : {
      "account_id" : 42679246,
      "reputation" : 379,
      "user_id" : 30869176,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/e8c2f3e4f8519a81500e2c8f44b0b208?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Vasilis Kontopoulos",
      "link" : "https://stackoverflow.com/users/30869176/vasilis-kontopoulos"
    },
    "creation_date" : 1750683950,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140535174,
    "post_id" : 79675833,
    "body" : "I dont think Java is using byte array directly either. It also convert it to int array before counting. But in C# the conversion maybe take more time or memory. Try to count directly on byte array in C# and see if it help.",
    "score" : 0,
    "owner" : {
      "account_id" : 32398336,
      "reputation" : 3,
      "user_id" : 25166100,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/4b46c4c51053b26d07eebe6c5096ec76?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Shiraz Ahmed",
      "link" : "https://stackoverflow.com/users/25166100/shiraz-ahmed"
    },
    "creation_date" : 1750683752,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140535147,
    "post_id" : 79675833,
    "body" : "@aled I don&#39;t think the problem is in Java but in C#...",
    "score" : 0,
    "owner" : {
      "account_id" : 42679246,
      "reputation" : 379,
      "user_id" : 30869176,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/e8c2f3e4f8519a81500e2c8f44b0b208?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Vasilis Kontopoulos",
      "link" : "https://stackoverflow.com/users/30869176/vasilis-kontopoulos"
    },
    "creation_date" : 1750683256,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140535141,
    "post_id" : 79675833,
    "body" : "@rustyx I tried adding [MethodImpl(MethodImplOptions.AggressiveOptimization)] but there is no difference...still almost the same performance...",
    "score" : 0,
    "owner" : {
      "account_id" : 42679246,
      "reputation" : 379,
      "user_id" : 30869176,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/e8c2f3e4f8519a81500e2c8f44b0b208?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Vasilis Kontopoulos",
      "link" : "https://stackoverflow.com/users/30869176/vasilis-kontopoulos"
    },
    "creation_date" : 1750683142,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140535124,
    "post_id" : 79675833,
    "body" : "@k314159 Could be. Can anyone get at the Java assembler output for the method?",
    "score" : 0,
    "owner" : {
      "account_id" : 37150,
      "reputation" : 111091,
      "user_id" : 106159,
      "user_type" : "registered",
      "accept_rate" : 93,
      "profile_image" : "https://i.sstatic.net/Qfp6z.png?s=256",
      "display_name" : "Matthew Watson",
      "link" : "https://stackoverflow.com/users/106159/matthew-watson"
    },
    "creation_date" : 1750682806,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140535069,
    "post_id" : 79675833,
    "body" : "@MatthewWatson the ASM code you showed us checks each array element individually. It could be that the JVM JIT generates vector operations.",
    "score" : 0,
    "owner" : {
      "account_id" : 19118721,
      "reputation" : 12499,
      "user_id" : 13963086,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/9df2c3c4c87d8050b8fd6a59c88c7133?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "k314159",
      "link" : "https://stackoverflow.com/users/13963086/k314159"
    },
    "creation_date" : 1750681684,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140535043,
    "post_id" : 79675833,
    "body" : "For the Java test use the Java Microbenchmark Harness: <a href=\"https://github.com/openjdk/jmh\" rel=\"nofollow noreferrer\">github.com/openjdk/jmh</a>. But for both give more time for warmup.",
    "score" : 0,
    "owner" : {
      "account_id" : 372682,
      "reputation" : 26512,
      "user_id" : 721855,
      "user_type" : "registered",
      "profile_image" : "https://i.sstatic.net/vZiox.png?s=256",
      "display_name" : "aled",
      "link" : "https://stackoverflow.com/users/721855/aled"
    },
    "creation_date" : 1750681161,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140535013,
    "post_id" : 79675833,
    "body" : "Try annotating <code>TestSpeed</code> C# method with <code>[MethodImpl(MethodImplOptions.AggressiveOptimization)]</code>",
    "score" : 1,
    "owner" : {
      "account_id" : 225072,
      "reputation" : 86496,
      "user_id" : 485343,
      "user_type" : "registered",
      "accept_rate" : 75,
      "profile_image" : "https://www.gravatar.com/avatar/e18b024a122df74275dd2c4486e8a2b4?s=256&d=identicon&r=PG",
      "display_name" : "rustyx",
      "link" : "https://stackoverflow.com/users/485343/rustyx"
    },
    "creation_date" : 1750680325,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140534939,
    "post_id" : 79675833,
    "body" : "@MatthewWatson I used BenchmarkDotNet and the results are these: TestSpeed Mean: 411.2 ms. Which is not different from Stopwatch...",
    "score" : 3,
    "owner" : {
      "account_id" : 42679246,
      "reputation" : 379,
      "user_id" : 30869176,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/e8c2f3e4f8519a81500e2c8f44b0b208?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Vasilis Kontopoulos",
      "link" : "https://stackoverflow.com/users/30869176/vasilis-kontopoulos"
    },
    "creation_date" : 1750678783,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140534909,
    "post_id" : 79675833,
    "body" : "@rustyx For me debug mode is normally slower than release mode...",
    "score" : 0,
    "owner" : {
      "account_id" : 42679246,
      "reputation" : 379,
      "user_id" : 30869176,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/e8c2f3e4f8519a81500e2c8f44b0b208?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Vasilis Kontopoulos",
      "link" : "https://stackoverflow.com/users/30869176/vasilis-kontopoulos"
    },
    "creation_date" : 1750677783,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140534906,
    "post_id" : 79675833,
    "body" : "@VasilisKontopoulos You need to add a field for the array: <code>private int[] _array = null!;</code> and then add a <code>[GlobalSetup] public void Setup()</code> which initialises <code>_array</code>. Then implement the method to test as <code>static int testSpeed(int[] array){...}</code> and call it like so: <code>[Benchmark] public int TestSpeed() { return testSpeed(_array); }</code>",
    "score" : 1,
    "owner" : {
      "account_id" : 37150,
      "reputation" : 111091,
      "user_id" : 106159,
      "user_type" : "registered",
      "accept_rate" : 93,
      "profile_image" : "https://i.sstatic.net/Qfp6z.png?s=256",
      "display_name" : "Matthew Watson",
      "link" : "https://stackoverflow.com/users/106159/matthew-watson"
    },
    "creation_date" : 1750677738,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140534900,
    "post_id" : 79675833,
    "body" : "Hmm. I&#39;m on Linux but I can confirm the issue. Interestingly, C# debug mode seems much faster than release mode, which makes no sense to me.",
    "score" : 0,
    "owner" : {
      "account_id" : 225072,
      "reputation" : 86496,
      "user_id" : 485343,
      "user_type" : "registered",
      "accept_rate" : 75,
      "profile_image" : "https://www.gravatar.com/avatar/e18b024a122df74275dd2c4486e8a2b4?s=256&d=identicon&r=PG",
      "display_name" : "rustyx",
      "link" : "https://stackoverflow.com/users/485343/rustyx"
    },
    "creation_date" : 1750677513,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140534879,
    "post_id" : 79675833,
    "body" : "I checked BenchmarkDotNet as you guys suggested but I only find examples with no parameters or constant parameters how can I test the TestSpeed(int[] array) with BenchmarkDotNet, does anybody know?",
    "score" : 0,
    "owner" : {
      "account_id" : 42679246,
      "reputation" : 379,
      "user_id" : 30869176,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/e8c2f3e4f8519a81500e2c8f44b0b208?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Vasilis Kontopoulos",
      "link" : "https://stackoverflow.com/users/30869176/vasilis-kontopoulos"
    },
    "creation_date" : 1750677054,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140534853,
    "post_id" : 79675833,
    "body" : "Well it seems that the C# <a href=\"https://sharplab.io/#v2:C4LghgzgtgPgAgJgIwFgBQcDMACR2DC2A3utmbjnACzYCyAFAJTGnkC+rZnuSAbNgEsAdsGzAAphGABlAA7jxAE3rDgAbQC62MACcdYAJ6NuJNOXOCR2AMYB7AK5WAvNgAMAbnTdzAM1s7xMGsAC2wVK3EAG3EocSthbT1DYzMLMlM0tIEfMKiYuNEAPmwkV1cUzIsMysy7R2AAagbPVJrsDlaLDu9yOAB2GwcRFvM2c3Q2IA===\" rel=\"nofollow noreferrer\">ASM code generated is fairly well optimised</a> so I can&#39;t really explain why there&#39;s such an apparent difference for you.",
    "score" : 1,
    "owner" : {
      "account_id" : 37150,
      "reputation" : 111091,
      "user_id" : 106159,
      "user_type" : "registered",
      "accept_rate" : 93,
      "profile_image" : "https://i.sstatic.net/Qfp6z.png?s=256",
      "display_name" : "Matthew Watson",
      "link" : "https://stackoverflow.com/users/106159/matthew-watson"
    },
    "creation_date" : 1750676342,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140534823,
    "post_id" : 79675833,
    "body" : "@MatthewWatson I tried system.nanoTime() and the results are around the same...",
    "score" : 1,
    "owner" : {
      "account_id" : 42679246,
      "reputation" : 379,
      "user_id" : 30869176,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/e8c2f3e4f8519a81500e2c8f44b0b208?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Vasilis Kontopoulos",
      "link" : "https://stackoverflow.com/users/30869176/vasilis-kontopoulos"
    },
    "creation_date" : 1750675606,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140534814,
    "post_id" : 79675833,
    "body" : "Well it uses the system clock which has a default resolution of around 15ms on Windows, so any measurement could be 15ms out. So if you take two measurements very close together (say 10ms apart) then the system clock could return the same value for both measurements. Not saying that this is definitely causing any timing issues, but it&#39;s a possibility that can be avoided by using <code>system.nanoTime()</code> which uses the performance counters on a Windows platform.",
    "score" : 1,
    "owner" : {
      "account_id" : 37150,
      "reputation" : 111091,
      "user_id" : 106159,
      "user_type" : "registered",
      "accept_rate" : 93,
      "profile_image" : "https://i.sstatic.net/Qfp6z.png?s=256",
      "display_name" : "Matthew Watson",
      "link" : "https://stackoverflow.com/users/106159/matthew-watson"
    },
    "creation_date" : 1750675307,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140534804,
    "post_id" : 79675833,
    "body" : "@MatthewWatson You mean, it will produce readings that are smaller than they actually are?",
    "score" : 0,
    "owner" : {
      "account_id" : 957028,
      "reputation" : 16497,
      "user_id" : 982149,
      "user_type" : "registered",
      "accept_rate" : 100,
      "profile_image" : "https://i.sstatic.net/LdDoZ.png?s=256",
      "display_name" : "Fildor",
      "link" : "https://stackoverflow.com/users/982149/fildor"
    },
    "creation_date" : 1750675009,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140534801,
    "post_id" : 79675833,
    "body" : "I actually think the main issue is the use of <code>System.currentTimeInMillis()</code> in the Java code...",
    "score" : 0,
    "owner" : {
      "account_id" : 37150,
      "reputation" : 111091,
      "user_id" : 106159,
      "user_type" : "registered",
      "accept_rate" : 93,
      "profile_image" : "https://i.sstatic.net/Qfp6z.png?s=256",
      "display_name" : "Matthew Watson",
      "link" : "https://stackoverflow.com/users/106159/matthew-watson"
    },
    "creation_date" : 1750674883,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140534795,
    "post_id" : 79675833,
    "body" : "Then I must chime in to the above: Use Benchmark.Net to get reliable readings, then we talk again.",
    "score" : 0,
    "owner" : {
      "account_id" : 957028,
      "reputation" : 16497,
      "user_id" : 982149,
      "user_type" : "registered",
      "accept_rate" : 100,
      "profile_image" : "https://i.sstatic.net/LdDoZ.png?s=256",
      "display_name" : "Fildor",
      "link" : "https://stackoverflow.com/users/982149/fildor"
    },
    "creation_date" : 1750674701,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "answer_comments" : {
    "79676383" : [ {
      "comment_id" : 140548025,
      "post_id" : 79676383,
      "body" : "All x86 CPUs for many years are out-of-order exec, so the loads can overlap with the computation. It doesn&#39;t make sense to say &quot;the rest of the time is spent indexing the array.&quot;  The CPU will have <code>mov</code> loads in flight along with <code>cmp</code>/<code>cmov</code> or <code>cmp</code>/<code>setcc</code>/etc. from earlier iterations.  <a href=\"https://www.lighterra.com/papers/modernmicroprocessors/\" rel=\"nofollow noreferrer\">lighterra.com/papers/modernmicroprocessors</a> is a great into to pipelining and superscalar and out-of-order exec, and see also <a href=\"https://www.realworldtech.com/sandy-bridge/\" rel=\"nofollow noreferrer\">realworldtech.com/sandy-bridge</a>",
      "score" : 0,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1751046149,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140548019,
      "post_id" : 79676383,
      "body" : "@k314159: On what CPU model? 4 bytes per cycle memory bandwidth should be achievable by all desktops/laptops from the past decade, with HW prefetch for L1d hits. Intel since Haswell has 4 ALU execution ports, like AMD Zen. On Haswell/Skylake hardware the front-end would be a bottleneck if it compiles as I&#39;m hoping, with <code>xor</code>-zeroing + <code>setcc</code>, or the way C# compiles with <code>setcc</code>/<code>movzx</code>, but I still expected &gt;50% speedup.  Can you paste the asm loop somewhere?  (Unfortunately your answer is right at the 30k char limit.  But so is mine, else I&#39;d move the section I added into my own answer. xD)",
      "score" : 0,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1751045992,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140547946,
      "post_id" : 79676383,
      "body" : "@PeterCordes I tried <code>count += (element &gt; 100 ? 1 : 0);</code> (similar to your <code>count += (int) (element &gt; 100)</code> but with corrected syntax as Java doesn&#39;t allow casting booleans as integers). It sped up the loop by about 20%, but only after a lot of warm-up (the speed increased only on the third and subsequent calls to <code>TestSpeed</code>). I guess the rest of the time is spent indexing the array.",
      "score" : 1,
      "owner" : {
        "account_id" : 19118721,
        "reputation" : 12499,
        "user_id" : 13963086,
        "user_type" : "registered",
        "profile_image" : "https://www.gravatar.com/avatar/9df2c3c4c87d8050b8fd6a59c88c7133?s=256&d=identicon&r=PG&f=y&so-version=2",
        "display_name" : "k314159",
        "link" : "https://stackoverflow.com/users/13963086/k314159"
      },
      "creation_date" : 1751043335,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140542765,
      "post_id" : 79676383,
      "body" : "<a href=\"https://godbolt.org/z/abK19T41h\" rel=\"nofollow noreferrer\">godbolt.org/z/abK19T41h</a> - Clang and GCC know the <code>cmp</code>/<code>sbb $-1, %reg</code> trick for <code>uint8_t *data</code>, avoiding having to materialize a 0/1 integer in a register like they do for <code>int32_t *data</code>.  Compiled with <code>-O3 -fno-tree-vectorize</code> to see their scalar code-gen.",
      "score" : 0,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750893420,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140540099,
      "post_id" : 79676383,
      "body" : "I added some analysis of Java&#39;s C2 assembly loop.  Maybe I should have just posted it as my own answer and referenced yours for the asm; I can do that if you&#39;d prefer.  Unrolling probably didn&#39;t help at all; it has a bottleneck of 2 cycles per compare/cmov, and Zen&#39;s 5-wide front-end could get one compare/conditional-increment plus loop overhead done in maybe 5 or 6 uops, maybe 7 or 8 with asm as clunky as what the JIT made here.  So a rolled-up loop wouldn&#39;t run into any worse bottlenecks than the one imposed by its sub-optimal if-conversion strategy.",
      "score" : 0,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750829795,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140537854,
      "post_id" : 79676383,
      "body" : "@k314159: I wasn&#39;t suggesting hand-modifying the asm from ahead-of-time compilers.  That is a possibility, but then you have to maintain asm versions of functions.  Better (but harder) to improve the compiler to it makes better asm.  Or just use intrinsics to manually vectorize with a good strategy, then compilers can make good asm out of that.  The problem with JITs is that they have to redo optimization on every run (or every install, if they keep the result in a file), so they can&#39;t afford to spend as long looking for optimizations, often missing out on SIMD vectorization.",
      "score" : 3,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750761589,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140537845,
      "post_id" : 79676383,
      "body" : "@k314159: Clang uses a pretty good heuristic: tiny loops get unrolled more than larger loops, e.g. 4x (or even 8x) for tiny loops, 2x for less tiny loops, and not at all for larger loops.  So total loop size doesn&#39;t get huge.  (Some <code>-mtune</code> settings plus <code>-O3</code> do unroll a huge amount, probably too much.)",
      "score" : 0,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750761453,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140537829,
      "post_id" : 79676383,
      "body" : "@VasilisKontopoulos: GCC doesn&#39;t unroll loops either by default even at <code>-O3</code> (except for fully unrolling+peeling small constant-count loops); <code>-funroll-loops</code> is only enabled manually or as part of profile-guided optimization (so it knows which loops are important, like a JVM).  IDK how much profiling info .NET gathers before making final optimized asm, if none then not unrolling makes sense.  For an ahead-of-time compiler, bloating every loop with code like Java is making here would often be overall slower, with more I-cache misses and larger binaries.",
      "score" : 5,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750761188,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140537499,
      "post_id" : 79676383,
      "body" : "@PeterCordes that&#39;s interesting info, but you&#39;re talking about assembly code generated by C++, where it is possible to take the assembly output and hand-optimize it. With JIT compilers like Java and C#, unfortunately we can&#39;t do that.",
      "score" : 0,
      "owner" : {
        "account_id" : 19118721,
        "reputation" : 12499,
        "user_id" : 13963086,
        "user_type" : "registered",
        "profile_image" : "https://www.gravatar.com/avatar/9df2c3c4c87d8050b8fd6a59c88c7133?s=256&d=identicon&r=PG&f=y&so-version=2",
        "display_name" : "k314159",
        "link" : "https://stackoverflow.com/users/13963086/k314159"
      },
      "creation_date" : 1750754490,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140537477,
      "post_id" : 79676383,
      "body" : "@VasilisKontopoulos the fact that C# doesn&#39;t unroll the loop doesn&#39;t mean it&#39;s generally slower: if there was some chunky processing inside the loop (which there usually is) then unrolling wouldn&#39;t make much difference, as the CPU would spend much more time processing inside the loop than looping.",
      "score" : 1,
      "owner" : {
        "account_id" : 19118721,
        "reputation" : 12499,
        "user_id" : 13963086,
        "user_type" : "registered",
        "profile_image" : "https://www.gravatar.com/avatar/9df2c3c4c87d8050b8fd6a59c88c7133?s=256&d=identicon&r=PG&f=y&so-version=2",
        "display_name" : "k314159",
        "link" : "https://stackoverflow.com/users/13963086/k314159"
      },
      "creation_date" : 1750754328,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140536965,
      "post_id" : 79676383,
      "body" : "<a href=\"https://godbolt.org/z/1Tx3j4vTY\" rel=\"nofollow noreferrer\">godbolt.org/z/1Tx3j4vTY</a> shows how GCC and Clang vectorize a byte-compare loop.  They do a pretty bad job, not accumulating vertically at all before they slowly unpack all the way to 32 or 64-bit (the width of the count).  Not using <code>psadbw</code> for horizontal sums of compare results.  The code is a lot cleaner when using signed <code>int32_t</code> for the compares, but it gets 4x less work done per vector than with uint8_t, and doing the unpacking in the same pass as compares is better than doing it separately.",
      "score" : 3,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750742943,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140536953,
      "post_id" : 79676383,
      "body" : "Doing worse than Java probably requires failing to do if-conversion, so having branch mispredicts.  It&#39;s not unrolling that&#39;s the key here, it&#39;s if-conversion from branchy source to branchless asm.  (@VasilisKontopoulos).  About 5x sounds about right for that, like in <a href=\"https://stackoverflow.com/q/11227809\">Why is processing a sorted array faster than processing an unsorted array?</a> which is basically the same problem.  <code>++</code> instead of adding the element is the only real difference.  Note that modern C++ compilers <i>do</i> vectorize this.",
      "score" : 3,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750742309,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140536949,
      "post_id" : 79676383,
      "body" : "@ruakh: It&#39;s not unreasonable to hope that a smart compiler would have vectorized with <code>vpcmpgtd</code> / <code>vpsubd</code> which would go much faster than this clunky asm from Java&#39;s JIT.  The JVM unrolled way too much, and is using XMM vector registers, but only as a way to spill integer regs as an alternative to stack memory, it appears.  It made branchless asm, but not like <code>count += (int)(val &gt; 100);</code>, instead it&#39;s doing <code>count = (val&gt;100) count+1 : count;</code> so the critical path latency includes <code>mov</code> + <code>inc</code> (failed to even use <code>lea</code>) plus <code>cmov</code>.  At least 2 cycle latency, vs. 1 for <code>cmp&#47;setcc</code>/<code>add</code>",
      "score" : 5,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750742102,
      "content_license" : "CC BY-SA 4.0"
    } ],
    "79676396" : [ {
      "comment_id" : 140546115,
      "post_id" : 79676396,
      "body" : "I downvoted this answer.  Java doesn&#39;t SIMD vectorize this loop, and its unrolling isn&#39;t helping in this case.  The important optimization here is if-conversion of the control dependency in the source to a data dependency in the asm, i.e. making branchless asm to process this array of random data.  (SIMD vectorization would also be branchless and even faster, but again, HotSpot misses that optimization, if the answer showing its asm output matches what happened on the OP&#39;s system.)",
      "score" : 1,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750992027,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140544385,
      "post_id" : 79676396,
      "body" : "@KarlKnechtel: Turned my various comments into an answer of my own, with the C# asm output from Sharplab for the original and branchless version.  I haven&#39;t actually benchmarked it, but I don&#39;t need to; it&#39;s branchless and only does sequential memory accesses, so we can just count the uops to get a pretty good prediction of performance.",
      "score" : 1,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750944741,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140542844,
      "post_id" : 79676396,
      "body" : "I forgot to check the OP&#39;s original source!  Yes, as I expected, it compiles to <code>cmp&#47;jle</code> over an <code>inc</code>, so this is nearly a duplicate of <a href=\"https://stackoverflow.com/q/11227809\">Why is processing a sorted array faster than processing an unsorted array?</a> (except Java goes branchless for this, it&#39;s C# that would speed up with a sorted array.)  With the <code>if</code> version, C# uses a memory operand for <code>cmp</code> instead of loading separately, <code>cmp dword [rcx+r9*4+0x10], 0x64</code>.  Instead of a separate load instruction for <code>cmp&#47;setg</code>.  Silly compiler.",
      "score" : 1,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750898401,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140542761,
      "post_id" : 79676396,
      "body" : "With <code>byte[] array</code>, in C# that&#39;s unsigned; same asm except a <code>movzx</code> load.  <a href=\"https://sharplab.io/#v2:EYLgHgbALANALiAhgZwLYB8ACAmAjAWAChMBmAAhzIGEyBvIsxpxgBwCcBLAN0TgFMKuCGQ4A7OGQAqfZHADKLPnwAmACmABPfgG0AumURs2iDQEoGzJvUKXbZAPT2OAMzKrDxjWQC83sqIBXABsg0zI4AAs2AHsAd38+eIBBNgBzANQ+cQA5YKCAUTAAYz4WOA5o0VVTAG4LOyZHFzcPEwA6ABks1MifPwAGMMiY+NFEshT0zPFCkrKKqtr6hpFxMiLogLWBupsVxmdotj5EIoi3MQk+IL5piTEDIxNzPf3rfdtHAxYWQyy4IJeTT8ETIMhbZAcVJjZSragAYjIwD4RUQAWQAkiHDBG1QLA4NzBcGiZFQ0S4AC8wGQKXwYgBaPhgfiiZRiVJkILRRDKZBtZYfdabNYAaj8qmut3+ZAAfGRcP1BmQAPzysggMj9XaCgC+ArsmAA7EKtnBtXY9YQdUA==\" rel=\"nofollow noreferrer\">sharplab.io/&hellip;</a>",
      "score" : 0,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750893128,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140542756,
      "post_id" : 79676396,
      "body" : "With 8 uops, 7 of which need an ALU execution unit, probably only Intel <a href=\"https://chipsandcheese.com/p/skymont-intels-e-cores-reach-for-the-sky\" rel=\"nofollow noreferrer\">Skymont E-cores are 8-wide</a> can run it at 1 compare per cycle; other cores will bottleneck on the front-end and/or integer ALU ports thanks to C# doing everything it could to waste instructions inside the loop, including redoing sign-extension (<code>movsxd</code>) of a 32-bit index despite using <code>foreach (int element in array)</code> instead of manual indexing.  (Lion Cove and Zen 5 are 8-wide but &quot;only&quot; have 6 integer ALU ports, so close to 1/clock.)",
      "score" : 0,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750892765,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140542737,
      "post_id" : 79676396,
      "body" : "@KarlKnechtel: Yeah, if someone with C# installed can test that, please do. <code>count += (element &gt; 100) ? 1 : 0;</code> instead of the <code>if</code> compiles to an 8-uop using <code>cmp</code>/<code>setg</code>/<code>movzx</code>/<code>add</code> -   <a href=\"https://sharplab.io/#v2:EYLgHgbALANALiAhgZwLYB8ACAmAjAWAChMBmAAhzIGEyBvIsxpxgBwCcBLAN0TgFMKuCGQ4A7OGQAqfZHADKLPnwAmACjFwA2gF0yiNm0QBPAJQNmTeoQs2RAMzKr9ho2QC8bsqICuAG18mZHAAFmwA9gDuXnxRAIJsAObeqHziAHJ+vgCiYADGfCxwHGGiqiYA3Oa2TBwOTgbGAHQAMqkJIe6eAAyBIeFRojFk8Ukp4jn5hcWlFVXVIuJkuWHei92V1vOMdmFsfIi5wY4aZHy+fGMSYnoNpnPVVls2y6sSANSeqmcXqRIAfGRcF0emQAPyAsggMhdDZPMgAX3utkwAHYlitxLDbIjCPCgA\" rel=\"nofollow noreferrer\">sharplab.io/&hellip;</a>",
      "score" : 0,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750891845,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140541688,
      "post_id" : 79676396,
      "body" : "@PeterCordes It seems worth checking whether actually writing the code that way helps in C#, then.",
      "score" : 3,
      "owner" : {
        "account_id" : 248321,
        "reputation" : 61443,
        "user_id" : 523612,
        "user_type" : "registered",
        "accept_rate" : 100,
        "profile_image" : "https://www.gravatar.com/avatar/4ae512dd708a619496d36b1f681f95e0?s=256&d=identicon&r=PG",
        "display_name" : "Karl Knechtel",
        "link" : "https://stackoverflow.com/users/523612/karl-knechtel"
      },
      "creation_date" : 1750864421,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140536978,
      "post_id" : 79676396,
      "body" : "As I commented on other answers, I expect the main difference isn&#39;t unrolling, it&#39;s if-conversion: making branchless asm from an <code>if(){}</code> in the source.  (Ideally <code>count += (int)(x &gt;= 100);</code> with <code>cmp&#47;setge&#47;add</code>, or what Java does which has a longer critical path latency of at least 2 cycles (increment and cmov), <code>count = (x&gt;=100) ? count+1 : count;</code>.  Java is up to 2x or potentially 3x on Ice Lake slower than it could be with simple scalar code, but at least it avoids branch mispredictions.)",
      "score" : 6,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750743400,
      "content_license" : "CC BY-SA 4.0"
    } ],
    "79680585" : [ {
      "comment_id" : 140544392,
      "post_id" : 79680585,
      "body" : "This got kinda long, and could probably use proof-reading.  It was taking too long to write so I didn&#39;t do a final read-through of the whole thing.  I&#39;m sure I&#39;ve repeated myself some, some of it intentionally so separate paragraphs / sections are more self-contained.",
      "score" : 0,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750944842,
      "content_license" : "CC BY-SA 4.0"
    } ],
    "79676247" : [ {
      "comment_id" : 140539663,
      "post_id" : 79676247,
      "body" : "@Slaw: In scalar code (for compilers that won&#39;t auto-vectorize), just widen to <code>int</code> on the fly; a <code>movzx eax, byte [mem]</code> load is basically free if it compiles as written, although <code>cmp byte [mem], 100</code> on x86 could save a front-end uop since we don&#39;t need the byte value. (RISCs always need to load separately).  But if we&#39;re stuck with signed bytes, the (JIT) compiler would want to do <code>movsx</code> sign extension to <code>int</code>.  How is the original code solving that problem?  Oh, with <code>x &amp; 0xFF</code>, so we can then hope the JIT is smart enough to see that sign-extension + masking = zero-extension.",
      "score" : 1,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750804404,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140539659,
      "post_id" : 79676247,
      "body" : "@Slaw x86 (without AVX-512) doesn&#39;t have SIMD unsigned compares either, but it does have unsigned <code>min</code> and <code>==</code>.  Without using that either, add/subtract or XOR with <code>128</code> to range-shift unsigned bytes to signed, so <code>(x^128) &gt;= (100^128)</code> with a signed byte compare should be equivalent to <code>x &gt;= 100u</code> with an unsigned byte compare.  (And we can hopefully leave it up to the compiler to do <code>a &gt;= b</code> as <code>!(b &gt; a)</code> with <code>vpcmpgt</code>, but maybe counting not-greater and subtracting could avoid an instruction in the loop.)",
      "score" : 1,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750804138,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140538639,
      "post_id" : 79676247,
      "body" : "@PeterCordes Changing from <code>int[]</code> and <code>IntVector</code> to <code>byte[]</code> and <code>ByteVector</code> changed the JMH timings to <code>62.998 &#177; 1.056 ms&#47;op</code>, <code>7.430 &#177; 0.148 ms&#47;op</code>, and <code>3.843 &#177; 0.112 ms&#47;op</code> (timings with respect to my previous comment), so at least on Java making the switch definitely improves execution time for vector implementations in this case. But just wondering, I had to compare <code>GT</code> 100 and <code>LT</code> 0 in two steps to account for the fact Java bytes are signed; is there a way to do a single comparison without actually widening the values to an int?",
      "score" : 1,
      "owner" : {
        "account_id" : 8532578,
        "reputation" : 49904,
        "user_id" : 6395627,
        "user_type" : "registered",
        "profile_image" : "https://www.gravatar.com/avatar/af0f9bfe593f36642a032cd7ea611e7d?s=256&d=identicon&r=PG&f=y&so-version=2",
        "display_name" : "Slaw",
        "link" : "https://stackoverflow.com/users/6395627/slaw"
      },
      "creation_date" : 1750776571,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140536968,
      "post_id" : 79676247,
      "body" : "Actually the trick for unsigned compare <code>x &gt;= 100u</code> without AVX-512 is <code>pminub</code> / <code>pcmpeqb</code>, to check if <code>min(x, 100u) == 100u</code>.  <a href=\"https://godbolt.org/z/1Tx3j4vTY\" rel=\"nofollow noreferrer\">godbolt.org/z/1Tx3j4vTY</a> shows how GCC and Clang auto-vectorize a loop over bytes.  (Not great, but much better than scalar.)",
      "score" : 1,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750743019,
      "content_license" : "CC BY-SA 4.0"
    } ],
    "79676180" : [ {
      "comment_id" : 140547553,
      "post_id" : 79676180,
      "body" : "I&#39;d assume it was downvoted because of the first sentence being wrong.  <code>foreach</code> should compile to asm that&#39;s at least as good as <code>for</code>.  (And if not, that&#39;s very surprising and needs some evidence to back it up.)  Also, as commenters pointed out, the Java uses <code>for (int element : byteArray)</code> which is effectively a <code>foreach</code>.",
      "score" : 0,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1751033981,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140546897,
      "post_id" : 79676180,
      "body" : "See new edits. Not sure why this was downvoted to be honest...",
      "score" : 0,
      "owner" : {
        "account_id" : 20264817,
        "reputation" : 78793,
        "user_id" : 14868997,
        "user_type" : "registered",
        "profile_image" : "https://www.gravatar.com/avatar/40cbeeb90667c9a8c1830f615a9b2899?s=256&d=identicon&r=PG",
        "display_name" : "Charlieface",
        "link" : "https://stackoverflow.com/users/14868997/charlieface"
      },
      "creation_date" : 1751019513,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140546803,
      "post_id" : 79676180,
      "body" : "I updated my answer with a <code>Vector&lt;byte&gt;</code> version that avoids unpacking first.  I noticed that it and your answer both compile with bounds-checks on every SIMD load.  Is there a way to avoid that, like maybe <code>MemoryMarshal.Cast&lt;byte, Vector&lt;byte&gt;&gt;</code> outside the loop, and index whole vectors?  Or would one need <code>.LoadUnsafe()</code>?",
      "score" : 0,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1751017523,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140546122,
      "post_id" : 79676180,
      "body" : "For the record, the vectorization strategy here, with <code>Vector.Subtract(count, mask);</code> inside the loop and <code>Vector.Sum(count);</code> outside, is <i>much</i> better than what  Matthew Watson&#39;s answer is doing with <code>scalarcount -= Vector.Sum</code> inside the loop.  On x86-64, <code>Vector.Sum</code> costs 2 or 3 shuffles + adds (for 128-bit or 256-bit vectors respectively), plus a <code>vmovq</code> from vector to scalar.  But the JVM isn&#39;t vectorizing, just making branchless scalar asm according to k314159&#39;s answer.",
      "score" : 0,
      "owner" : {
        "account_id" : 78868,
        "reputation" : 377570,
        "user_id" : 224132,
        "user_type" : "registered",
        "accept_rate" : 83,
        "profile_image" : "https://i.sstatic.net/N4ivW.png?s=256",
        "display_name" : "Peter Cordes",
        "link" : "https://stackoverflow.com/users/224132/peter-cordes"
      },
      "creation_date" : 1750992511,
      "content_license" : "CC BY-SA 4.0"
    } ]
  }
}