{
  "question" : {
    "question_id" : 79753814,
    "title" : "How to enforce delay between Kafka retry topic consumers (e.g., 5m, 15m, 30m) in Spring Boot?",
    "body" : "<p>I'm building a Kafka-based retry mechanism in a Spring Boot application. The setup involves:</p>\n<ul>\n<li>A primary topic for normal processing.</li>\n<li>Three retry topics (<code>topic-retry-5m</code>, <code>topic-retry-15m</code>, <code>topic-retry-30m</code>) for retrying failed events after <code>5</code>, <code>15</code>, and <code>30</code> minutes.</li>\n<li>Each retry topic has its own <code>@KafkaListener</code>.</li>\n</ul>\n<p>The Kafka consumer config is shared across all topics using Spring beans, and I override the consumer group ID only for retry topics.</p>\n<p>The question is how can I ensure the retry messages are only consumed after <code>5</code>, <code>15</code>, or <code>30</code> minutes.\nRight now:</p>\n<ul>\n<li>Kafka will consume retry messages immediately after theyâ€™re published to the retry topics.</li>\n<li>I need a simple way to delay consumption or schedule publishing to enforce this retry timing.</li>\n</ul>\n<p>I think publishing after some scheduled delay would be a way but It's not gonna work. Since, a lot of messages stacking up will kill down the application, also storing temporarily doesn't sound like right choice.</p>\n<hr />\n<p>The use case is we have to call third party service to deliver information once some operation happens in our application. If third party service is unreachable or response timed out then re-calling the service instantly will not be worth doing so, we want to have a retry mechanism after some delay. We have one service that does our actual operation and publishes the info to Kafka queue and third party caller service which consumes from queue, prepares request and make third party call.</p>\n",
    "tags" : [ "java", "apache-kafka", "spring-kafka" ],
    "owner" : {
      "account_id" : 20679683,
      "reputation" : 111,
      "user_id" : 15183550,
      "user_type" : "registered",
      "profile_image" : "https://i.sstatic.net/0y9zF.png?s=256",
      "display_name" : "Satya Raj Awasthi",
      "link" : "https://stackoverflow.com/users/15183550/satya-raj-awasthi"
    },
    "is_answered" : true,
    "view_count" : 294,
    "answer_count" : 1,
    "score" : 1,
    "last_activity_date" : 1756915760,
    "creation_date" : 1756836898,
    "link" : "https://stackoverflow.com/questions/79753814/how-to-enforce-delay-between-kafka-retry-topic-consumers-e-g-5m-15m-30m-in",
    "content_license" : "CC BY-SA 4.0"
  },
  "answers" : [ {
    "answer_id" : 79753841,
    "question_id" : 79753814,
    "body" : "<p>This &quot;mechanism&quot; is already built in Spring Kafka - it called <a href=\"https://docs.spring.io/spring-kafka/api/org/springframework/kafka/annotation/RetryableTopic.html\" rel=\"nofollow noreferrer\">RetriableTopic</a>.</p>\n<p>What you need not to forget - is to configure yourself a backoff with desired parameters.</p>\n<p>In your case, it's either a custom implementation of a <a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/util/backoff/BackOff.html\" rel=\"nofollow noreferrer\">Backoff interface</a>, or <a href=\"https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/util/backoff/ExponentialBackOff.html\" rel=\"nofollow noreferrer\">ExponentialBackoff</a> with a trick: set initial interval to 5, multiplier to 3 (so next happened at 15), and, most important, maxElapsedTime to 30 (so next won't happen at 45, as multiplier suggests, but earlier).</p>\n<p>As a bonus, you'd have a DLT for whatever failed all attempts.</p>\n",
    "score" : 3,
    "is_accepted" : true,
    "owner" : {
      "account_id" : 7692774,
      "reputation" : 1282,
      "user_id" : 5828464,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/de54db63fab1e3c3d00d0dbef1a0a0f1?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Yuri G",
      "link" : "https://stackoverflow.com/users/5828464/yuri-g"
    },
    "creation_date" : 1756838771,
    "last_activity_date" : 1756838771,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "question_comments" : [ ],
  "answer_comments" : {
    "79753841" : [ {
      "comment_id" : 140712821,
      "post_id" : 79753841,
      "body" : "@SatyaRajAwasthi Not necessarily custom exception, but you do have the option of catching any exception in your custom error handler (or standard but configured to your needs). It just so looks that you don&#39;t really need it, cause your probable cause of processing issue lies outside your system, and delay &amp; another attempt is your only reasonable option.",
      "score" : 0,
      "owner" : {
        "account_id" : 7692774,
        "reputation" : 1282,
        "user_id" : 5828464,
        "user_type" : "registered",
        "profile_image" : "https://www.gravatar.com/avatar/de54db63fab1e3c3d00d0dbef1a0a0f1?s=256&d=identicon&r=PG&f=y&so-version=2",
        "display_name" : "Yuri G",
        "link" : "https://stackoverflow.com/users/5828464/yuri-g"
      },
      "creation_date" : 1756925881,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140711433,
      "post_id" : 79753841,
      "body" : "@SatyaRajAwasthi Get the details on the API documentation. Thanks.",
      "score" : 0,
      "owner" : {
        "account_id" : 20679683,
        "reputation" : 111,
        "user_id" : 15183550,
        "user_type" : "registered",
        "profile_image" : "https://i.sstatic.net/0y9zF.png?s=256",
        "display_name" : "Satya Raj Awasthi",
        "link" : "https://stackoverflow.com/users/15183550/satya-raj-awasthi"
      },
      "creation_date" : 1756894669,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140710778,
      "post_id" : 79753841,
      "body" : "Thanks @yuri-g for the answer. So, I should be throwing some custom exception and pass it to include parameter on the annotation, right ?    Also, just curious how does Spring Kafka delays it? Does it ignore consuming or consume and repush until the delay time is exceeded ? Since, the kafka design is to make the consumer listening the message once its published.",
      "score" : 0,
      "owner" : {
        "account_id" : 20679683,
        "reputation" : 111,
        "user_id" : 15183550,
        "user_type" : "registered",
        "profile_image" : "https://i.sstatic.net/0y9zF.png?s=256",
        "display_name" : "Satya Raj Awasthi",
        "link" : "https://stackoverflow.com/users/15183550/satya-raj-awasthi"
      },
      "creation_date" : 1756874416,
      "content_license" : "CC BY-SA 4.0"
    } ]
  }
}