{
  "question" : {
    "question_id" : 79588572,
    "title" : "How to specify output format in speech-to-text v2 recognize requests?",
    "body" : "<p>I am trying to use v2 speech to text API and cant figure out how to pass OutputFormatConfig set to set or vat as the output format for the transcription.\nThe java class for RecognitionOutputConfig doesn't have OutputFormatConfig.\n<a href=\"https://cloud.google.com/speech-to-text/v2/docs/reference/rpc/google.cloud.speech.v2#recognitionoutputconfig\" rel=\"nofollow noreferrer\">https://cloud.google.com/speech-to-text/v2/docs/reference/rpc/google.cloud.speech.v2#recognitionoutputconfig</a>\n<a href=\"https://cloud.google.com/speech-to-text/v2/docs/reference/rpc/google.cloud.speech.v2#google.cloud.speech.v2.OutputFormatConfig\" rel=\"nofollow noreferrer\">https://cloud.google.com/speech-to-text/v2/docs/reference/rpc/google.cloud.speech.v2#google.cloud.speech.v2.OutputFormatConfig</a></p>\n<p>This is the contents of <code>RecognitionOutputConfig.java</code> it doesn't include <a href=\"https://cloud.google.com/speech-to-text/v2/docs/reference/rpc/google.cloud.speech.v2#google.cloud.speech.v2.OutputFormatConfig\" rel=\"nofollow noreferrer\">OutputFormatConfig</a> property.</p>\n<pre><code>public final class RecognitionOutputConfig extends GeneratedMessageV3 implements RecognitionOutputConfigOrBuilder {\n  private static final long serialVersionUID = 0L;\n  private int outputCase_;\n  private Object output_;\n  public static final int GCS_OUTPUT_CONFIG_FIELD_NUMBER = 1;\n  public static final int INLINE_RESPONSE_CONFIG_FIELD_NUMBER = 2;\n  private byte memoizedIsInitialized;\n  private static final RecognitionOutputConfig DEFAULT_INSTANCE = new RecognitionOutputConfig();\n</code></pre>\n<p>I tried looking every where and going through different classes to see which one has this property and am drawing blanks. Any help would be greatly appreciated. We need the extensibility to support both srt and vtt output formats.</p>\n<pre><code>// Imports the Google Cloud client library\nimport com.google.api.gax.longrunning.OperationFuture;\nimport com.google.cloud.speech.v2.AutoDetectDecodingConfig;\nimport com.google.cloud.speech.v2.CreateRecognizerRequest;\nimport com.google.cloud.speech.v2.OperationMetadata;\nimport com.google.cloud.speech.v2.RecognitionConfig;\nimport com.google.cloud.speech.v2.RecognizeRequest;\nimport com.google.cloud.speech.v2.RecognizeResponse;\nimport com.google.cloud.speech.v2.Recognizer;\nimport com.google.cloud.speech.v2.SpeechClient;\nimport com.google.cloud.speech.v2.SpeechRecognitionAlternative;\nimport com.google.cloud.speech.v2.SpeechRecognitionResult;\nimport com.google.protobuf.ByteString;\nimport java.io.IOException;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.List;\nimport java.util.concurrent.ExecutionException;\n\npublic class QuickstartSampleV2 {\n\n  public static void main(String[] args) throws IOException, ExecutionException,\n      InterruptedException {\n    String projectId = &quot;my-project-id&quot;;\n    String filePath = &quot;path/to/audioFile.raw&quot;;\n    String recognizerId = &quot;my-recognizer-id&quot;;\n    quickstartSampleV2(projectId, filePath, recognizerId);\n  }\n\n  public static void quickstartSampleV2(String projectId, String filePath, String recognizerId)\n      throws IOException, ExecutionException, InterruptedException {\n\n    // Initialize client that will be used to send requests. This client only needs to be created\n    // once, and can be reused for multiple requests. After completing all of your requests, call\n    // the &quot;close&quot; method on the client to safely clean up any remaining background resources.\n    try (SpeechClient speechClient = SpeechClient.create()) {\n      Path path = Paths.get(filePath);\n      byte[] data = Files.readAllBytes(path);\n      ByteString audioBytes = ByteString.copyFrom(data);\n\n      String parent = String.format(&quot;projects/%s/locations/global&quot;, projectId);\n\n      // First, create a recognizer\n      Recognizer recognizer = Recognizer.newBuilder()\n          .setModel(&quot;latest_long&quot;)\n          .addLanguageCodes(&quot;en-US&quot;)\n          .build();\n\n      CreateRecognizerRequest createRecognizerRequest = CreateRecognizerRequest.newBuilder()\n          .setParent(parent)\n          .setRecognizerId(recognizerId)\n          .setRecognizer(recognizer)\n          .build();\n\n      OperationFuture&lt;Recognizer, OperationMetadata&gt; operationFuture =\n          speechClient.createRecognizerAsync(createRecognizerRequest);\n      recognizer = operationFuture.get();\n\n      // Next, create the transcription request\n      RecognitionConfig recognitionConfig = RecognitionConfig.newBuilder()\n          .setAutoDecodingConfig(AutoDetectDecodingConfig.newBuilder().build())\n          .build();\n         RecognitionOutputConfig.Builder outputConfigBuilder =     RecognitionOutputConfig.newBuilder()\n          .setGcsOutputConfig(GcsOutputConfig.newBuilder()\n            .setUri(&quot;gs://&quot; + bucketName + &quot;/output/&quot; + file.getFileName().toString() + &quot;.&quot;+subtitleFormat))\n.setOutputFormatConfig(OutputFormatConfig.newBuilder().build);\n\n      RecognizeRequest request = RecognizeRequest.newBuilder()\n          .setConfig(recognitionConfig)\n          .setRecognizer(recognizer.getName())\n.setRecognitionOutputConfig(outputConfigBuilder.build())\n          .setContent(audioBytes)\n          .build();\n\n      RecognizeResponse response = speechClient.recognize(request);\n      List&lt;SpeechRecognitionResult&gt; results = response.getResultsList();\n\n      for (SpeechRecognitionResult result : results) {\n        // There can be several alternative transcripts for a given chunk of speech. Just use the\n        // first (most likely) one here.\n        if (result.getAlternativesCount() &gt; 0) {\n          SpeechRecognitionAlternative alternative = result.getAlternativesList().get(0);\n          System.out.printf(&quot;Transcription: %s%n&quot;, alternative.getTranscript());\n        }\n      }\n    }\n  }\n}\n</code></pre>\n",
    "tags" : [ "java", "google-speech-to-text-api" ],
    "owner" : {
      "account_id" : 30698879,
      "reputation" : 11,
      "user_id" : 23537423,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/e31afa6a450b06816281e59f5bb27e17?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Sagar Kaja",
      "link" : "https://stackoverflow.com/users/23537423/sagar-kaja"
    },
    "is_answered" : false,
    "view_count" : 55,
    "answer_count" : 0,
    "score" : 1,
    "last_activity_date" : 1745409545,
    "creation_date" : 1745409545,
    "link" : "https://stackoverflow.com/questions/79588572/how-to-specify-output-format-in-speech-to-text-v2-recognize-requests",
    "content_license" : "CC BY-SA 4.0"
  },
  "answers" : [ ],
  "question_comments" : [ ],
  "answer_comments" : { }
}