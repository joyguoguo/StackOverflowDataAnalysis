{
  "question" : {
    "question_id" : 79638703,
    "title" : "Solr DIH pagination using paginated query processes only one chunk",
    "body" : "<p>I'm indexing a SQL-based view into Solr using DataImportHandler (DIH), trying to implement pagination by using ROW_NUMBER() in the query. The goal is to chunk the import by passing start and rows parameters for large datasets.</p>\n<p>However, only one chunk is being processed per run—meaning if I set start=100 only that chunk runs, if I set start=400 only that chunk runs. Even though I have a loop in Java which should run through all chunks, the rest don’t trigger additional imports. No errors appear, and the statusMessages for the chunk say it completed successfully.</p>\n<p>The query (in <strong>data-config.xml</strong>) looks like this:</p>\n<pre><code>&lt;dataConfig&gt;\n &lt;dataSource connectionRetryCount=&quot;5&quot; connectionRetryWait=&quot;10000&quot; driver=&quot;com.jnetdirect.jsql.JSQLDriver&quot; name=&quot;jdbcDS&quot; password=&quot;abc1234&quot; type=&quot;JdbcDataSource&quot; url=&quot;jdbc:JSQLConnect://localhost:1433/database=ABC_XYZ&quot; user=&quot;abc&quot;/&gt;\n &lt;document&gt;\n   &lt;entity dataSource=&quot;jdbcDS&quot; name=&quot;matter&quot; pk=&quot;matterid&quot; \n    query=&quot;SELECT * FROM (SELECT *, ROW_NUMBER() OVER ( ORDER BY CREATORORGID, MATTERID) AS RowNum FROM MyView WITH (NOLOCK) ) AS T WHERE T.RowNum &gt; '${dataimporter.request.start}' AND T.RowNum &lt;= ('${dataimporter.request.start}' + '${dataimporter.request.rows}')&quot;\n    transformer=&quot;RegexTransformer&quot;&gt;\n    ...\n   &lt;/entity&gt;\n  &lt;/document&gt;\n&lt;/dataConfig&gt;\n</code></pre>\n<p><strong>Java code snippet that loops through chunks:</strong></p>\n<pre><code>int start = 200;\nint totalRowsFetched = 809;\n\ngetSolrConfigsXmlBuilder().buildDataConfigFile(orgData, dataConfigXmlPath, dbInfo, coreData.getOrgId(), fullImport, useTempView);\n\nwhile (start &lt; totalRowsFetched) {\n  int adjustedRows = Math.min(DEFAULT_BATCH_SIZE, totalRowsFetched - start);\n\n  ModifiableSolrParams params = new ModifiableSolrParams();\n  String indexType = SOLR_INDEX_TYPE_FULL;\n\n  params.set(SOLR_QUERY_PARAM_QT, SOLR_QUERY_PARAM_DATAIMPORT);\n  params.set(SOLR_QUERY_PARAM_SYNCHRONOUS, syncImport);// false\n\n  if(!fullImport) {\n     indexType = SOLR_INDEX_TYPE_DELTA;\n     params.set(SOLR_QUERY_PARAM_CLEAN, Boolean.FALSE.toString());\n  }\n  params.set(SOLR_QUERY_PARAM_COMMIT, Boolean.TRUE.toString());\n  params.set(SOLR_QUERY_PARAM_COMMAND, SOLR_QUERY_PARAM_FULL_IMPORT);\n  params.set(SOLR_QUERY_PARAM_START, String.valueOf(start));\n  params.set(SOLR_QUERY_PARAM_ROWS, String.valueOf(adjustedRows));\n\n  log.info(String.format(&quot;Chunked import: Start=%d, Rows=%d for core %s&quot;, start, DEFAULT_BATCH_SIZE, coreData.getCoreName()));\n\n  QueryResponse queryResponse;\n  log.info(String.format(&quot;Starting '%s' index of Solr core: [%s]&quot;, indexType, coreData.getCoreName()));\n  queryResponse = getTemplate().getSolrClientOrDefault(coreData.getSolrServerAddress()).query(coreData.getCoreName(), params);\n\n  String statusMessages = &quot;&quot;;\n  if(queryResponse != null &amp;&amp; queryResponse.getResponse() != null\n     &amp;&amp; queryResponse.getResponse().get(&quot;statusMessages&quot;) != null) {\n    statusMessages = queryResponse.getResponse().get(&quot;statusMessages&quot;).toString();\n  }\n  log.info(&quot;Chunk import completed: &quot; + statusMessages);\n  start += adjustedRows;\n }\nresponse = new FipSolrAdminResponse(FipSolrAdminResponse.ResponseCodeType.SUCCESS, &quot;All chunks processed successfully.&quot;,String.format(&quot;Solr Index for core/collection [%s] has been successfully created&quot;, coreData.getCoreName()));\n</code></pre>\n<p><strong>What I’ve tried:</strong></p>\n<ul>\n<li>Verified that start and rows are being set and incremented correctly\nin the loop.</li>\n<li>Confirmed the SQL query works manually with hardcoded values.</li>\n<li>Checked Solr logs and DIH debug mode – it only processes one batch.</li>\n</ul>\n<p><strong>Question:</strong></p>\n<p>How can I get Solr DIH to process all paginated chunks sequentially, using this ROW_NUMBER() query approach? Is there something about DIH or Solr query parameters I’m missing? Should the DIH command or request handling be different to allow multiple chunked imports in a single process?</p>\n<p>Thanks in advance for any insights!</p>\n",
    "tags" : [ "java", "solr", "pagination", "chunks", "dih" ],
    "owner" : {
      "account_id" : 42198864,
      "reputation" : 1,
      "user_id" : 30637447,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/e1c59988ea30cb73284805fa8c209abc?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "Jaismeen",
      "link" : "https://stackoverflow.com/users/30637447/jaismeen"
    },
    "is_answered" : false,
    "view_count" : 46,
    "answer_count" : 0,
    "score" : 0,
    "last_activity_date" : 1748253736,
    "creation_date" : 1748253736,
    "link" : "https://stackoverflow.com/questions/79638703/solr-dih-pagination-using-paginated-query-processes-only-one-chunk",
    "content_license" : "CC BY-SA 4.0"
  },
  "answers" : [ ],
  "question_comments" : [ ],
  "answer_comments" : { }
}