{
  "question" : {
    "question_id" : 79569570,
    "title" : "Unable to use brotli compression in Azure Databricks runtime 15.4 LTS",
    "body" : "<pre><code>spark.conf.set(&quot;spark.sql.parquet.compression.codec&quot;, &quot;brotli&quot;)\ndf.write.format(&quot;delta&quot;).mode(&quot;overwrite&quot;).saveAsTable(table_name, path= delta_table_path) \n</code></pre>\n<p>Error message is :\nspark.conf.set(&quot;spark.sql.parquet.compression.codec&quot;, &quot;brotli&quot;)\ndf.write.format(&quot;delta&quot;).mode(&quot;overwrite&quot;).saveAsTable(table_name, path= delta_table_path)</p>\n<p>An error occurred while calling o432.saveAsTable.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 5.0 failed 4 times, most recent failure: Lost task 3.3 in stage 5.0 (TID 53) (10.139.64.5 executor 0): org.apache.parquet.hadoop.BadConfigurationException: Class org.apache.hadoop.io.compress.BrotliCodec was not found at org.apache.parquet.hadoop.CodecFactory.getCodec(CodecFactory.java:254) at org.apache.parquet.hadoop.CodecFactory$HeapBytesCompressor.(CodecFactory.java:155)\nat org.apache.parquet.hadoop.CodecFactory.createCompressor(CodecFactory.java:219)at org.apache.parquet.hadoop.CodecFactory.getCompressor(CodecFactory.java:202)\nat org.apache.parquet.hadoop.ParquetRecordWriter.(ParquetRecordWriter.java:152)\nat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:565)\nat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:473)\nat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:462)\nat org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.(ParquetOutputWriter.scala:36)\nat org.apache.spark.sql.execution.datasources.parquet.ParquetUtils$$anon$1.newInstance(ParquetUtils.scala:570)\nat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:205)\nat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.(FileFormatDataWriter.scala:187)\nat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:545)\nat org.apache.spark.sql.execution.datasources.WriteFilesExec.$anonfun$doExecuteWrite$1(WriteFiles.scala:125)\nat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:938)\nat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:938)\nat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n8 spark.conf.set(&quot;spark.sql.parquet.compression.codec&quot;, &quot;brotli&quot;)\n---&gt; 10 df.write.format(&quot;delta&quot;).mode(&quot;overwrite&quot;).saveAsTable(table_name, path= delta_table_path)</p>\n",
    "tags" : [ "java", "apache-spark", "hadoop", "azure-databricks" ],
    "owner" : {
      "account_id" : 8624929,
      "reputation" : 947,
      "user_id" : 6458418,
      "user_type" : "registered",
      "accept_rate" : 0,
      "profile_image" : "https://www.gravatar.com/avatar/800fee9d7d9d1778f1c3d252687153ee?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "knowdotnet",
      "link" : "https://stackoverflow.com/users/6458418/knowdotnet"
    },
    "is_answered" : false,
    "view_count" : 135,
    "answer_count" : 1,
    "score" : 0,
    "last_activity_date" : 1744635400,
    "creation_date" : 1744398831,
    "link" : "https://stackoverflow.com/questions/79569570/unable-to-use-brotli-compression-in-azure-databricks-runtime-15-4-lts",
    "content_license" : "CC BY-SA 4.0"
  },
  "answers" : [ {
    "answer_id" : 79573201,
    "question_id" : 79569570,
    "body" : "<p>The error you are encountering is due to the fact that the Brotli compression codec is not found in your environment.\nThis is indicated by the</p>\n<blockquote>\n<p>org.apache.parquet.hadoop.BadConfigurationException: Class\norg.apache.hadoop.io.compress.BrotliCodec was not found error</p>\n</blockquote>\n<p>message.</p>\n<p>To resolve this issue:</p>\n<p>Make sure that the Brotli codec is available in your Spark environment.\nYou might need to add the necessary dependencies to your Spark configuration.\nFor example, you can add the Brotli codec jar to your Spark session.</p>\n<p>If adding the Brotli codec is not feasible, you can switch to a different compression codec that is supported in your environment.\nCommonly used codecs include <strong>snappy</strong>, <strong>gzip</strong>, and <strong>lz4</strong>.</p>\n<p>The below code shows how set a different compression codec:</p>\n<pre><code>spark.conf.set(&quot;spark.sql.parquet.compression.codec&quot;, &quot;snappy&quot;)\ndf.write.format(&quot;delta&quot;).mode(&quot;overwrite&quot;).saveAsTable(table_name, path=delta_table_path)\n</code></pre>\n<p><strong>Other approaches:</strong></p>\n<pre><code>spark.sql(&quot;set spark.sql.parquet.compression.codec=gzip&quot;);\n\n\nsqlContext.setConf(&quot;spark.sql.parquet.compression.codec&quot;, &quot;uncompressed&quot;)\n</code></pre>\n<p>The value highlighted could be one of the four : uncompressed, <strong>snappy</strong>, <strong>gzip</strong>, <strong>lzo</strong></p>\n<pre><code>df.write.option(&quot;compression&quot;,&quot;none&quot;).mode(&quot;overwrite&quot;).save(&quot;testoutput.parquet&quot;)\n</code></pre>\n",
    "score" : 0,
    "is_accepted" : false,
    "owner" : {
      "account_id" : 28240346,
      "reputation" : 3681,
      "user_id" : 21588212,
      "user_type" : "registered",
      "profile_image" : "https://i.sstatic.net/7f73C.png?s=256",
      "display_name" : "Dileep Raj Narayan Thumula",
      "link" : "https://stackoverflow.com/users/21588212/dileep-raj-narayan-thumula"
    },
    "creation_date" : 1744635400,
    "last_activity_date" : 1744635400,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "question_comments" : [ {
    "comment_id" : 140332812,
    "post_id" : 79569570,
    "body" : ".option(&quot;spark.databricks.io.cache.enabled&quot;, False) can you try this?",
    "score" : 0,
    "owner" : {
      "account_id" : 28240346,
      "reputation" : 3681,
      "user_id" : 21588212,
      "user_type" : "registered",
      "profile_image" : "https://i.sstatic.net/7f73C.png?s=256",
      "display_name" : "Dileep Raj Narayan Thumula",
      "link" : "https://stackoverflow.com/users/21588212/dileep-raj-narayan-thumula"
    },
    "creation_date" : 1744634193,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "answer_comments" : {
    "79573201" : [ {
      "comment_id" : 140336780,
      "post_id" : 79573201,
      "body" : "After installing the Brotli codec, you can set the compression codec and write the Delta table spark.conf.set(&quot;spark.sql.parquet.compression.codec&quot;, &quot;brotli&quot;) df.write.format(&quot;delta&quot;).mode(&quot;overwrite&quot;).saveAsTable(table&zwnj;&#8203;_name, path=delta_table_path)",
      "score" : 0,
      "owner" : {
        "account_id" : 28240346,
        "reputation" : 3681,
        "user_id" : 21588212,
        "user_type" : "registered",
        "profile_image" : "https://i.sstatic.net/7f73C.png?s=256",
        "display_name" : "Dileep Raj Narayan Thumula",
        "link" : "https://stackoverflow.com/users/21588212/dileep-raj-narayan-thumula"
      },
      "creation_date" : 1744720714,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140336776,
      "post_id" : 79573201,
      "body" : "The error you are encountering indicates that the Brotli codec is not available in your Spark environment. Even though the documentation states that Brotli should work, it might not be included in your current Spark setup. you can add the Brotli codec dependency in a Databricks notebook: %python %pip install brotli",
      "score" : 0,
      "owner" : {
        "account_id" : 28240346,
        "reputation" : 3681,
        "user_id" : 21588212,
        "user_type" : "registered",
        "profile_image" : "https://i.sstatic.net/7f73C.png?s=256",
        "display_name" : "Dileep Raj Narayan Thumula",
        "link" : "https://stackoverflow.com/users/21588212/dileep-raj-narayan-thumula"
      },
      "creation_date" : 1744720664,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140336021,
      "post_id" : 79573201,
      "body" : "As per documentation brotli should work.  Above is a not a solution or fix.",
      "score" : 0,
      "owner" : {
        "account_id" : 8624929,
        "reputation" : 947,
        "user_id" : 6458418,
        "user_type" : "registered",
        "accept_rate" : 0,
        "profile_image" : "https://www.gravatar.com/avatar/800fee9d7d9d1778f1c3d252687153ee?s=256&d=identicon&r=PG&f=y&so-version=2",
        "display_name" : "knowdotnet",
        "link" : "https://stackoverflow.com/users/6458418/knowdotnet"
      },
      "creation_date" : 1744708790,
      "content_license" : "CC BY-SA 4.0"
    } ]
  }
}