{
  "question" : {
    "question_id" : 79748476,
    "title" : "Kafka topic offset was committed despite deserialization problem",
    "body" : "<p>I deliberately used the wrong deserializer to test how Kafka handles deserialization errors. I found that the Kafka topic offset was committed automatically, despite the deserialization error.</p>\n<p>I have already implemented the ErrorHandlingDeserializer and the DefaultErrorHandler, but the offset is still being committed automatically â€” i.e., no lag is detected.</p>\n<p>My application.yaml:</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>server:\n  port:9292\n\nspring:\n  kafka:\n    consumer:\n      group-id: consumer-group-1\n      enable-auto-commit: false\n      bootstrap-servers: localhost:9092\n      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer\n      value-deserializer: org.springframework.kafka.support.serializer.ErrorHandlingDeserializer\n      properties:\n        spring.json.type.mapping: com.test.kafka_producer.dto.BankTransferEvent:com.test.kafka_consumer.dto.BankTransferEvent\n        spring.deserializer.value.delegate.class: org.apache.kafka.common.serialization.StringDeserializer\n        spring.json.trusted.packages: com.test.kafka_consumer.dto,com.test.kafka_producer.dto\n</code></pre>\n<p>My configuration:</p>\n<pre class=\"lang-java prettyprint-override\"><code>package com.test.kafka_consumer.configuration;\n\nimport com.test.kafka_consumer.dto.BankTransferEvent;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;\nimport org.springframework.kafka.core.ConsumerFactory;\nimport org.springframework.kafka.listener.ContainerProperties;\nimport org.springframework.kafka.listener.DefaultErrorHandler;\nimport org.springframework.util.backoff.FixedBackOff;\n\n@Configuration\npublic class KafkaConsumerConfig {\n    @Bean\n    public DefaultErrorHandler errorHandler() {\n        // z.B. kein Commit bei Fehlern\n        DefaultErrorHandler errorHandler = new DefaultErrorHandler(new FixedBackOff(1000L, 2L)); // 2 Retries\n        errorHandler.setCommitRecovered(false); // verhindert Offset Commit nach Recovery\n        return errorHandler;\n    }\n\n    @Bean\n    public ConcurrentKafkaListenerContainerFactory&lt;String, BankTransferEvent&gt; kafkaListenerContainerFactory(\n            ConsumerFactory&lt;String, BankTransferEvent&gt; consumerFactory) {\n\n        ConcurrentKafkaListenerContainerFactory&lt;String, BankTransferEvent&gt; factory =\n                new ConcurrentKafkaListenerContainerFactory&lt;&gt;();\n        factory.setConsumerFactory(consumerFactory);\n\n        // Manuelles Acknowledgment aktivieren:\n        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL);\n\n        // WICHTIG: Fehlerhandler dem Container zuweisen\n        factory.setCommonErrorHandler(errorHandler());\n\n        return factory;\n    }\n}\n</code></pre>\n<p>My Kafkalistener:</p>\n<pre class=\"lang-java prettyprint-override\"><code>package com.test.kafka_consumer.service;\n\nimport com.test.kafka_consumer.dto.BankTransferEvent;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.kafka.annotation.KafkaListener;\nimport org.springframework.kafka.support.Acknowledgment;\n\nimport org.springframework.stereotype.Service;\n\n@Service\n@Slf4j\npublic class KafkaConsumer {\n\n    @KafkaListener(topics = &quot;topic-json&quot;,groupId = &quot;consumer-group-2&quot;, containerFactory = &quot;kafkaListenerContainerFactory&quot;)\n    public void consumeJsonEvent1(BankTransferEvent bankTransferEvent, Acknowledgment ack){\n        log.info(&quot;Kafka Consumer aufgerufen&quot;);\n        try {\n            log.info(&quot;consumer-JSON-1 consume the event: {&quot; + bankTransferEvent.toString() + &quot;}&quot;);\n            ack.acknowledge();\n        } catch (Exception e){\n            log.error(&quot;Error bei der Event-Verarbeitung: &quot; + e.getMessage());\n        }\n    }\n}\n</code></pre>\n",
    "tags" : [ "java", "spring", "spring-boot", "apache-kafka" ],
    "owner" : {
      "account_id" : 30870753,
      "reputation" : 1,
      "user_id" : 23689759,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/9bbe036a5dd174ce947f0c4f0a692f79?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "JavaInsel",
      "link" : "https://stackoverflow.com/users/23689759/javainsel"
    },
    "is_answered" : false,
    "view_count" : 63,
    "answer_count" : 0,
    "score" : 0,
    "last_activity_date" : 1756370239,
    "creation_date" : 1756328489,
    "link" : "https://stackoverflow.com/questions/79748476/kafka-topic-offset-was-committed-despite-deserialization-problem",
    "content_license" : "CC BY-SA 4.0"
  },
  "answers" : [ ],
  "question_comments" : [ {
    "comment_id" : 140698601,
    "post_id" : 79748476,
    "body" : "Hi @Donz, yes. I turned off the autocommit in my applicaiton.yaml &quot;enable-auto-commit: false&quot;. But this autocommit false works only inside the KafkaListener. My problem occurs during the deserialization error.",
    "score" : 0,
    "owner" : {
      "account_id" : 30870753,
      "reputation" : 1,
      "user_id" : 23689759,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/9bbe036a5dd174ce947f0c4f0a692f79?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "JavaInsel",
      "link" : "https://stackoverflow.com/users/23689759/javainsel"
    },
    "creation_date" : 1756385923,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140698019,
    "post_id" : 79748476,
    "body" : "This question seems to have been generated or &quot;improved&quot; with help of ChatGPT or another AI. Please be aware that using LLMs or other AIs to generate content is <a href=\"https://meta.stackoverflow.com/questions/421831/temporary-policy-generative-ai-e-g-chatgpt-is-banned\">not allowed</a>.",
    "score" : 0,
    "owner" : {
      "account_id" : 213468,
      "reputation" : 110280,
      "user_id" : 466862,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/d873f397779db38cd510d9ee5416fd43?s=256&d=identicon&r=PG",
      "display_name" : "Mark Rotteveel",
      "link" : "https://stackoverflow.com/users/466862/mark-rotteveel"
    },
    "creation_date" : 1756370257,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140697137,
    "post_id" : 79748476,
    "body" : "Have you turned off autocommit? If you want strong committing you need to this manually. Even if autocommit is off kafka consumer does the batch commit in some delay.",
    "score" : 0,
    "owner" : {
      "account_id" : 208839,
      "reputation" : 1397,
      "user_id" : 459572,
      "user_type" : "registered",
      "accept_rate" : 23,
      "profile_image" : "https://www.gravatar.com/avatar/249f0361df87dd50f9292ea86ef55619?s=256&d=identicon&r=PG",
      "display_name" : "Donz",
      "link" : "https://stackoverflow.com/users/459572/donz"
    },
    "creation_date" : 1756330240,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "answer_comments" : { }
}