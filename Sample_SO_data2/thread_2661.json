{
  "question" : {
    "question_id" : 79608038,
    "title" : "Failed to start Kraft controller in K8s",
    "body" : "<p>We are manually trying out Zookeeper to Kafka KRaft migration in our K8s environment. For that the initial step is to deploy Kraft controller in migration mode. We used configmaps to provide the controller.properties configuration during server start.</p>\n<p>Our configMap:</p>\n<pre><code># {% raw %}\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kraft-controller-config\n  namespace: cgbu-ums-dev\ndata:\n  controller.properties: |\n    zookeeper.metadata.migration.enable=true\n    zookeeper.connect=zookeeper:2181\n    process.roles=controller\n    node.id=0\n    controller.quorum.voters=0@kraft-controller-0.kraft-controller:9092\n    #controller.quorum.bootstrap.servers=kraft-controller:9092\n    listeners=CONTROLLER://kraft-controller-0:9092\n    advertised.listeners=CONTROLLER://kraft-controller-0:9092\n    controller.listener.names=CONTROLLER\n    num.network.threads=3\n    num.io.threads=8\n    socket.send.buffer.bytes=102400\n    socket.receive.buffer.bytes=102400\n    socket.request.max.bytes=104857600\n    log.dirs=/var/lib/kafka/data/kraft-controller-0\n    num.partitions=1\n    num.recovery.threads.per.data.dir=1\n    offsets.topic.replication.factor=1\n    transaction.state.log.replication.factor=1\n    transaction.state.log.min.isr=1\n    share.coordinator.state.topic.replication.factor=1\n    share.coordinator.state.topic.min.isr=1\n    log.retention.hours=168\n    log.segment.bytes=1073741824\n    log.retention.check.interval.ms=300000\n# {% endraw %}\n</code></pre>\n<p>On server start I am getting this following error:</p>\n<pre><code>[2025-05-06 05:25:13,768] ERROR Encountered fatal fault: exception while completing controller activation (org.apache.kafka.server.fault.ProcessTerminatingFaultHandler)\njava.lang.RuntimeException: Should not have ZK migrations enabled on a cluster that was created in KRaft mode.\n    at org.apache.kafka.controller.ActivationRecordsGenerator.recordsForNonEmptyLog(ActivationRecordsGenerator.java:168)\n    at org.apache.kafka.controller.ActivationRecordsGenerator.generate(ActivationRecordsGenerator.java:234)\n    at org.apache.kafka.controller.QuorumController$CompleteActivationEvent.generateRecordsAndResult(QuorumController.java:1243)\n    at org.apache.kafka.controller.QuorumController$ControllerWriteEvent.run(QuorumController.java:791)\n    at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:132)\n    at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:215)\n    at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:186)\n    at java.base/java.lang.Thread.run(Thread.java:842)\n</code></pre>\n<p>Initially I was starting the Kraft controller first w/o migration -- it started successfully, then I changed the configmap and added migration properties and did <code>kubectl rollout restart</code>. On restart I got the same error which I believe happened because the pod started in pure Kraft mode but when later told to do migration, there might be some issue in the formatting of logs.dir property so it failed.</p>\n<p>Now that I am directly starting with migration properties enabled, I am not sure why I am getting this error. Need help in figuring out why this happened and how do I fix it.</p>\n<p>Update:\nZK Configuration variables:</p>\n<pre><code>env:\n    - name: ZK_REPLICAS\n        value: &quot;3&quot;\n    - name: ZK_CLIENT_PORT\n        value: &quot;2181&quot;\n    - name: ZK_SERVER_PORT\n        value: &quot;2888&quot;\n    - name: ZK_ELECTION_PORT\n        value: &quot;3888&quot;\n    - name: ZK_TICK_TIME\n        value: &quot;2000&quot;\n    - name: ZK_INIT_LIMIT\n        value: &quot;10&quot;\n    - name: ZK_SYNC_LIMIT\n        value: &quot;5&quot;\n    - name: ZK_MAX_CLIENT_CNXNS\n        value: &quot;500&quot;\n    - name: ZK_SNAP_RETAIN_COUNT\n        value: &quot;3&quot;\n    - name: ZK_PURGE_INTERVAL\n        value: &quot;0&quot;\n    - name: LOG4J_FORMAT_MSG_NO_LOOKUPS\n        value: &quot;true&quot;\n</code></pre>\n",
    "tags" : [ "java", "kubernetes", "apache-kafka", "migration", "kraft" ],
    "owner" : {
      "account_id" : 30637324,
      "reputation" : 39,
      "user_id" : 23486478,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/d1647d7de6770064990c56ddf6ebb092?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "BloodFury",
      "link" : "https://stackoverflow.com/users/23486478/bloodfury"
    },
    "is_answered" : false,
    "view_count" : 163,
    "answer_count" : 0,
    "score" : 0,
    "last_activity_date" : 1746601009,
    "creation_date" : 1746510146,
    "link" : "https://stackoverflow.com/questions/79608038/failed-to-start-kraft-controller-in-k8s",
    "content_license" : "CC BY-SA 4.0"
  },
  "answers" : [ ],
  "question_comments" : [ {
    "comment_id" : 140403698,
    "post_id" : 79608038,
    "body" : "There should be misconfiguration between environments or even the version are different.",
    "score" : 0,
    "owner" : {
      "account_id" : 24440940,
      "reputation" : 5259,
      "user_id" : 18364656,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/70eb650df3e935255b17e62942f30620?s=256&d=identicon&r=PG",
      "display_name" : "Andrei Lisa",
      "link" : "https://stackoverflow.com/users/18364656/andrei-lisa"
    },
    "creation_date" : 1746616812,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140403370,
    "post_id" : 79608038,
    "body" : "Yes, but that worked on my local machine. If I try to do migration stuff with 1 node in k8s it fails here as well.",
    "score" : 0,
    "owner" : {
      "account_id" : 30637324,
      "reputation" : 39,
      "user_id" : 23486478,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/d1647d7de6770064990c56ddf6ebb092?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "BloodFury",
      "link" : "https://stackoverflow.com/users/23486478/bloodfury"
    },
    "creation_date" : 1746611255,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140403137,
    "post_id" : 79608038,
    "body" : "It means that one of the node has been created with KRaft controller from the beginning, I guess. As you pointed out that 1 node with the same migration stuff works well and not when having 2 or more.",
    "score" : 0,
    "owner" : {
      "account_id" : 24440940,
      "reputation" : 5259,
      "user_id" : 18364656,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/70eb650df3e935255b17e62942f30620?s=256&d=identicon&r=PG",
      "display_name" : "Andrei Lisa",
      "link" : "https://stackoverflow.com/users/18364656/andrei-lisa"
    },
    "creation_date" : 1746606841,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140402823,
    "post_id" : 79608038,
    "body" : "@AndreiLisa, I have added the envs we use for deploying ZK. Please let me know if this is not what you were looking for. See I tried starting Kraft controller (just 1 node) in my local machine using podman and migration by default -- successful. There were minor changes to the controller.properties.",
    "score" : 0,
    "owner" : {
      "account_id" : 30637324,
      "reputation" : 39,
      "user_id" : 23486478,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/d1647d7de6770064990c56ddf6ebb092?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "BloodFury",
      "link" : "https://stackoverflow.com/users/23486478/bloodfury"
    },
    "creation_date" : 1746601313,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140402756,
    "post_id" : 79608038,
    "body" : "Could you also share as a question update the ZooKeeper configuration you have ? I mean there can be some misconfiguration in the KRaft controller but without ZooKeeper one I cannot tell you exactly",
    "score" : 0,
    "owner" : {
      "account_id" : 24440940,
      "reputation" : 5259,
      "user_id" : 18364656,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/70eb650df3e935255b17e62942f30620?s=256&d=identicon&r=PG",
      "display_name" : "Andrei Lisa",
      "link" : "https://stackoverflow.com/users/18364656/andrei-lisa"
    },
    "creation_date" : 1746599882,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140402653,
    "post_id" : 79608038,
    "body" : "@AndreiLisa, I don&#39;t see that path in the guide you shared, I believe what have to do is directly start Kraft controller with migration enabled... which I tried but again not working and getting the same error",
    "score" : 0,
    "owner" : {
      "account_id" : 30637324,
      "reputation" : 39,
      "user_id" : 23486478,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/d1647d7de6770064990c56ddf6ebb092?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "BloodFury",
      "link" : "https://stackoverflow.com/users/23486478/bloodfury"
    },
    "creation_date" : 1746597218,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140399768,
    "post_id" : 79608038,
    "body" : "About the migrations steps <a href=\"https://docs.confluent.io/platform/current/installation/migrate-zk-kraft.html#phase-1-cluster-is-running-in-zk-mode\" rel=\"nofollow noreferrer\">ZooKeeper to KRaft</a>",
    "score" : 1,
    "owner" : {
      "account_id" : 24440940,
      "reputation" : 5259,
      "user_id" : 18364656,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/70eb650df3e935255b17e62942f30620?s=256&d=identicon&r=PG",
      "display_name" : "Andrei Lisa",
      "link" : "https://stackoverflow.com/users/18364656/andrei-lisa"
    },
    "creation_date" : 1746526387,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140399681,
    "post_id" : 79608038,
    "body" : "Yes I am suggesting that path.",
    "score" : 0,
    "owner" : {
      "account_id" : 24440940,
      "reputation" : 5259,
      "user_id" : 18364656,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/70eb650df3e935255b17e62942f30620?s=256&d=identicon&r=PG",
      "display_name" : "Andrei Lisa",
      "link" : "https://stackoverflow.com/users/18364656/andrei-lisa"
    },
    "creation_date" : 1746524947,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140399657,
    "post_id" : 79608038,
    "body" : "@AndreiLisa, how do I run that in ZK mode. I believe these properties are enough to start a Kraft controller with migration enabled by default on startup. What you are suggesting is that I should start a kafka cluster in ZK mode &gt;&gt; convert it to Kraft controller mode &gt;&gt; run migration stuff ?",
    "score" : 0,
    "owner" : {
      "account_id" : 30637324,
      "reputation" : 39,
      "user_id" : 23486478,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/d1647d7de6770064990c56ddf6ebb092?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "BloodFury",
      "link" : "https://stackoverflow.com/users/23486478/bloodfury"
    },
    "creation_date" : 1746524686,
    "content_license" : "CC BY-SA 4.0"
  }, {
    "comment_id" : 140399637,
    "post_id" : 79608038,
    "body" : "The cluster was created in KRaft mode, even the attached logs prove it this is why you are getting that exception, Actually the ZK migration state is NONE. To check the configuration create a cluster in the ZooKeeper mode and then run migration stuff.",
    "score" : 0,
    "owner" : {
      "account_id" : 24440940,
      "reputation" : 5259,
      "user_id" : 18364656,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/70eb650df3e935255b17e62942f30620?s=256&d=identicon&r=PG",
      "display_name" : "Andrei Lisa",
      "link" : "https://stackoverflow.com/users/18364656/andrei-lisa"
    },
    "creation_date" : 1746524237,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "answer_comments" : { }
}