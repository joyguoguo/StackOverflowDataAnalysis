{
  "question" : {
    "question_id" : 79594738,
    "title" : "Why the performance is bad if I use HashMap to solve Codility problem MinAbsSum?",
    "body" : "<p>Regarding the Codility problem MinAbsSum at <a href=\"https://app.codility.com/programmers/lessons/17-dynamic_programming/min_abs_sum/\" rel=\"nofollow noreferrer\">https://app.codility.com/programmers/lessons/17-dynamic_programming/min_abs_sum/</a>, the performance is bad if I use HashMap to solve the problem. I expect the performance to be similar to Array. I prefer to use HashMap because Array wastes a lot of memory if the number range is too large. Any idea why the HashMap is much slower than the Array?</p>\n<pre class=\"lang-java prettyprint-override\"><code>import java.util.*;\n\npublic class MinAbsSumUsingHashMap {\n    // Total score = 54%\n    // Detected time complexity: O(N**2 * max(abs(A)))\n    public int solution(int[] A) {\n        // 1. Convert all numbers to absolute numbers\n        // 2. Sum all the converted absolute numbers\n        // 3. Count the occurrence of all the converted absolute numbers\n        int sum = 0;\n        Map&lt;Integer, Integer&gt; numberCountMap = new TreeMap&lt;&gt;();\n        for (int num : A) {\n            int absNum = Math.abs(num);\n            sum += absNum;\n            numberCountMap.merge(absNum, 1, Integer::sum);\n        }\n\n        AllPossibleSumNumbers allPossibleSumNumbers = new AllPossibleSumNumbers(sum);\n        for (Map.Entry&lt;Integer, Integer&gt; entry : numberCountMap.entrySet()) {\n            int absNum = entry.getKey();\n            int count = entry.getValue();\n            allPossibleSumNumbers.addPossibleSumNumber(absNum, count);\n        }\n\n        float halfSum = sum / 2f;\n        int halfSumFloor = (int) Math.floor(halfSum);\n        for (int bestPossibleHalfSum = halfSumFloor; bestPossibleHalfSum &gt;= 0; bestPossibleHalfSum--) {\n            if (allPossibleSumNumbers.isPossibleSumNumber(bestPossibleHalfSum)) {\n                float halfDifference = halfSum - bestPossibleHalfSum;\n                float fullDifference = halfDifference * 2;\n                return (int) fullDifference;\n            }\n        }\n        return -1; // Ideally, it will not return -1.\n    }\n\n    class AllPossibleSumNumbers {\n        private final Map&lt;Integer, Integer&gt; allPossibleSumCounts = new HashMap&lt;&gt;();\n        private final int expectedSum;\n\n        public AllPossibleSumNumbers(int expectedSum) {\n            this.expectedSum = expectedSum;\n\n            // Sum 0 can be achieved without any number\n            int possibleSumNumber = 0;\n            int count = 0;\n            allPossibleSumCounts.put(possibleSumNumber, count);\n        }\n\n        public void addPossibleSumNumber(int num, int count) {\n            for (int possibleSum = 0; possibleSum &lt;= expectedSum; possibleSum++) {\n                if (isPossibleSumNumber(possibleSum)) {\n                    // we can set like this because no value num is needed to obtain the possibleSum\n                    allPossibleSumCounts.put(possibleSum, count);\n                } else if (possibleSum &gt;= num) {\n                    // It is not a possible sum number, check the previous one\n                    int prevPossibleSum = possibleSum - num;\n                    Integer prevCount = allPossibleSumCounts.get(prevPossibleSum);\n                    if (prevCount != null) {\n                        // previous one is a possible sum number\n                        int currCount = prevCount - 1; // currCount should be reduced by 1 because the num has been used once to achieve the current sum\n                        if (currCount &gt;= 0) {\n                            // Is currCount &gt;= 0 necessary? Got the same score after adding currCount &gt;= 0 condition :(\n                            allPossibleSumCounts.put(possibleSum, currCount);\n                        }\n                    }\n                }\n            }\n        }\n\n        public boolean isPossibleSumNumber(int num) {\n            Integer count = allPossibleSumCounts.get(num);\n            if (count == null) {\n                return false;\n            } else {\n                return count &gt;= 0;\n            }\n        }\n    }\n}\n</code></pre>\n<p>A similar code uses array can achieve a 100% score.</p>\n<pre class=\"lang-java prettyprint-override\"><code>import java.util.*;\n\npublic class MinAbsSumUsingArray {\n    // Total score = 100%\n    // Detected time complexity: O(N * max(abs(A))**2)\n    public int solution(int[] A) {\n        // 1. Convert all numbers to absolute numbers\n        // 2. Sum all the converted absolute numbers\n        // 3. Count the occurrence of all the converted absolute numbers\n        int sum = 0;\n        Map&lt;Integer, Integer&gt; numberCountMap = new TreeMap&lt;&gt;();\n        for (int num : A) {\n            int absNum = Math.abs(num);\n            sum += absNum;\n            numberCountMap.merge(absNum, 1, Integer::sum);\n        }\n\n        AllPossibleSumNumbers allPossibleSumNumbers = new AllPossibleSumNumbers(sum);\n        for (Map.Entry&lt;Integer, Integer&gt; entry : numberCountMap.entrySet()) {\n            int absNum = entry.getKey();\n            int count = entry.getValue();\n            allPossibleSumNumbers.addPossibleSumNumber(absNum, count);\n        }\n\n        float halfSum = sum / 2f;\n        int halfSumFloor = (int) Math.floor(halfSum);\n        for (int bestPossibleHalfSum = halfSumFloor; bestPossibleHalfSum &gt;= 0; bestPossibleHalfSum--) {\n            if (allPossibleSumNumbers.isPossibleSumNumber(bestPossibleHalfSum)) {\n                float halfDifference = halfSum - bestPossibleHalfSum;\n                float fullDifference = halfDifference * 2;\n                return (int) fullDifference;\n            }\n        }\n        return -1; // Ideally, it will not return -1.\n    }\n\n    class AllPossibleSumNumbers {\n        private final int[] allPossibleSumCounts;\n\n        public AllPossibleSumNumbers(int expectedSum) {\n            allPossibleSumCounts = new int[expectedSum + 1];\n\n            // first one is 0. the rest are -1\n            for (int i = 1; i &lt; allPossibleSumCounts.length; i++) {\n                allPossibleSumCounts[i] = -1;\n            }\n        }\n\n        public void addPossibleSumNumber(int num, int count) {\n            for (int possibleSum = 0; possibleSum &lt; allPossibleSumCounts.length; possibleSum++) {\n                if (isPossibleSumNumber(possibleSum)) {\n                    // we can set like this because no value num is needed to obtain the possibleSum\n                    allPossibleSumCounts[possibleSum] = count;\n                } else if (possibleSum &gt;= num) {\n                    // It is not a possible sum number, check the previous one\n                    int prevPossibleSum = possibleSum - num;\n                    int prevCount = allPossibleSumCounts[prevPossibleSum];\n                    int currCount = prevCount - 1; // currCount should be reduced by 1 because the num has been used once to achieve the current sum\n                    allPossibleSumCounts[possibleSum] = currCount;\n                }\n            }\n        }\n\n        public boolean isPossibleSumNumber(int num) {\n            return allPossibleSumCounts[num] &gt;= 0;\n        }\n    }\n}\n</code></pre>\n<p>Interestingly, I just tried the same in Python, and both work fine. I assume the Python dictionary is equivalent to the Java HashMap. Please let me know if I am wrong.</p>\n<pre class=\"lang-py prettyprint-override\"><code>def solution(A):\n    array_length = len(A)\n    # 1. Convert all numbers to absolute numbers\n    for best_possible_half_sum in range(array_length):\n        A[best_possible_half_sum] = abs(A[best_possible_half_sum])\n    # 2. Sum all the converted absolute numbers\n    abs_sum = sum(A)\n    # 3. Count the occurrence of all the converted absolute numbers\n    num_counts = {}\n    for num in A:\n        if num in num_counts:\n            num_counts[num] += 1\n        else:\n            num_counts[num] = 1\n\n    # Sum 0 can be achieved without any number\n    all_possible_sum_counts = {0: 0}\n\n    for num, count in num_counts.items():\n        for possible_sum in range(abs_sum):\n            if possible_sum in all_possible_sum_counts and all_possible_sum_counts[possible_sum] &gt;= 0:\n                # we can set like this because no value num is needed to obtain the possible_sum\n                all_possible_sum_counts[possible_sum] = count\n            elif (possible_sum &gt;= num):\n                # It is not a possible sum number, check the previous one\n                prev_possible_sum = possible_sum - num\n                if prev_possible_sum in all_possible_sum_counts:\n                    # previous one is a possible sum number\n                    prev_count = all_possible_sum_counts[prev_possible_sum]\n                    curr_count = prev_count - 1 # currCount should be reduced by 1 because the num has been used once to achieve the current sum\n                    all_possible_sum_counts[possible_sum] = curr_count\n    \n    half_sum = abs_sum / 2\n    half_sum_floor = abs_sum // 2\n    for best_possible_half_sum in range(half_sum_floor, -1, -1):\n        if best_possible_half_sum in all_possible_sum_counts and all_possible_sum_counts[best_possible_half_sum] &gt;= 0:\n            half_difference = half_sum - best_possible_half_sum\n            full_difference = half_difference * 2\n            return int(full_difference)\n</code></pre>\n<p>Below is the array version</p>\n<pre class=\"lang-py prettyprint-override\"><code>def solution(A):\n    array_length = len(A)\n    # 1. Convert all numbers to absolute numbers\n    for best_possible_half_sum in range(array_length):\n        A[best_possible_half_sum] = abs(A[best_possible_half_sum])\n    # 2. Sum all the converted absolute numbers\n    abs_sum = sum(A)\n    # 3. Count the occurrence of all the converted absolute numbers\n    num_counts = {}\n    for num in A:\n        if num in num_counts:\n            num_counts[num] += 1\n        else:\n            num_counts[num] = 1\n\n    # first one is 0. the rest are -1\n    all_possible_sum_counts = [-1] * (abs_sum + 1)\n    all_possible_sum_counts[0] = 0\n\n    for num, count in num_counts.items():\n        for possible_sum in range(abs_sum):\n            if all_possible_sum_counts[possible_sum] &gt;= 0:\n                # we can set like this because no value num is needed to obtain the possible_sum\n                all_possible_sum_counts[possible_sum] = count\n            elif (possible_sum &gt;= num):\n                # It is not a possible sum number, check the previous one\n                prev_possible_sum = possible_sum - num\n                prev_count = all_possible_sum_counts[prev_possible_sum]\n                curr_count = prev_count - 1 # currCount should be reduced by 1 because the num has been used once to achieve the current sum\n                all_possible_sum_counts[possible_sum] = curr_count\n    \n    half_sum = abs_sum / 2\n    half_sum_floor = abs_sum // 2\n    for best_possible_half_sum in range(half_sum_floor, -1, -1):\n        if all_possible_sum_counts[best_possible_half_sum] &gt;= 0:\n            half_difference = half_sum - best_possible_half_sum\n            full_difference = half_difference * 2\n            return int(full_difference)\n</code></pre>\n",
    "tags" : [ "python", "java", "arrays", "performance", "hashmap" ],
    "owner" : {
      "account_id" : 21416883,
      "reputation" : 23,
      "user_id" : 15775974,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/edc26098f0fb2c9de97886d594db3007?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "James",
      "link" : "https://stackoverflow.com/users/15775974/james"
    },
    "is_answered" : true,
    "view_count" : 151,
    "answer_count" : 1,
    "score" : 1,
    "last_activity_date" : 1749224770,
    "creation_date" : 1745734983,
    "link" : "https://stackoverflow.com/questions/79594738/why-the-performance-is-bad-if-i-use-hashmap-to-solve-codility-problem-minabssum",
    "content_license" : "CC BY-SA 4.0"
  },
  "answers" : [ {
    "answer_id" : 79594899,
    "question_id" : 79594738,
    "body" : "<p><strong>TL;DR:</strong> the array is pretty small in memory (&lt;10 MiB) so accesses are fast and the memory overhead is still small, meanwhile the overheads of hash-map are huge, especially on run-time.</p>\n<hr />\n<h2>About Java</h2>\n<p>In Java, a <code>int[]</code> data type is a sequence of native (signed) integer (of typically 4 bytes) contiguously stored in memory. Accessing an item is very efficient because there is no software overhead for this. On mainstream CPUs, it can be done in a single CPU instruction. As long as the array fit in the CPU cache, random accesses are very fast.</p>\n<p>A <a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/HashMap.html\" rel=\"nofollow noreferrer\"><code>HashMap&lt;Integer, Integer&gt;</code></a> is equivalent to <code>Hashtable&lt;Integer, Integer&gt;</code> internally besides the handling of <code>null</code> and synchronisation. It basically contains an array of bucket objects. Each bucket is typically a structure containing a hash, the key and the value as well as a reference to the next structure forming a linked list (see <a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/Hashtable.html\" rel=\"nofollow noreferrer\">the doc of <code>Hashtable</code></a> for more information). The number of buckets is basically the <em>capacity</em> of the container. There are generally more buckets than the number of items so to avoid <em>collisions</em> (see load-factor). Items are hashed and the number of buckets can be adapted at runtime causing re-hashing of all items (quite expensive). The later is typically done with a power-of-n growing policy (where <code>n</code> is often between 1 excluded and 2 included). The default load-factor is 0.75. Which means that for 1000 items, we should expect 1300~2700 buckets. When considering that each bucket is significantly bigger than just a <code>Integer</code> or even a <code>int</code>, we can safely say that <strong>the memory overhead of hash-maps is significant</strong>.</p>\n<p>Indeed, on top of that, this is not just <code>int</code> that are stored but <strong><code>Integer</code> object</strong> which are handled completely differently internally. Such data type are <a href=\"https://docs.oracle.com/javase/tutorial/java/data/autoboxing.html\" rel=\"nofollow noreferrer\">autoboxed</a> but they are managed like full objects except for tiny integer values which are <a href=\"https://stackoverflow.com/questions/20897020/why-integer-class-caching-values-in-the-range-128-to-127\">cached</a>. This means the Java implementation internally use a pointer on a dynamically-allocated garbage-collected Integer object. You cannot use a native <code>int</code> data-type parameter for such container (or any container actually) because of how <a href=\"https://docs.oracle.com/javase/tutorial/extra/generics/index.html\" rel=\"nofollow noreferrer\">Generics</a> work. On a 64-bit machine with a 64-bit JVM, pointers should theoretically be 8-byte wide. That being said some JVMs like Hotspot can compress pointers to objects so they only take 4 bytes in many cases. This is called <a href=\"https://wiki.openjdk.org/display/HotSpot/CompressedOops\" rel=\"nofollow noreferrer\">CompressedOops</a> (see <a href=\"https://stackoverflow.com/questions/981073/how-big-is-an-object-reference-in-java-and-precisely-what-information-does-it-co\">this post</a> and <a href=\"https://stackoverflow.com/questions/25120546/trick-behind-jvms-compressed-oops\">this one</a> for more information; thanks to @Holger for pointing this out). In this case, using the Hotspot JVM, this means the array of bucket objects is actually an array of 4-byte pointers referencing dynamically-allocated garbage-collected bucket objects. On such platform, each bucket typically takes 24-bytes (hash + 3 pointers + some padding). 2 of the 3 pointers reference dynamically-allocated garbage-collected <code>Integer</code> objects. <a href=\"https://www.baeldung.com/java-size-of-object\" rel=\"nofollow noreferrer\">All objects take at least 16 bytes</a> on modern JVMs due to a 12-byte header and also due to the 8-byte alignment required by CompressedOops. An <code>Integer</code> object actually takes 16 bytes (a 12-byte header + 4-byte actual value). This is 4 times more than an <code>int</code>-items in an <code>int[]</code> array! Even worse: you need 2 Integer objects here for each key-value pair in the <code>HashMap</code>, so 32-bytes. Because of all of that, we can safely say that, on such mainstream platform, a <code>HashMap</code> takes at least <strong>14 times more memory</strong> than the number of <code>int</code> actually used in an alternative array. It is also much slower because of all the afore-mentioned overhead (i.e. multiple memory indirections, GC, hashing, allocations).</p>\n<p>Thus, yes, a <code>HashMap&lt;Integer, Integer&gt;</code> can theoretically be smaller in memory than an array when the number of element actually used in the array are tiny compared to its size (let us call this the load-factor of the array). For any array load-factor &gt;0.1, the hash-map will take more memory than a basic array. For an array load-factor of 0.03~0.10, both should take a significant amount of memory in practice. For array load-factors &lt;0.03, the hash-map should be better. The question is then: how many items are actually used in the array. Or put it differently: how big is the array load-factor. Not to mention that even with big arrays taking more memory, the hash-map will be still be much slower due to all its overheads. At least, this will be the case unless the array load-factor is so tiny that the array is really huge in memory and memory overheads (e.g. uncached accesses, paging, etc.) appears.</p>\n<p>It turns out that, <em>&quot;N is an integer within the range [0..20,000]&quot;</em> and <em>&quot;each element of array A is an integer within the range [−100..100]&quot;</em> in your exercise so the array should take less than 10 MiB. In practice, the sum should be often significantly smaller because numbers can be negative (likely less than few MiB). <strong>The array should fit in the quite-fast L3 cache of all recent mainstream CPU</strong>. Thus, accessing such an array is pretty cheap. Meanwhile, there is a lot to do for accessing a hash-map (which might not even fit in the L2 cache). <strong>You should not care about the memory overhead of a single small array</strong>.</p>\n<hr />\n<h2>About (C)Python</h2>\n<p>Regarding Python, the default implementation (CPython) is an <strong>interpreter</strong> which is insanely <strong>slow</strong>. Accessing a list is much slower than a <code>int[]</code> array in Java. Indeed, using a mainstream optimised Java VM, the code is <strong>compiled</strong> at runtime thanks to a just-in-time (JIT) compiler. Any trivial like an addition of 2 integers is typically &gt;100 times slower than in Java. In the end, you might not even see a difference between a <code>list</code> and a <code>dict</code> because other overhead are too big. You can test that with PyPy (JIT) instead of CPython (interpreter). Still, <code>list</code> store integer <strong>objects</strong> in Python like an <code>ArrayList&lt;Integer&gt;</code> in Java, which is generally significantly slower than just a <code>int[]</code> data-type containing contiguous native integers. Besides, integers in Python have an variable size (no bound), as opposed to <code>int</code> or <code>Integer</code> in Java, introducing even more overheads (even in PyPy) and hiding even more the difference between the two implementations.</p>\n<blockquote>\n<p>I assume the Python dictionary is equivalent to the Java HashMap</p>\n</blockquote>\n<p><strong>They are implemented very differently</strong>. In the Java's <code>HashMap</code>, a <em>&quot;single bucket stores multiple entries&quot;</em>. Meanwhile, <a href=\"https://stackoverflow.com/questions/327311/how-are-pythons-built-in-dictionaries-implemented\">CPython <code>dict</code> use open-addressing</a> so each bucket only contains 1 item (hence no linked lists -- see <a href=\"https://en.wikipedia.org/wiki/Open_addressing\" rel=\"nofollow noreferrer\">this article</a> on the matter). Open-addressing tends to be faster when both the load-factor is not high (e.g. &lt;0.9) and the hash-function is well-balanced. <strong>I expect open-addressing to be faster in this case</strong> since numbers are small, the hash function should not be too bad, and the default load factor is reasonably low enough (at the expense of a higher memory usage). Beside, iterating over key-values (like you do) is cheaper on hash-map with open-addressing (like in CPython) when the load-factor is not to high, because it internally just travel a contiguous array of buckets; meanwhile an implementation with linked-lists (like Java) does more (possibly unpredictable) indirections in memory due to linked-lists in each buckets. Pointer chasing is generally inefficient on modern CPUs.</p>\n",
    "score" : 3,
    "is_accepted" : true,
    "owner" : {
      "account_id" : 17815984,
      "reputation" : 53370,
      "user_id" : 12939557,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/cdadf199839f6b9bb97198c7254bbf09?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name" : "J&#233;r&#244;me Richard",
      "link" : "https://stackoverflow.com/users/12939557/j%c3%a9r%c3%b4me-richard"
    },
    "creation_date" : 1745746886,
    "last_activity_date" : 1749224770,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "question_comments" : [ {
    "comment_id" : 140373345,
    "post_id" : 79594738,
    "body" : "If you think an array wastes a lot of memory, you&#39;d be surprised how much more memory a HashMap uses for a comparable number of entries...",
    "score" : 0,
    "owner" : {
      "account_id" : 213468,
      "reputation" : 110280,
      "user_id" : 466862,
      "user_type" : "registered",
      "profile_image" : "https://www.gravatar.com/avatar/d873f397779db38cd510d9ee5416fd43?s=256&d=identicon&r=PG",
      "display_name" : "Mark Rotteveel",
      "link" : "https://stackoverflow.com/users/466862/mark-rotteveel"
    },
    "creation_date" : 1745745415,
    "content_license" : "CC BY-SA 4.0"
  } ],
  "answer_comments" : {
    "79594899" : [ {
      "comment_id" : 140396085,
      "post_id" : 79594899,
      "body" : "I did not see anything in the <code>Hashtable</code> documentation that wasn’t also covered by <a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/HashMap.html\" rel=\"nofollow noreferrer\">the <code>HashMap</code> documentation</a> which you already linked.",
      "score" : 1,
      "owner" : {
        "account_id" : 3211603,
        "reputation" : 301001,
        "user_id" : 2711488,
        "user_type" : "registered",
        "profile_image" : "https://i.sstatic.net/t2hoD.jpg?s=256",
        "display_name" : "Holger",
        "link" : "https://stackoverflow.com/users/2711488/holger"
      },
      "creation_date" : 1746431309,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140381892,
      "post_id" : 79594899,
      "body" : "@Holger Thank you for mentioning 32-bit references (i.e. CompressedOops). I did not know that. I edited the question accordingly. In the end, the overhead is still huge (actually worse because objects are bigger than expected). Regarding <code>Hashtable</code>, I agree, but I mentioned it because the doc reference it and the implementation is described precisely enough only for <code>Hashtable</code> in the doc. If there is an official/doc source directly talking about the <code>HashMap</code> implementation, then this is better to reference it and remove the part about <code>HashTable</code> indeed.",
      "score" : 0,
      "owner" : {
        "account_id" : 17815984,
        "reputation" : 53370,
        "user_id" : 12939557,
        "user_type" : "registered",
        "profile_image" : "https://www.gravatar.com/avatar/cdadf199839f6b9bb97198c7254bbf09?s=256&d=identicon&r=PG&f=y&so-version=2",
        "display_name" : "J&#233;r&#244;me Richard",
        "link" : "https://stackoverflow.com/users/12939557/j%c3%a9r%c3%b4me-richard"
      },
      "creation_date" : 1745962102,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140380766,
      "post_id" : 79594899,
      "body" : "Further note that today, even 64 bit JVMs use 32 bit references by default. This doesn’t matter much, as the array of references is far smaller than the memory required for what you call “bucket objects” plus the <code>Integer</code> objects. So, your explanation still applies to the overall performance.",
      "score" : 2,
      "owner" : {
        "account_id" : 3211603,
        "reputation" : 301001,
        "user_id" : 2711488,
        "user_type" : "registered",
        "profile_image" : "https://i.sstatic.net/t2hoD.jpg?s=256",
        "display_name" : "Holger",
        "link" : "https://stackoverflow.com/users/2711488/holger"
      },
      "creation_date" : 1745940294,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140380717,
      "post_id" : 79594899,
      "body" : "I don’t see the point of saying “A <code>HashMap&lt;Integer, Integer&gt;</code> is equivalent to <code>Hashtable&lt;Integer, Integer&gt;</code>” and even linking to <code>Hashtable</code>’s documentation. Unless you’re talking to somebody who knowingly worked with Java 1.0 before, this statement is useless and the documentation of <code>Hashtable</code> doesn’t say anything that wasn’t covered by <code>HashMap</code>’s documentation already linked in a preceding sentence. The entire answer would work well without bringing in the unrelated <code>Hashtable</code> class.",
      "score" : 1,
      "owner" : {
        "account_id" : 3211603,
        "reputation" : 301001,
        "user_id" : 2711488,
        "user_type" : "registered",
        "profile_image" : "https://i.sstatic.net/t2hoD.jpg?s=256",
        "display_name" : "Holger",
        "link" : "https://stackoverflow.com/users/2711488/holger"
      },
      "creation_date" : 1745939708,
      "content_license" : "CC BY-SA 4.0"
    }, {
      "comment_id" : 140377627,
      "post_id" : 79594899,
      "body" : "It is wild to me to think that less than 10 megabytes is now considered &quot;tiny in memory&quot; but this answer is correct and a good explanation.",
      "score" : 0,
      "owner" : {
        "account_id" : 318670,
        "reputation" : 16477,
        "user_id" : 636009,
        "user_type" : "registered",
        "profile_image" : "https://i.sstatic.net/IIQJV.jpg?s=256",
        "display_name" : "David Conrad",
        "link" : "https://stackoverflow.com/users/636009/david-conrad"
      },
      "creation_date" : 1745864457,
      "content_license" : "CC BY-SA 4.0"
    } ]
  }
}